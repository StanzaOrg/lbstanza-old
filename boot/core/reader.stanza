;See License.txt for details about licensing.
defpackage reader :
   import core
   import collections

;=============== PUBLIC INTERFACE ===========================
public defn lex (text:String) -> List<Token> :
   lex-all-forms(StringInputStream(text))

public defn lex-file (filename:String) -> List<Token> :
   println-all(["Reading " filename])
   val eater = StringInputStream(read-file(filename), filename)
   lex-all-forms(eater)
   
public defn lex-form (eater:StringInputStream) :
   init-lexer(eater)
   eat-lexeme()
   while (peek?(EATER) != false) and not empty?(SCOPES) :
      eat-lexeme()
   val form = head(lex-all(group-all()))
   throw(LexerExceptions(ERRORS)) when not empty?(ERRORS)
   form

public defn lex-all-forms (eater:StringInputStream) :
   init-lexer(eater)
   eat-all()
   val grouped = group-all()
   val form = lex-all(grouped)
   throw(LexerExceptions(ERRORS)) when not empty?(ERRORS)
   form

;=============== TOKEN CLASSES ==============================
defstruct Indentation :
   indent:Int
defmethod print (o:OutputStream, i:Indentation) :
   print-all(o, ["[Indentation " indent(i) "]"])

defstruct OpenToken :
   symbol:Symbol
defmethod print (o:OutputStream, t:OpenToken) :
   print-all(o, ["OPEN[" symbol(t) "]"])

defstruct CloseToken :
   symbol:Symbol
defmethod print (o:OutputStream, t:CloseToken) :
   print-all(o, ["CLOSE[" symbol(t) "]"])

defstruct PuncToken :
   symbol:Symbol
defmethod print (o:OutputStream, t:PuncToken) :
   print-all(o, ["PUNC[" symbol(t) "]"])

;=============== LEXER STATE ================================
var LEXEMES: Vector<Token>
var SCOPES: Vector<Symbol>
var ERRORS: Vector<LexerException>
var EATER: StringInputStream
var STAR?: True|False

defn init-lexer (eater:StringInputStream) :
   EATER = eater
   LEXEMES = Vector<Token>()
   SCOPES = Vector<Symbol>()
   ERRORS = Vector<LexerException>()
   STAR? = false

;================= CHARACTER CLASSES ========================
val CHAR-CLASSES = CharArray(256, to-char(0))
defn class? (c, bit:Int) -> True|False :
   match(c) :
      (c:Char) :
         val mask = to-int(CHAR-CLASSES[to-int(c as Char)])
         ((mask >> bit) & 1) == 1
      (c) :
         false

defn tag-class (class:String, bit:Int) :
   val tag = 1 << bit
   for c in class do :
      val i = to-int(c)
      val mask = to-int(CHAR-CLASSES[i])
      val c2 = to-char(mask | tag)
      CHAR-CLASSES[i] = c2

val DIGIT-CHAR = 0
val ALPHA-CHAR = 1
val PUNC-CHAR = 2
val OPEN-BRACE-CHAR = 3
val CLOSE-BRACE-CHAR = 4
val OPERATOR-CHAR = 5
val SYMBOL-CHAR = 6
val WHITESPACE-CHAR = 7

let :
   val digits = "0123456789"
   val letters = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
   tag-class(letters, ALPHA-CHAR)
   tag-class("_?", ALPHA-CHAR)   
   tag-class(digits, DIGIT-CHAR)
   tag-class("`", PUNC-CHAR)
   tag-class(" ,", WHITESPACE-CHAR)
   tag-class("([{<", OPEN-BRACE-CHAR)
   tag-class(")]}>", CLOSE-BRACE-CHAR)
   tag-class("~!@#$%^*+-=/", OPERATOR-CHAR)
   tag-class("~!@#$%^*+-=/", SYMBOL-CHAR)
   tag-class(".:<&|", OPERATOR-CHAR)
   tag-class("_?", SYMBOL-CHAR)
   tag-class(letters, SYMBOL-CHAR)
   tag-class(digits, SYMBOL-CHAR)

;================ LOW LEVEL PREDICATES =====================
;Lexer Predicates
defn whitespace? (c) : class?(c, WHITESPACE-CHAR)
defn digit? (c) : class?(c, DIGIT-CHAR)
defn alpha? (c) : class?(c, ALPHA-CHAR)
defn punc? (c) : class?(c, PUNC-CHAR)
defn open-brace? (c) : class?(c, OPEN-BRACE-CHAR)
defn close-brace? (c) : class?(c, CLOSE-BRACE-CHAR)
defn number-char? (c) : digit?(c) or (c == '.')
defn symbol-char? (c) : class?(c, SYMBOL-CHAR)
defn operator-char? (c) :
   if c == '>' :
      empty?(SCOPES) or (peek(SCOPES) != `>)
   else :
      class?(c, OPERATOR-CHAR)

;================ EATING FUNCTIONS =========================
defn update-stack (info:FileInfo, c:Symbol) :
   defn pop-stack () :
      if empty?(SCOPES) :
         throw(ExtraClosingToken(info, c))
      else if peek(SCOPES) != c :
         throw(WrongClosingToken(info, peek(SCOPES), c))
      else :
         pop(SCOPES)

   switch {c == _} :
      `\|<| : add(SCOPES, `\|>|)
      `\|[| : add(SCOPES, `\|]|)
      `\|{| : add(SCOPES, `\|}|)
      `\|(| : add(SCOPES, `\|)|)
      `\|*<| : add(SCOPES, `\|>|)
      `\|*[| : add(SCOPES, `\|]|)
      `\|*{| : add(SCOPES, `\|}|)
      `\|*(| : add(SCOPES, `\|)|)
      `\|>| : pop-stack()
      `\|]| : pop-stack()
      `\|}| : pop-stack()
      `\|)| : pop-stack()

defn eat (s:StringInputStream, i:Int) :
   String(repeatedly(next{s}, i))

defn eater-index-when (start:Int, f: Char -> True|False) :
   defn* loop (i:Int) :
      match(peek?(EATER,i)) :
         (c:Char) :
            if f(c) : i
            else : loop(i + 1)
         (c:False) :
            false
   loop(start)   

defn eater-index-of (start:Int, c:Char) :
   eater-index-when(start, {_ == c})

defn token-eaten (t:Token) :
   ;Update Lexemes
   add(LEXEMES, t)
   
   ;Update the stack
   match(item(t)) :
      (x:OpenToken) : update-stack(info(t), symbol(x))
      (x:CloseToken) : update-stack(info(t), symbol(x))
      (x) : false

   ;Update STAR?
   STAR? = 
      match(item(t)) :
         (x:CloseToken) : true
         (x:Int|Float|Char|String) : true
         (x:True|False) : true
         (x:Symbol) : any?(alpha?, to-string(x))         
         (x) : false

   true

defn escape-char (c:Char) -> Char :
   switch {c == _} :
      'n' : '\n'
      '\\' : c
      '"' : c
      '\'' : c
      '|' : c
      else : throw(InvalidEscapeChar(info(EATER), c))

defn eat-escaped-chars () :
   val buf = StringBuffer()
   val end-char = peek?(EATER)
   val end = loop(1) where :
      defn* loop (i:Int) :
         val c1 = peek?(EATER, i)
         val c2 = peek?(EATER, i + 1)
         if c1 == false :
            false
         else if c1 == end-char :
            i + 1
         else if c1 == '\\' and c2 != false :
            add(buf, escape-char(c2 as Char))
            loop(i + 2)
         else :
            add(buf, c1 as Char)
            loop(i + 1)
   if end != false :
      eat(EATER, end as Int)
      to-string(buf)

defn eat-comment () -> True|False :
   if peek?(EATER) == ';' :
      while (peek?(EATER) != false and peek?(EATER) != '\n') :
         next(EATER)
      true   

defn eat-string () :
   val info = info(EATER)
   if peek?(EATER) == '"' :
      match(eat-escaped-chars()) :
         (s:String) : token-eaten(Token(s, info))
         (s:False) : throw(UnclosedString(info))

defn eat-char () :
   val info = info(EATER)
   if peek?(EATER) == '\'' :
      match(eat-escaped-chars()) :
         (s:String) :
            if length(s) == 1 : token-eaten(Token(s[0], info))
            else : throw(InvalidCharString(info))
         (s:False) : throw(UnclosedCharString(info))

defn eat-escaped-symbol () :
   val info = info(EATER)
   if peek?(EATER) == '\\' and peek?(EATER, 1) == '|' :
      next(EATER)
      match(eat-escaped-chars()) :
         (s:String) : token-eaten(Token(to-symbol(s), info))
         (s:False) : throw(UnclosedSymbol(info))

defn symbol-end (start:Int) -> False|Int :
   defn length (a?:True|False, i:Int) :
      if symbol-char?(peek?(EATER,i)) :
         length(a? or alpha?(peek?(EATER,i)), i + 1)
      else if a? :
         i
   length(false, start)      

defn eat-symbol () :
   match(symbol-end(0)) :
      (len:Int) :
         val info = info(EATER)
         val str = eat(EATER, len)
         switch {str == _} :
            "true" : token-eaten(Token(true, info))
            "false" : token-eaten(Token(false, info))
            else : token-eaten(Token(to-symbol(str), info))
      (len:False) :
         false

defn eat-operator () :
   val len = look-forward(0) where :
      defn* look-forward (i:Int) :
         if operator-char?(peek?(EATER,i)) : look-forward(i + 1)
         else if alpha?(peek?(EATER,i)) : look-back(i - 1)
         else : i
      defn* look-back (i:Int) :
         if symbol-char?(peek?(EATER,i)) : look-back(i - 1)
         else : i + 1
   if len > 0 :
      val info = info(EATER)
      token-eaten(Token(to-symbol(eat(EATER, len)), info))

defn* eat-indent () :
   val info = info(EATER)
   val len = find!({peek?(EATER,_) != ' '}, 0 to false)
   eat(EATER, len)
   val indent = Token(Indentation(len), info)
   if eat-comment() :
      eat-indent()
   else if peek?(EATER) == '\n' :
      next(EATER)
      eat-indent()
   else :
      token-eaten(indent)

defn eat-number () :
   if digit?(peek?(EATER,0)) or
      (peek?(EATER) == '-' and digit?(peek?(EATER,1))) :
      
      val info = info(EATER)
      val end = find!({not number-char?(peek?(EATER,_))}, 1 to false)
      val str = eat(EATER, end)
      if contains?(str, '.') :
         match(to-float(str)) :
            (f:Float) : token-eaten(Token(f, info))
            (f:False) : throw(InvalidNumber(info))
      else :
         token-eaten(Token(to-int(str), info))

defn eat-here-string () :
   if peek?(EATER) == '\\' and peek?(EATER,1) == '<' :
      val info = info(EATER)      
      next(EATER)
      val tag-len =
         match(eater-index-of(0, '>')) :
            (i:Int) : i + 1
            (n:False) : throw(InvalidTag(info))
      defn tag? (i:Int) :
         for j in 0 to tag-len all? :
            peek?(EATER, i + j) == peek?(EATER, j)
      val str-len =
         match(find(tag?, tag-len to length(EATER))) :
            (i:Int) : i - tag-len
            (n:False) : throw(NoEndTagFound(info))
      eat(EATER, tag-len)
      val str = eat(EATER, str-len)
      eat(EATER, tag-len)      
      token-eaten(Token(str, info))

defn eat-structural-token () :
   val info = info(EATER)
   if open-brace?(peek?(EATER)) :
      token-eaten(Token(OpenToken(to-symbol(next(EATER))), info))
   else if close-brace?(peek?(EATER)) :
      token-eaten(Token(CloseToken(to-symbol(next(EATER))), info))
   else if punc?(peek?(EATER)) :
      token-eaten(Token(PuncToken(to-symbol(next(EATER))), info))

defn eat-star-token () :
   val info = info(EATER)
   if open-brace?(peek?(EATER)) :
      token-eaten(Token(OpenToken(symbol-join(["*" next(EATER)])), info))

defn eat-capture () :   
   if (peek?(EATER) == '?') :
      match(symbol-end(1)) :
         (end:Int) :
            val pinfo = info(EATER)
            token-eaten(Token(PuncToken(to-symbol(next(EATER))), pinfo))            
            val info = info(EATER)
            token-eaten(Token(to-symbol(eat(EATER, end - 1)), info))            
         (end:False) :
            false

defn eat-lexeme! () :
   val ate? =
      eat-capture() or
      eat-here-string() or
      eat-escaped-symbol() or
      eat-char() or
      eat-string() or
      eat-number() or
      eat-symbol() or
      eat-operator() or
      eat-structural-token()
   if ate? :
      eat-star-token() when STAR?
   else : throw(InvalidToken(info(EATER)))

defn eat-whitespace () :
   if whitespace?(peek?(EATER)) :
      while whitespace?(peek?(EATER)) :
         next(EATER)
      STAR? = false      
      
defn eat-lexeme () :
   eat-whitespace()
   if peek?(EATER) != false :
      if eat-comment() :
         eat-lexeme()
      else if peek?(EATER) == '\n' :
         next(EATER)
         eat-indent()
      else :
         eat-lexeme!()

defn eat-all () :
   while peek?(EATER) != false :
      eat-lexeme()      
      
;================ GROUPING ==================================
val OPEN-PAREN = `\|(|
val STAR-PAREN = `\|*(|
val CLOSE-PAREN = `\|)| 
val OPEN-BRACKET = `\|{|
val STAR-BRACKET = `\|*{|
val CLOSE-BRACKET = `\|}|
val OPEN-BRACE = `\|[|
val STAR-BRACE = `\|*[|
val CLOSE-BRACE = `\|]|
val STAR-ANGLE = `\|*<|
val CLOSE-ANGLE = `\|>|
val COLON = `:
val QUESTION = `?
val BACKTICK = `\|`|

defn matching-end (s:Symbol) :
   if s == OPEN-PAREN : CLOSE-PAREN
   else if s == STAR-PAREN : CLOSE-PAREN
   else if s == OPEN-BRACKET : CLOSE-BRACKET
   else if s == STAR-BRACKET : CLOSE-BRACKET
   else if s == OPEN-BRACE : CLOSE-BRACE
   else if s == STAR-BRACE : CLOSE-BRACE
   else if s == STAR-ANGLE : CLOSE-ANGLE
   else : fatal("No matching end")

var START-INFO = false
var TOKEN-STREAM : Vector<Token>
defn group-all () -> List :
   TOKEN-STREAM = Vector<Token>(length(LEXEMES))
   while not empty?(LEXEMES) :
      add(TOKEN-STREAM, pop(LEXEMES))
   group-rest(false)

defn group-rest (end) -> List :
   if empty?(TOKEN-STREAM) :
      match(end) :
         (end:Symbol) :
            throw(NoClosingToken(START-INFO as FileInfo, end))
         (end) :
            List()
   else :
      val x = peek(TOKEN-STREAM)
      match(item(x)) :
         (t:CloseToken) :
            match(end) :
               (end:Symbol) :
                  pop(TOKEN-STREAM)
                  List()
               (end:Indentation) :
                  List()
         (t:OpenToken) :
            pop(TOKEN-STREAM)
            val old-info = START-INFO
            START-INFO = info(x)
            val g = group-rest(matching-end(symbol(t)))
            START-INFO = old-info
            cons(cons(x, g), group-rest(end))
         (t:PuncToken) :
            pop(TOKEN-STREAM)
            cons(x, group-rest(end))
         (s:Symbol) :
            pop(TOKEN-STREAM)
            if s == COLON :
               match(item(peek(TOKEN-STREAM))) :
                  (i:Indentation) :
                     val y = pop(TOKEN-STREAM)
                     val g = group-rest(i)
                     cons(x, cons(y, g), group-rest(end))
                  (t) :
                     cons(x, group-rest(end))
            else :
               cons(x, group-rest(end))
         (i:Indentation) :
            if (end typeof Indentation) and
               (indent(i) < indent(end as Indentation)) :
               List()
            else :
               pop(TOKEN-STREAM)
               group-rest(end)
         (t) :
            pop(TOKEN-STREAM)
            cons(x, group-rest(end))

;============== ADDING SHORTCUTS ============================
defn indentation? (x) :
   unwrap-token(x) typeof Indentation
defn opentoken? (x, s:Symbol) :
   match(unwrap-token(x)) :
      (x:OpenToken) : symbol(x) == s
      (x) : false
defn opentoken? (x, s:Seqable<Symbol>) :
   match(unwrap-token(x)) :
      (x:OpenToken) : contains?(s, symbol(x))
      (x) : false
defn punctoken? (x, s:Symbol) :
   match(unwrap-token(x)) :
      (x:PuncToken) : symbol(x) == s
      (x) : false
defn startoken-pending? (xs:List) :
   if not empty?(xs) :
      match(head(xs)) :
         (x:FullList) : opentoken?(head(x), [STAR-PAREN, STAR-BRACE, STAR-BRACKET, STAR-ANGLE])
         (x) : false

defn lex-atom (x) -> ? :
   match(x) :
      (x:Token) :
         Token(lex-atom(item(x)), info(x))
      (x:FullList) :
         if indentation?(head(x)) : lex-all(tail(x))
         else if opentoken?(head(x), OPEN-PAREN) : lex-all(tail(x))
         else if opentoken?(head(x), OPEN-BRACE) : cons(`@tuple, lex-all(tail(x)))
         else if opentoken?(head(x), OPEN-BRACKET) : cons(`@afn, lex-all(tail(x)))
         else if opentoken?(head(x), STAR-PAREN) : cons(`@do, lex-all(tail(x)))
         else if opentoken?(head(x), STAR-BRACE) : cons(`@get, lex-all(tail(x)))
         else if opentoken?(head(x), STAR-BRACKET) : cons(`@do-afn, lex-all(tail(x)))
         else if opentoken?(head(x), STAR-ANGLE) : cons(`@of, lex-all(tail(x)))
         else : fatal("Invalid grouped form: %_" % [x])
      (x) : x

defn lex-all (xs:List) -> List :
   if empty?(xs) :
      xs
   else if punctoken?(head(xs), QUESTION) :
      val capped = List(OpenToken(`\|(|), `@cap, xs[1])
      lex-all(cons(capped, tailn(xs, 2)))
   else if punctoken?(head(xs), BACKTICK) :
      if empty?(tail(xs)) :
         `(@quote)
      else :
         val rest = lex-all(tail(xs))
         cons(List(`@quote, head(rest)), tail(rest))
   else :
      cons(lex-atom(head(xs)), lex-all(tail(xs)))

;============== LEXER ERRORS ================================
deftype LexerException <: Exception
defn LexerException (s:String) :
   new LexerException :
      defmethod print (o:OutputStream, this) :
         print(o, s)

defn LexerExceptions (xs:Seqable<LexerException>) :
   LexerException(string-join(xs, "\n"))

defn NoClosingToken (info:FileInfo, end:Symbol) :
   LexerException $ string-join $
   [info ": No closing token found. Expecting " end "."]

defn InvalidNumber (info:FileInfo) :
   LexerException $ string-join $
   [info ": Invalid number."]

defn InvalidToken (info:FileInfo) :
   LexerException $ string-join $
   [info ": Invalid token."]

defn InvalidEscapeChar (info:FileInfo, c:Char) :
   LexerException $ string-join $
   [info ": Invalid escape character: " c "."]

defn UnclosedString (info:FileInfo) :
   LexerException $ string-join $
   [info ": Unclosed string. "]

defn UnclosedCharString (info:FileInfo) :
   LexerException $ string-join $
   [info ": Unclosed character. "]

defn UnclosedSymbol (info:FileInfo) :
   LexerException $ string-join $
   [info ": Unclosed symbol. "]

defn InvalidCharString (info:FileInfo) :
   LexerException $ string-join $
   [info ": Invalid character string. Must have length 1."]

defn WrongClosingToken (info:FileInfo, expected:Symbol, actual:Symbol) :
   LexerException $ string-join $
   [info ": Wrong closing parenthesis. Expecting " expected " but got " actual "."]

defn ExtraClosingToken (info:FileInfo, c:Symbol) :
   LexerException $ string-join $
   [info ": Extra closing token found: " c "."]

defn InvalidTag (info:FileInfo) :
   LexerException $ string-join $
   [info ": Invalid tag for here string."]

defn NoEndTagFound (info:FileInfo) :
   LexerException $ string-join $
   [info ": No ending tag found for here string."]