;See License.txt for details about licensing.
defpackage reader :
   import core
   import collections

;============================================================
;================== Public Interface ========================
;============================================================
   
public defn read (eater:StringInputStream) :
   init-lexer(eater)
   eat-lexeme()
   while (peek?(EATER) != false) and not empty?(SCOPES) :
      eat-lexeme()
   val form = head(lex-all(group-all()))
   throw(LexerExceptions(ERRORS)) when not empty?(ERRORS)
   form

public defn read-all (eater:StringInputStream) :
   init-lexer(eater)
   eat-all()
   val grouped = group-all()
   val form = lex-all(grouped)
   throw(LexerExceptions(ERRORS)) when not empty?(ERRORS)
   form

public defn read-all (text:String) -> List<Token> :
   read-all(StringInputStream(text))

public defn read-file (filename:String) -> List<Token> :
   val eater = StringInputStream(slurp(filename), filename)
   read-all(eater)

;============================================================
;================== Token Classes ===========================
;============================================================

defstruct Indentation :
   indent:Int
defmethod print (o:OutputStream, i:Indentation) :
   print-all(o, ["[Indentation " indent(i) "]"])

defstruct OpenToken :
   symbol:Symbol
defmethod print (o:OutputStream, t:OpenToken) :
   print-all(o, ["OPEN[" symbol(t) "]"])

defstruct CloseToken :
   symbol:Symbol
defmethod print (o:OutputStream, t:CloseToken) :
   print-all(o, ["CLOSE[" symbol(t) "]"])

defstruct PuncToken :
   symbol:Symbol
defmethod print (o:OutputStream, t:PuncToken) :
   print-all(o, ["PUNC[" symbol(t) "]"])

;============================================================
;================== Lexer State =============================
;============================================================

var LEXEMES: Vector<Token>
var SCOPES: Vector<Symbol>
var ERRORS: Vector<LexerException>
var EATER: StringInputStream
var STAR?: True|False

defn init-lexer (eater:StringInputStream) :
   EATER = eater
   LEXEMES = Vector<Token>()
   SCOPES = Vector<Symbol>()
   ERRORS = Vector<LexerException>()
   STAR? = false

;============================================================
;================= Character Classes ========================
;============================================================

;TODO: Get rid of this once bootstrapped
val TAB-CHAR = to-char(9)
val BACKSPACE-CHAR = to-char(8)
val CARRIAGE-RETURN-CHAR = to-char(13)

val CHAR-CLASSES = CharArray(256, to-char(0))
defn class? (c, bit:Int) -> True|False :
   match(c) :
      (c:Char) :
         val mask = to-int(CHAR-CLASSES[to-int(c as Char)])
         ((mask >> bit) & 1) == 1
      (c) :
         false

defn tag-class (c:Char, bit:Int) :
   val tag = 1 << bit
   val i = to-int(c)
   val mask = to-int(CHAR-CLASSES[i])
   val c2 = to-char(mask | tag)
   CHAR-CLASSES[i] = c2

defn tag-class (class:String, bit:Int) :
   for c in class do :
      tag-class(c, bit)

val DIGIT-CHAR = 0
val ALPHA-CHAR = 1
val PUNC-CHAR = 2
val OPEN-BRACE-CHAR = 3
val CLOSE-BRACE-CHAR = 4
val OPERATOR-CHAR = 5
val SYMBOL-CHAR = 6
val WHITESPACE-CHAR = 7

let :
   val digits = "0123456789"
   val letters = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"   
   tag-class(letters, ALPHA-CHAR)
   tag-class("_?", ALPHA-CHAR)

   tag-class(letters, SYMBOL-CHAR)
   tag-class("_?", SYMBOL-CHAR)
   tag-class("~!@#$%^*+-=/", SYMBOL-CHAR)
   tag-class(digits, SYMBOL-CHAR)

   tag-class("~!@#$%^*+-=/", OPERATOR-CHAR)
   tag-class(".:<&|", OPERATOR-CHAR)
   
   tag-class(digits, DIGIT-CHAR)
   tag-class("`", PUNC-CHAR)
   tag-class("([{<", OPEN-BRACE-CHAR)
   tag-class(")]}>", CLOSE-BRACE-CHAR)

   tag-class(" ,", WHITESPACE-CHAR)
   tag-class(CARRIAGE-RETURN-CHAR, WHITESPACE-CHAR)

;Test if a character is whitespace
defn whitespace? (c) :
   class?(c, WHITESPACE-CHAR)

;Test if a character is a digit
defn digit? (c) :
   class?(c, DIGIT-CHAR)

defn alpha? (c) :
   class?(c, ALPHA-CHAR)

defn punc? (c) :
   class?(c, PUNC-CHAR)

defn open-brace? (c) :
   class?(c, OPEN-BRACE-CHAR)

defn close-brace? (c) :
   class?(c, CLOSE-BRACE-CHAR)

defn number-char? (c) :
   digit?(c) or (c == '.')

defn symbol-char? (c) :
   class?(c, SYMBOL-CHAR)

defn operator-char? (c) :
   if c == '>' :
      empty?(SCOPES) or (peek(SCOPES) != `>)
   else :
      class?(c, OPERATOR-CHAR)

;============================================================
;================= Eating Functions =========================
;============================================================

;Update the brace scope stack.
;Throws an error if improperly matched.
defn update-stack (info:FileInfo, c:Symbol) :
   defn pop-stack () :
      if empty?(SCOPES) :
         throw(ExtraClosingToken(info, c))
      else if peek(SCOPES) != c :
         throw(WrongClosingToken(info, peek(SCOPES), c))
      else :
         pop(SCOPES)

   switch {c == _} :
      `\|<| : add(SCOPES, `\|>|)
      `\|[| : add(SCOPES, `\|]|)
      `\|{| : add(SCOPES, `\|}|)
      `\|(| : add(SCOPES, `\|)|)
      `\|*<| : add(SCOPES, `\|>|)
      `\|*[| : add(SCOPES, `\|]|)
      `\|*{| : add(SCOPES, `\|}|)
      `\|*(| : add(SCOPES, `\|)|)
      `\|>| : pop-stack()
      `\|]| : pop-stack()
      `\|}| : pop-stack()
      `\|)| : pop-stack()

;Update the lexer state with the most recently eaten token
;Adds it to the lexeme buffer, and updates the scope stack and star? status.
defn token-eaten (t:Token) :
   ;Update Lexemes
   add(LEXEMES, t)
   
   ;Update the stack
   match(item(t)) :
      (x:OpenToken) : update-stack(info(t), symbol(x))
      (x:CloseToken) : update-stack(info(t), symbol(x))
      (x) : false

   ;Update STAR?
   STAR? = 
      match(item(t)) :
         (x:CloseToken) : true
         (x:Byte|Char|Int|Long|Float|Double|True|False|String) : true
         (x:Symbol) : any?(alpha?, to-string(x))         
         (x) : false

   ;Returns true, so that it may be used as return expression
   ;in predicates.
   true

;Eat n characters from the input stream
;Returns the eaten characters
defn eat (s:StringInputStream, n:Int) :
   String(repeatedly(next{s}, n))

defn escape-char (c:Char) -> Char :
   switch {c == _} :
      't' : TAB-CHAR
      'b' : BACKSPACE-CHAR
      'r' : CARRIAGE-RETURN-CHAR
      'n' : '\n'
      '\\' : c
      '"' : c
      '\'' : c
      '|' : c
      else : throw(InvalidEscapeChar(info(EATER), c))

defn eat-escaped-chars () :
   val buf = StringBuffer()
   val end-char = peek?(EATER)
   val end = loop(1) where :
      defn* loop (i:Int) :
         val c1 = peek?(EATER, i)
         val c2 = peek?(EATER, i + 1)
         if c1 == false :
            false
         else if c1 == end-char :
            i + 1
         else if c1 == '\\' and c2 != false :
            add(buf, escape-char(c2 as Char))
            loop(i + 2)
         else :
            add(buf, c1 as Char)
            loop(i + 1)
   if end != false :
      eat(EATER, end as Int)
      to-string(buf)

defn eat-comment () -> True|False :
   if peek?(EATER) == ';' :
      while (peek?(EATER) != false and peek?(EATER) != '\n') :
         next(EATER)
      true   

defn eat-string () :
   val info = info(EATER)
   if peek?(EATER) == '"' :
      match(eat-escaped-chars()) :
         (s:String) : token-eaten(Token(s, info))
         (s:False) : throw(UnclosedString(info))

defn eat-char () :
   val info = info(EATER)
   if peek?(EATER) == '\'' :
      match(eat-escaped-chars()) :
         (s:String) :
            if length(s) == 1 : token-eaten(Token(s[0], info))
            else : throw(InvalidCharString(info))
         (s:False) : throw(UnclosedCharString(info))

defn eat-escaped-symbol () :
   val info = info(EATER)
   if peek?(EATER) == '\\' and peek?(EATER, 1) == '|' :
      next(EATER)
      match(eat-escaped-chars()) :
         (s:String) : token-eaten(Token(to-symbol(s), info))
         (s:False) : throw(UnclosedSymbol(info))

;A symbol is a string of SYMBOL characters that contains at
;least one alpha character.
defn eat-symbol () :
   match(symbol-end(0)) :
      (len:Int) :
         val info = info(EATER)
         val str = eat(EATER, len)
         switch {str == _} :
            "true" : token-eaten(Token(true, info))
            "false" : token-eaten(Token(false, info))
            else : token-eaten(Token(to-symbol(str), info))
      (len:False) :
         false

defn symbol-end (start:Int) -> False|Int :
   defn length (a?:True|False, i:Int) :
      if symbol-char?(peek?(EATER,i)) :
         length(a? or alpha?(peek?(EATER,i)), i + 1)
      else if a? :
         i
   length(false, start)      

;An operator is a reluctant string of OPERATOR characters.
defn eat-operator () :
   val len = look-forward(0) where :
      defn* look-forward (i:Int) :
         if operator-char?(peek?(EATER,i)) : look-forward(i + 1)
         else if alpha?(peek?(EATER,i)) : look-back(i - 1)
         else : i
      defn* look-back (i:Int) :
         if symbol-char?(peek?(EATER,i)) : look-back(i - 1)
         else : i + 1
   if len > 0 :
      val info = info(EATER)
      token-eaten(Token(to-symbol(eat(EATER, len)), info))

defn* eat-indent () :
   val info = info(EATER)
   val len = find!({peek?(EATER,_) != ' '}, 0 to false)
   eat(EATER, len)
   val indent = Token(Indentation(len), info)
   if eat-comment() :
      eat-indent()
   else if peek?(EATER) == '\n' :
      next(EATER)
      eat-indent()
   else :
      token-eaten(indent)

defn* number-end (i:Int) -> Int :
   val c = peek?(EATER,i)
   if c == false or open-brace?(c) or close-brace?(c) or whitespace?(c) : i
   else : number-end(i + 1)   

defn eat-number () :
   if digit?(peek?(EATER,0)) or
      (peek?(EATER) == '-' and digit?(peek?(EATER,1))) :      
      val info = info(EATER)
      val str = eat(EATER, number-end(0))
      parse-number(str, info)

defn parse-number (str:String, info:FileInfo) :
   defn try-parse (x) :
      if x == false : throw(InvalidNumber(info))
      else : token-eaten(Token(x, info))
   defn but-last (str:String) :
      str[0 to (length(str) - 1)]
   if contains?(str, '.') :
      if suffix?(str, "f") or suffix?(str, "F") :
         try-parse(to-float(but-last(str)))
      else : try-parse(to-double(str))
   else :
      if suffix?(str, "y") or suffix?(str, "Y") :
         try-parse(to-byte(but-last(str)))      
      else if suffix?(str, "l") or suffix?(str, "L") :
         try-parse(to-long(but-last(str)))
      else : try-parse(to-int(str))

defn eat-here-string () :
   if peek?(EATER) == '\\' and peek?(EATER,1) == '<' :
      val info = info(EATER)      
      next(EATER)
      val tag-len =
         match(find({peek?(EATER,_) == '>'}, 0 to length(EATER))) :
            (i:Int) : i + 1
            (n:False) : throw(InvalidTag(info))
      defn tag? (i:Int) :
         for j in 0 to tag-len all? :
            peek?(EATER, i + j) == peek?(EATER, j)
      val str-len =
         match(find(tag?, tag-len to length(EATER))) :
            (i:Int) : i - tag-len
            (n:False) : throw(NoEndTagFound(info))
      eat(EATER, tag-len)
      val str = eat(EATER, str-len)
      eat(EATER, tag-len)      
      token-eaten(Token(str, info))

defn eat-structural-token () :
   val info = info(EATER)
   if open-brace?(peek?(EATER)) :
      token-eaten(Token(OpenToken(to-symbol(next(EATER))), info))
   else if close-brace?(peek?(EATER)) :
      token-eaten(Token(CloseToken(to-symbol(next(EATER))), info))
   else if punc?(peek?(EATER)) :
      token-eaten(Token(PuncToken(to-symbol(next(EATER))), info))

defn eat-star-token () :
   val info = info(EATER)
   if open-brace?(peek?(EATER)) :
      token-eaten(Token(OpenToken(symbol-join(["*" next(EATER)])), info))

defn eat-capture () :   
   if (peek?(EATER) == '?') :
      match(symbol-end(1)) :
         (end:Int) :
            val pinfo = info(EATER)
            token-eaten(Token(PuncToken(to-symbol(next(EATER))), pinfo))            
            val info = info(EATER)
            token-eaten(Token(to-symbol(eat(EATER, end - 1)), info))            
         (end:False) :
            false

defn eat-lexeme! () :
   val ate? =
      eat-capture() or
      eat-here-string() or
      eat-escaped-symbol() or
      eat-char() or
      eat-string() or
      eat-number() or
      eat-symbol() or
      eat-operator() or
      eat-structural-token()
   if ate? :
      eat-star-token() when STAR?
   else : throw(InvalidToken(info(EATER)))

defn eat-whitespace () :
   if whitespace?(peek?(EATER)) :
      while whitespace?(peek?(EATER)) :
         next(EATER)
      STAR? = false      
      
defn eat-lexeme () :
   eat-whitespace()
   if peek?(EATER) != false :
      if eat-comment() :
         eat-lexeme()
      else if peek?(EATER) == '\n' :
         next(EATER)
         eat-indent()
      else :
         eat-lexeme!()

defn eat-all () :
   while peek?(EATER) != false :
      eat-lexeme()
      
;============================================================
;===================== Grouping =============================
;============================================================

val OPEN-PAREN = `\|(|
val STAR-PAREN = `\|*(|
val CLOSE-PAREN = `\|)| 
val OPEN-BRACKET = `\|{|
val STAR-BRACKET = `\|*{|
val CLOSE-BRACKET = `\|}|
val OPEN-BRACE = `\|[|
val STAR-BRACE = `\|*[|
val CLOSE-BRACE = `\|]|
val STAR-ANGLE = `\|*<|
val CLOSE-ANGLE = `\|>|
val COLON = `:
val QUESTION = `?
val BACKTICK = `\|`|

defn matching-end (s:Symbol) :
   if s == OPEN-PAREN : CLOSE-PAREN
   else if s == STAR-PAREN : CLOSE-PAREN
   else if s == OPEN-BRACKET : CLOSE-BRACKET
   else if s == STAR-BRACKET : CLOSE-BRACKET
   else if s == OPEN-BRACE : CLOSE-BRACE
   else if s == STAR-BRACE : CLOSE-BRACE
   else if s == STAR-ANGLE : CLOSE-ANGLE
   else : fatal("No matching end")

var START-INFO = false
var TOKEN-STREAM : Vector<Token>
defn group-all () -> List :
   TOKEN-STREAM = Vector<Token>(length(LEXEMES))
   while not empty?(LEXEMES) :
      add(TOKEN-STREAM, pop(LEXEMES))
   group-rest(false)

defn group-rest (end) -> List :
   if empty?(TOKEN-STREAM) :
      match(end) :
         (end:Symbol) :
            throw(NoClosingToken(START-INFO as FileInfo, end))
         (end) :
            List()
   else :
      val x = peek(TOKEN-STREAM)
      match(item(x)) :
         (t:CloseToken) :
            match(end) :
               (end:Symbol) :
                  pop(TOKEN-STREAM)
                  List()
               (end:Indentation) :
                  List()
         (t:OpenToken) :
            pop(TOKEN-STREAM)
            val g = let-var START-INFO = info(x) :
               group-rest(matching-end(symbol(t)))
            cons(cons(x, g), group-rest(end))
         (t:PuncToken) :
            pop(TOKEN-STREAM)
            cons(x, group-rest(end))
         (s:Symbol) :
            pop(TOKEN-STREAM)
            if s == COLON :
               match(item(peek(TOKEN-STREAM))) :
                  (i:Indentation) :
                     val y = pop(TOKEN-STREAM)
                     val g = group-rest(i)
                     cons(x, cons(y, g), group-rest(end))
                  (t) :
                     cons(x, group-rest(end))
            else :
               cons(x, group-rest(end))
         (i:Indentation) :
            if (end typeof Indentation) and
               (indent(i) < indent(end as Indentation)) :
               List()
            else :
               pop(TOKEN-STREAM)
               group-rest(end)
         (t) :
            pop(TOKEN-STREAM)
            cons(x, group-rest(end))


;============================================================
;===================== Shorthands ===========================
;============================================================

defn indentation? (x) :
   unwrap-token(x) typeof Indentation
defn opentoken? (x, s:Symbol) :
   match(unwrap-token(x)) :
      (x:OpenToken) : symbol(x) == s
      (x) : false
defn opentoken? (x, s:Seqable<Symbol>) :
   match(unwrap-token(x)) :
      (x:OpenToken) : contains?(s, symbol(x))
      (x) : false
defn punctoken? (x, s:Symbol) :
   match(unwrap-token(x)) :
      (x:PuncToken) : symbol(x) == s
      (x) : false
defn startoken-pending? (xs:List) :
   if not empty?(xs) :
      match(head(xs)) :
         (x:FullList) : opentoken?(head(x), [STAR-PAREN, STAR-BRACE, STAR-BRACKET, STAR-ANGLE])
         (x) : false

defn lex-atom (x) -> ? :
   match(x) :
      (x:Token) :
         Token(lex-atom(item(x)), info(x))
      (x:FullList) :
         if indentation?(head(x)) : lex-all(tail(x))
         else if opentoken?(head(x), OPEN-PAREN) : lex-all(tail(x))
         else if opentoken?(head(x), OPEN-BRACE) : cons(`@tuple, lex-all(tail(x)))
         else if opentoken?(head(x), OPEN-BRACKET) : cons(`@afn, lex-all(tail(x)))
         else if opentoken?(head(x), STAR-PAREN) : cons(`@do, lex-all(tail(x)))
         else if opentoken?(head(x), STAR-BRACE) : cons(`@get, lex-all(tail(x)))
         else if opentoken?(head(x), STAR-BRACKET) : cons(`@do-afn, lex-all(tail(x)))
         else if opentoken?(head(x), STAR-ANGLE) : cons(`@of, lex-all(tail(x)))
         else : fatal("Invalid grouped form: %_" % [x])
      (x) : x

defn lex-all (xs:List) -> List :
   if empty?(xs) :
      xs
   else if punctoken?(head(xs), QUESTION) :
      val capped = List(OpenToken(`\|(|), `@cap, xs[1])
      lex-all(cons(capped, tailn(xs, 2)))
   else if punctoken?(head(xs), BACKTICK) :
      if empty?(tail(xs)) :
         `(@quote)
      else :
         val rest = lex-all(tail(xs))
         cons(List(`@quote, head(rest)), tail(rest))
   else :
      cons(lex-atom(head(xs)), lex-all(tail(xs)))


;============================================================
;=================== Lexer Errors ===========================
;============================================================

deftype LexerException <: Exception
defn LexerException (s:String) :
   new LexerException :
      defmethod print (o:OutputStream, this) :
         print(o, s)

defn LexerExceptions (xs:Seqable<LexerException>) :
   LexerException(string-join(xs, "\n"))

defn NoClosingToken (info:FileInfo, end:Symbol) :
   LexerException $ string-join $
   [info ": No closing token found. Expecting " end "."]

defn InvalidNumber (info:FileInfo) :
   LexerException $ string-join $
   [info ": Invalid number."]

defn InvalidToken (info:FileInfo) :
   LexerException $ string-join $
   [info ": Invalid token."]

defn InvalidEscapeChar (info:FileInfo, c:Char) :
   LexerException $ string-join $
   [info ": Invalid escape character: " c "."]

defn UnclosedString (info:FileInfo) :
   LexerException $ string-join $
   [info ": Unclosed string. "]

defn UnclosedCharString (info:FileInfo) :
   LexerException $ string-join $
   [info ": Unclosed character. "]

defn UnclosedSymbol (info:FileInfo) :
   LexerException $ string-join $
   [info ": Unclosed symbol. "]

defn InvalidCharString (info:FileInfo) :
   LexerException $ string-join $
   [info ": Invalid character string. Must have length 1."]

defn WrongClosingToken (info:FileInfo, expected:Symbol, actual:Symbol) :
   LexerException $ string-join $
   [info ": Wrong closing parenthesis. Expecting " expected " but got " actual "."]

defn ExtraClosingToken (info:FileInfo, c:Symbol) :
   LexerException $ string-join $
   [info ": Extra closing token found: " c "."]

defn InvalidTag (info:FileInfo) :
   LexerException $ string-join $
   [info ": Invalid tag for here string."]

defn NoEndTagFound (info:FileInfo) :
   LexerException $ string-join $
   [info ": No ending tag found for here string."]