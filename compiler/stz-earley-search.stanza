defpackage stz/earley-search :
  import core
  import collections
  import stz/earley-eitems
  import stz/earley-grammar
  import stz/earley-sexp-stream
  import stz/earley-errors

;============================================================
;======================= ESet ===============================
;============================================================

public deftype ESet <: Collection<EItem>
defmulti start-completed? (s:ESet) -> True|False
defmulti scanned-atomic-any? (s:ESet) -> True|False
defmulti scanned-non-reluctant? (s:ESet) -> True|False
defmulti scanned-non-reluctant-list-start? (s:ESet) -> True|False
defmulti scanned-rest? (s:ESet) -> True|False
defmulti wildcard-expected? (s:ESet) -> True|False
defmulti list-expected? (s:ESet) -> True|False
defmulti list-end-expected? (s:ESet) -> True|False
defmulti add (s:ESet, item:EItem) -> False
defmulti clear (s:ESet, length:Int) -> False
defmulti length (s:ESet) -> Int
defmulti get (s:ESet, i:Int) -> EItem
defmulti map! (f:EItem -> EItem, s:ESet) -> False
defmulti remove! (f:EItem -> True|False, s:ESet) -> False

defn ESet (grammar:Grammar) :
  ;Starting rule
  val start-rule = next(to-seq(rules(grammar,0)))
  
  ;Accumulate items
  val items = Vector<EItem>()

  ;Track flags
  var start-completed?:True|False
  var scanned-atomic-any?:True|False
  var scanned-non-reluctant?:True|False
  var scanned-non-reluctant-list-start?:True|False
  var scanned-rest?:True|False
  var wildcard-expected?: True|False
  var list-expected?: True|False
  var list-end-expected?: True|False

  defn recompute-flags () :
    start-completed? = false
    scanned-atomic-any? = false
    scanned-non-reluctant? = false
    scanned-non-reluctant-list-start? = false
    scanned-rest? = false
    wildcard-expected? = false
    list-expected? = false
    list-end-expected? = false
    do(process-flags, items)

  defn process-flags (item:EItem) :
    ;Set flags for what was scanned.
    val prev-item = previous(item)
    match(prev-item) :
      (t:GAny) :
        if type(t) is Atomic : scanned-atomic-any? = true
      (t:GListStart) :
        if not reluctant?(t) :
          scanned-non-reluctant-list-start? = true
      (t:GListRest) :
        scanned-rest? = true
      (t) :
        false

    ;Process scanned non-reluctant flag
    if non-reluctant-terminal?(prev-item) :
      scanned-non-reluctant? = true

    ;Set flags for what is upcoming
    match(upcoming(item)) :
      (t:GListStart) :
        list-expected? = true
      (t:GListEnd) :
        list-end-expected? = true
      (t:GTerminal) :
        wildcard-expected? = true
      (t:False) :
        if rule-id(item) == start-rule : start-completed? = true
      (t) :
        false

  recompute-flags()
  new ESet :
    ;===== Set Operations =====
    defmethod clear (this, l:Int) :
      shorten(items, l)
      recompute-flags()
    defmethod add (this, item:EItem) :
      add(items, item)
      process-flags(item)
    defmethod get (this, i:Int) : items[i]
    defmethod length (this) : length(items)
    defmethod to-seq (this) : to-seq(items)
    ;===== Compute =====
    defmethod map! (f:EItem -> EItem, this) :
      map!(f, items)
    defmethod remove! (f:EItem -> True|False, this) :
      remove-when(f, items)
      recompute-flags()
    ;===== Retrieve Flags =====
    defmethod start-completed? (this) : start-completed?
    defmethod scanned-atomic-any? (this) : scanned-atomic-any?
    defmethod scanned-non-reluctant? (this) : scanned-non-reluctant?
    defmethod scanned-non-reluctant-list-start? (this) : scanned-non-reluctant-list-start?
    defmethod scanned-rest? (this) : scanned-rest?
    defmethod wildcard-expected? (this) : wildcard-expected?
    defmethod list-expected? (this) : list-expected?
    defmethod list-end-expected? (this) : list-end-expected?

defmethod do (f:EItem -> ?, eset:ESet) :
  val item-index = to-seq(0 to false)
  while peek(item-index) < length(eset) :
    f(eset[next(item-index)])

defn empty? (s:ESet) :
  length(s) == 0

defn print-current-set (grammar:Grammar, set-index:Int, current-set:Seqable<EItem>) :
  println("Set %_" % [set-index])
  within indented() :
    do(println{format(grammar,_)}, current-set)

;============================================================
;============= Classification of Terminals ==================
;============================================================

;Returns true if the given terminal is a reluctant terminal.
defn reluctant-terminal? (t:GTerminal) :
  match(t) :
    (t:GListStart) : reluctant?(t)
    (t:GAny) : type(t) is Reluctant
    (t:GListRest) : true
    (t) : false

;Returns true if the given token is a non-reluctant terminal.
defn non-reluctant-terminal? (t:GToken|False) :
  match(t:GTerminal) : not reluctant-terminal?(t)
  else : false

;============================================================
;=================== Search Result ==========================
;============================================================

public deftype SearchResult

public defstruct SearchSuccess <: SearchResult :
  inputlist: Vector<SExpToken>
  infolist: Vector<FileInfo|False>

public defstruct SearchFailure <: SearchResult :
  missing: Tuple<MissingInput>

;============================================================
;==================== Search Progress =======================
;============================================================

public deftype SearchProgress
public defmulti completed-set (progress:SearchProgress, index:Int, eset:ESet) -> False
public defmulti completed-all-sets (progress:SearchProgress) -> False

;============================================================
;====================== Algorithm ===========================
;============================================================

public defn search (progress:SearchProgress, grammar:Grammar, input:List) -> SearchResult :
  val input-stream = SExpStream(input)
  val setlist = ESetList()
  val prediction-set = ProductionSet(num-productions(grammar))
  val advance-table = HashTable<EItemCore,EItem>()
  val production-count = ProductionTable<Int>(num-productions(grammar), 0)
  val inputlist = Vector<SExpToken>()
  val infolist = Vector<FileInfo|False>()
  val missing = Vector<MissingInput>()

  val process-set-timer = MillisecondTimer("Process Set")
  val prune-conditional-matches-timer = MillisecondTimer("Prune conditional matches")
  val add-setlist-timer = MillisecondTimer("Add to setlist")
  val compute-completion-root-timer = MillisecondTimer("Compute completion root")

  defn advance (item:EItem, wildcard?:True|False) :
    match(get?(advance-table, core(item))) :
      (x:EItem) :
        [x, false]
      (f:False) :
        val item* = inc-num-parsed(item, wildcard?)
        advance-table[core(item)] = item*
        [item*, true]

  ;Advances items in current-set and puts them in next-set.
  defn process-set (set-index:Int,
                    current-set:ESet,
                    next-set:ESet,
                    next-input:SExpToken,
                    include-all-rules?:True|False) :
    start(process-set-timer)
    ;Clear state
    clear-markers(setlist)
    clear(prediction-set)
    clear(advance-table)

    ;Iterate through each item
    for item in current-set do :
      dispatch(item) where :
        defn* dispatch (item:EItem) :
          ;Dispatch
          match(upcoming(item)) :
            (t:GTerminal) : upcoming-terminal(item, t)
            (p:GProduction) : upcoming-production(item, p)
            (f:False) : end-of-rule(item)
;        defn add-completion (item:EItem) :
;          add(current-set, item) when add(completion-set, item)
        defn upcoming-terminal (item:EItem, t:GTerminal) :
          if matches-input?(grammar, t, next-input) :
            val [item*, new?] = advance(item, next-input is SExpWildcard)
            add(next-set, item*)
        defn upcoming-production (item:EItem, t:GProduction) :
          if nullable?(grammar, id(t)) :
            val [item*, new?] = advance(item, false)
            add(current-set, item*) when new?
          if add(prediction-set, id(t)) :
            val rule-ids = rules(grammar, id(t)) when include-all-rules?
                   else rules-with-prefix(grammar, id(t), next-input)
            val items = seq(EItem{grammar[_], 0, set-index, false}, rule-ids)
            do(add{current-set, _}, items)              
        defn end-of-rule (completed-item:EItem) :
          val prod = production(completed-item)
          val prod-start = parent(completed-item)

          ;Add new advanced items
          if prod-start < set-index :
            within item = items(setlist, prod-start, prod, true) :
              ;Determine whether right-recursive chain
              match(completion-root(item)) :
                (croot:ChainLink) :
                  ;Compute advance of root.
                  val [root*, new?] = advance(root(croot), matched-wildcard?(completed-item))
                  val [_, new-start?] = advance(item, false)
                  add-chain-completion(root*, item) when new-start?
                  add(current-set, root*) when new?
                (croot) :
                  ;Compute advance of item.
                  val [item*, new?] = advance(item, matched-wildcard?(completed-item))
                  add(current-set, item*) when new?

    stop(process-set-timer)

  ;Remove any conditional matches in the given set to handle
  ;reluctant matching algorithm.
  ;Returns true if the matched terminals implies the input stream
  ;should be expanded.
  defn prune-conditional-matches (eset:ESet, input:SExpToken) -> True|False :
    start(prune-conditional-matches-timer)
    ;Compute expansion condition
    val expand? = scanned-non-reluctant-list-start?(eset)
              and not scanned-atomic-any?(eset)
    ;Remove items
    for item in eset remove! :
      match(previous(item)) :
        (t:GListStart) : not expand?
        (t:GAny) :
          if type(t) is Reluctant : expand? or not scanned-non-reluctant?(eset)
          else : expand?
        (t:GListRest) : scanned-non-reluctant?(eset)
        (t) : false
    ;Return list expansion
    stop(prune-conditional-matches-timer)
    expand?

  ;Compute completion-roots of all deterministic reductions
  ;for last set in the setlist.
  defn compute-completion-root (current-set:ESet) :
    start(compute-completion-root-timer)
    ;Compute count table
    clear(production-count)
    for item in current-set do :
      val t = upcoming(item)
      match(t:GProduction) :
        production-count[id(t)] = production-count[id(t)] + 1
    ;Determine whether deterministic reduction
    defn deterministic-reduction? (item:EItem) :
      val num-tokens = length(tokens(rule(item)))
      if num-parsed(item) == num-tokens - 1 :
        val t = upcoming(item)
        match(t:GProduction) : production-count[id(t)] == 1

    ;Compute completion
    defn complete (item:EItem) -> CompletionRoot :
      val pitem = first-item(setlist, parent(item), production(item)) as EItem
      match(completion-root(pitem)) :
        (r:ChainRoot) : ChainLink(pitem, pitem)
        (r:ChainLink) : ChainLink(root(r), pitem)
        (r:NoCompletion) : ChainRoot()
    ;Compute completions of all deterministic reductions.
    for item in current-set do :
      if deterministic-reduction?(item) :
        set-completion-root(item, complete(item))
    stop(compute-completion-root-timer)

  defn commit-set (set-index:Int, eset:ESet) :
    defn remember? (x:EItem) : upcoming(x) is GProduction
    add(setlist, filter(remember?, eset))
    for item in eset do :
      val num-tokens = length(tokens(rule(item)))
      val np = num-parsed(item)
      if np > 0 and np <= num-tokens - 1 :
        ends(item)[np - 1] = cons(set-index, ends(item)[np - 1])
    compute-completion-root(eset)

  defn remembered-items (eset:ESet) -> Seqable<EItem> :
    for item in eset filter :
      upcoming(item) is GProduction

  defn process-all-sets () :
    ;Initialize current-set and next-set.
    val current-set = ESet(grammar)
    val next-set = ESet(grammar)
    val starting-rule = next(to-seq(rules(grammar,0)))
    add(current-set, EItem(grammar[starting-rule], 0, 0, false))

    ;Process sets until finished.
    let loop (set-index:Int = 0,
              current-set:ESet = current-set,
              next-set:ESet = next-set) :
      val next-input = peek(input-stream)
      val num-scanned = length(current-set)
      process-set(set-index, current-set, next-set, next-input, false)
      val expand-list? = prune-conditional-matches(next-set, next-input)

      ;Dispatch to different cases
      defn* dispatch () :
        if empty?(next-set) :
          if start-completed?(current-set) : finished-parse()
          else : unexpected-input()
        else if scanned-rest?(next-set) :
          advance-to-next-set(true)
        else :
          advance-to-next-set(false)

      defn* finished-parse () :
        ;Complete and report completion
        commit-set(set-index, current-set)
        completed-set(progress, set-index, current-set)
        completed-all-sets(progress)

      defn* advance-to-next-set (advance-rest?:True|False) :
        ;Record the current set
        ;Add matched input
        add(inputlist, next-input)
        add(infolist, info(input-stream))

        ;Compute the completion root and add to the setlist
        ;Add to setlist
        start(add-setlist-timer)
        commit-set(set-index, current-set)
        stop(add-setlist-timer)

        ;Debug
        ;print-current-set(grammar, set-index, current-set)

        ;Report completion
        completed-set(progress, set-index, current-set)

        ;Advance either to the end of the list, or by one token
        if advance-rest? : advance-rest(input-stream)
        else : /advance(input-stream, expand-list?)

        ;Scan the next set
        clear(current-set, 0)
        loop(set-index + 1, next-set, current-set)

      defn* unexpected-input () :
        ;Compute the complete current set without using look-ahead prediction.
        clear(current-set, num-scanned)
        process-set(set-index, current-set, next-set, next-input, true)

        ;Record context of missing input
        add(missing, MissingInput(next-input, set-index, info(input-stream), to-tuple(current-set)))

        ;Perform error recovery
        if list-end-expected?(current-set) : /advance(input-stream, false)
        else if wildcard-expected?(current-set) : insert-wildcard(input-stream)
        else if list-expected?(current-set) : insert-list(input-stream)
        else : fatal("Unrecoverable")

        ;Scan current set again now with additional inserted tokens.
        clear(current-set, num-scanned)
        loop(set-index, current-set, next-set)

      ;Launch
      dispatch()

  ;Launch!
  defn main () :
    process-all-sets()
    println("PROCESSED SETS: %_" % [stz/earley-eitems/MAIN-TIMER])
    println(process-set-timer)
    println(prune-conditional-matches-timer)
    println(add-setlist-timer)
    println(compute-completion-root-timer)

    if empty?(missing) :
      SearchSuccess(inputlist, infolist)
    else :
      SearchFailure(to-tuple(missing))

  main()