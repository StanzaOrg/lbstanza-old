defpackage stz/earley-search :
  import core
  import collections
  import stz/earley-eitems
  import stz/earley-grammar
  import stz/earley-sexp-stream
  import stz/earley-errors
  import stz/tree-list

;============================================================
;======================= ESet ===============================
;============================================================
public deftype ESet <: Collection<EItem>

;===== Basic Functions =====
defmulti add (s:ESet, item:EItem) -> False
defmulti clear (s:ESet, length:Int) -> False
defmulti length (s:ESet) -> Int

;===== Functions for Testing for Completion =====
defmulti start-completed? (s:ESet) -> True|False

;===== Functions for Reluctant Matching System =====
defmulti scanned-atomic-any? (s:ESet) -> True|False
defmulti scanned-non-reluctant? (s:ESet) -> True|False
defmulti scanned-non-reluctant-list-start? (s:ESet) -> True|False
defmulti scanned-rest? (s:ESet) -> True|False
defmulti remove! (f:EItem -> True|False, s:ESet) -> False

;===== Functions for Error Recovery System =====
defmulti wildcard-expected? (s:ESet) -> True|False
defmulti list-expected? (s:ESet) -> True|False
defmulti list-end-expected? (s:ESet) -> True|False

;===== Constructor =====
defn ESet (grammar:Grammar) :
  ;Accumulate items
  val items = Vector<EItem>()

  ;Track flags
  var start-completed?:True|False
  var scanned-atomic-any?:True|False
  var scanned-non-reluctant?:True|False
  var scanned-non-reluctant-list-start?:True|False
  var scanned-rest?:True|False
  var wildcard-expected?: True|False
  var list-expected?: True|False
  var list-end-expected?: True|False

  ;Reset and compute flags
  defn recompute-flags () :
    #for flag in [start-completed?,
                  scanned-atomic-any?,
                  scanned-non-reluctant?,
                  scanned-non-reluctant-list-start?,
                  scanned-rest?,
                  wildcard-expected?,
                  list-expected?,
                  list-end-expected?] :
      flag = false
    do(process-flags, items)

  ;Update the flag based upon adding the given item.
  defn process-flags (item:EItem) :
    ;Set Reluctance Matching Flags
    ;Set flags for what was scanned.
    val prev-item = previous(item)
    match(prev-item) :
      (t:GAny) :
        if type(t) is Atomic :
          scanned-atomic-any? = true
      (t:GListStart) :
        if not reluctant?(t) :
          scanned-non-reluctant-list-start? = true
      (t:GListRest) :
        scanned-rest? = true
      (t) :
        false

    ;Process scanned non-reluctant flag
    if non-reluctant-terminal?(prev-item) :
      scanned-non-reluctant? = true

    ;Set Error Recovery and Completion Flags
    match(upcoming(item)) :
      (t:GListStart) :
        list-expected? = true
      (t:GListEnd) :
        list-end-expected? = true
      (t:GTerminal) :
        wildcard-expected? = true
      (t:False) :
        if prod(rule(item)) == 0 :
          start-completed? = true
      (t) :
        false

  ;Initialize flags and create datastructure
  recompute-flags()
  new ESet :
    ;===== Basic Functions =====
    defmethod add (this, item:EItem) :
      add(items, item)
      process-flags(item)
    defmethod clear (this, l:Int) :
      shorten(items, l)
      recompute-flags()
    defmethod length (this) :
      length(items)

    ;===== Functions for Testing for Completion =====
    defmethod start-completed? (this) : start-completed?

    ;===== Functions for Reluctant Matching System =====
    defmethod scanned-atomic-any? (this) : scanned-atomic-any?
    defmethod scanned-non-reluctant? (this) : scanned-non-reluctant?
    defmethod scanned-non-reluctant-list-start? (this) : scanned-non-reluctant-list-start?
    defmethod scanned-rest? (this) : scanned-rest?
    defmethod remove! (f:EItem -> True|False, this) :
      remove-when(f, items)
      recompute-flags()

    ;===== Functions for Error Recovery System =====
    defmethod wildcard-expected? (this) : wildcard-expected?
    defmethod list-expected? (this) : list-expected?
    defmethod list-end-expected? (this) : list-end-expected?

    ;===== Collection Operations =====
    defmethod to-seq (this) : to-seq(items)

    ;===== Iteration =====
    defmethod do (f:EItem -> ?, this) :
      val item-index = to-seq(0 to false)
      while peek(item-index) < length(this) :
        f(items[next(item-index)])

;Returns true if 's' contains no items.
defn empty? (s:ESet) -> True|False :
  length(s) == 0

;Diagnostic printing facility.
defn print-current-set (grammar:Grammar, set-index:Int, current-set:Seqable<EItem>) :
  println("Set %_" % [set-index])
  within indented() :
    do(println{format(grammar,_)}, current-set)

;============================================================
;============= Reluctant Matching System ====================
;============================================================
;+[earley reluctant matching algorithm]

;Returns true if the given terminal is a reluctant terminal.
defn reluctant-terminal? (t:GTerminal) -> True|False :
  match(t) :
    (t:GListStart) : reluctant?(t)
    (t:GAny) : type(t) is Reluctant
    (t:GListRest) : true
    (t) : false

;Returns true if the given token is a non-reluctant terminal.
defn non-reluctant-terminal? (t:GToken|False) -> True|False :
  match(t:GTerminal) : not reluctant-terminal?(t)
  else : false

;Remove any conditional matches in the given set to handle reluctant
;matching algorithm. Returns true if the matched terminals implies the
;input stream should be expanded.
defn prune-conditional-matches (eset:ESet) -> True|False :
  ;Compute expansion condition
  val expand? = scanned-non-reluctant-list-start?(eset)
            and not scanned-atomic-any?(eset)
  ;Remove items
  for item in eset remove! :
    match(previous(item)) :
      (t:GListStart) :
        not expand?
      (t:GAny) :
        if type(t) is Reluctant :
          expand? or not scanned-non-reluctant?(eset)
        else :
          expand?
      (t:GListRest) :
        scanned-non-reluctant?(eset)
      (t) :
        false
  ;Return list expansion
  expand?

;/[earley reluctant matching algorithm]

;============================================================
;=================== Search Result ==========================
;============================================================
;+[earley search result]

public deftype SearchResult

;If the search succeeds, then the algorithm returns a SearchSuccess object.
;- items stores the completed EItem objects.
;- terminal-set stores the terminals that match at each position in the input stream.
;- inputlist stores the final list of tokens in the input stream.
;- infolist stores the computed file information in the input stream.
public defstruct SearchSuccess <: SearchResult :
  items: ECompletionList
  terminal-set: TerminalSet
  inputlist: Vector<SExpToken>
  infolist: Vector<FileInfo|False>

;If the search fails, then the algorithm returns a SearchFailure object.
;- missing stores the context for each problem in the input stream.
public defstruct SearchFailure <: SearchResult :
  missing: Tuple<MissingInput>

;/[earley search result]

;============================================================
;===================== Terminal Set =========================
;============================================================
;+[earley terminal set definition]

public deftype TerminalSet

;Returns true if the terminal 'terminal' was matched at index 'index'
;in the input stream.
public defmulti get (s:TerminalSet, index:Int, terminal:GTerminal) -> True|False

;Adds a new match to the set. It indicates that the terminal
;'terminal' successfully matched at index 'index' in the input stream.
defmulti add (s:TerminalSet, index:Int, terminal:GTerminal) -> False

;Create a new TerminalSet given the grammar and inputlist.
defn TerminalSet (grammar:Grammar, inputlist:Vector<SExpToken>) :
  val tset = HashSet<ParsedTerminal>()
  new TerminalSet :
    defmethod add (this, index:Int, term:GTerminal) :
      if save-terminal-match?(term) :
        add(tset, ParsedTerminal(term,index))
      false
    defmethod get (this, index:Int, term:GTerminal) :
      if save-terminal-match?(term) :
        tset[ParsedTerminal(term,index)]
      else :
        matches-input?(grammar, term, inputlist[index])

;Returns true if the given terminal is of a type where we should
;not recalculate whether it matches a given input. If it returns
;false, then it is safe to recalculate.
defn save-terminal-match? (t:GTerminal) -> True|False :
  t is GMatcherToken|GAny|GListStart|GListRest

;Represents a parsed terminal at a given position in the input list.
defstruct ParsedTerminal <: Hashable & Equalable :
  terminal: GTerminal
  position: Int
with:
  printer => true

defmethod hash (p:ParsedTerminal) :
  111 * hash(terminal(p)) + 131 * position(p)

defmethod equal? (a:ParsedTerminal, b:ParsedTerminal) :
  terminal(a) == terminal(b) and position(a) == position(b)

;/[earley terminal set definition]

;============================================================
;====================== Algorithm ===========================
;============================================================

public defn search (grammar:Grammar, input:List) -> SearchResult :
  ;+[earley search algorithm state]
  ;Input stream of tokens
  val input-stream = SExpStream(input)

  ;Collection of all earley sets
  val setlist = ESetList()

  ;Collected errors
  val missing = Vector<MissingInput>()

  ;Collect parsed items and terminals
  val completion-list = ECompletionList()
  val terminal-set = TerminalSet(grammar, inputlist(input-stream))
  ;/[earley search algorithm state]

  ;Timers for debugging
  val process-set-timer = MillisecondTimer("Process Set")
  val prune-conditional-matches-timer = MillisecondTimer("Prune conditional matches")
  val add-setlist-timer = MillisecondTimer("Add to setlist")
  val compute-completion-root-timer = MillisecondTimer("Compute completion root")

  ;Utility: Creating Starting EItems
  val empty-tree-list = TreeList()
  val empty-tree-list-array = Array<TreeList>(0)
  defn make-eitem (rule:GTokenRule, start:Int) -> EItem :
    val num-tokens = length(tokens(rule))
    val len = max(0, num-tokens - 1)
    val ends = empty-tree-list-array when len == 0
          else Array<TreeList>(len, empty-tree-list)
    EItem(rule, 0, start, false, ends)

  ;Utility: Memoized advancing of an EItem
  ;An entry core => item, means that an item with core 'core' has
  ;already been advanced in the current Earley set, and 'item' is the advanced
  ;version.
  val advance-table = HashTable<EItemCore,EItem>()
  defn advance-memoized (item:EItem, error?:True|False) -> [EItem, True|False] :
    match(get?(advance-table, core(item))) :
      (x:EItem) :
        [x, false]
      (f:False) :
        val item* = inc-num-parsed(item, error?)
        advance-table[core(item)] = item*
        [item*, true]

  ;Holds the productions that have been already been used
  ;to generate predicted EItems.
  ;An entry P indicates that EItems for production P have already been
  ;predicted in the Earley set.
  ;Used by process-set.
  val prediction-set = ProductionSet(num-productions(grammar))

  ;Process the current Earley set, and add scanned item to the next Earley set.
  ;- set-index is the index of the Earley set.
  ;- current-set is the current Earley set to process.
  ;- next-set is the next Earley set to add scanned items.
  ;- next-input is the upcoming input token.
  ;- include-all-rules? is true if prediction should include all possible rules
  ;  for a given production. If false, prediction should use look-ahead to include
  ;  only rules with matching first-sets.
  ;- error-recovery? is true if process-set is being ran after performing error recovery,
  ;  and thus any scanned items should be tagged as containing errors.
  defn process-set (set-index:Int,
                    current-set:ESet,
                    next-set:ESet,
                    next-input:SExpToken,
                    include-all-rules?:True|False,
                    error-recovery?:True|False) -> False :
    start(process-set-timer)

    ;Clear state
    defn clear-state () :
      clear-markers(setlist)
      clear(prediction-set)
      clear(advance-table)

    ;Process the given item
    defn process-item (item:EItem) :
      ;Dispatch
      match(upcoming(item)) :
        (t:GTerminal) : upcoming-terminal(item, t)
        (p:GProduction) : upcoming-production(item, p)
        (f:False) : end-of-rule(item) when parent(item) < set-index

    ;The item 'item' expects terminal 't'.
    defn upcoming-terminal (item:EItem, t:GTerminal) :
      ;If the terminal matches the upcoming input, then
      ;advance the item and add to the next set.
      if matches-input?(grammar, t, next-input) :
        val [item*, new?] = advance-memoized(item, error-recovery?)
        add(next-set, item*)

    ;The item 'item' expects production 't'.
    defn upcoming-production (item:EItem, t:GProduction) :
      ;If the production is nullable, then perform a null-advance.
      if nullable?(grammar, id(t)) :
        val [item*, new?] = advance-memoized(item, false)
        add(current-set, item*) when new?
      ;If we haven't already predicted rule for the production
      ;then add predicted rules to the current set.
      if add(prediction-set, id(t)) :
        val rule-ids = rules(grammar, id(t)) when include-all-rules?
                  else rules-with-prefix(grammar, id(t), next-input)
        for id in rule-ids do :
          add(current-set, make-eitem(grammar[id], set-index))

    ;The item 'completed-item' is finished parsing,
    ;and it is not a null-completion.
    defn end-of-rule (completed-item:EItem) :
      ;Get production and start position of item.
      val prod = production(completed-item)
      val prod-start = parent(completed-item)

      ;Unless we have already done so,
      ;retrieve all items in the set indexed 'prod-start' with
      ;upcoming production 'prod'.
      within item = items(setlist, prod-start, prod, true) :
        ;Determine whether right-recursive chain. If it is, then we
        ;advance the root of the chain instead of item.
        match(completion-root(item)) :
          (croot:ChainLink) :
            ;Compute advance of root and add to current set.
            val [root*, new?] = advance-memoized(root(croot), matched-wildcard?(completed-item))
            add(current-set, root*) when new?
            ;Add item as a new completion for the advanced root, unless already done so.
            ;Use the advance-table to track whether we've added this completion before.
            val [_, new-completion?] = advance-memoized(item, false)
            add-chain-completion(root*, item) when new-completion?
          (croot) :
            ;Compute advance of item and add to curren set.
            val [item*, new?] = advance-memoized(item, matched-wildcard?(completed-item))
            add(current-set, item*) when new?

    ;Launch by processing every item
    clear-state()
    do(process-item, current-set)
    stop(process-set-timer)

  ;Holds the number of items that have given upcoming productions.
  ;An entry P => N indicates that there are N items with upcoming production P.
  ;Used by commit-set.
  val production-count = ProductionTable<Int>(num-productions(grammar), 0)

  ;Commit the set 'eset' to the algorithm state. Does the following
  ;things.
  ;- Adds items to the setlist.
  ;- Adds items to the completion list.
  ;- Adds scanned terminals to the terminal set.
  ;- Records new ends to items.
  ;- Computes the completion roots for items.
  defn commit-set (set-index:Int, eset:ESet) -> False :
    ;Add items with upcoming productions to set list.
    defn add-items-to-setlist () :      
      defn upcoming-prod? (x:EItem) : upcoming(x) is GProduction
      add(setlist, filter(upcoming-prod?, eset))

    ;Add complete items to completion list.
    defn add-items-to-completion-list () :
      defn complete? (x:EItem) : upcoming(x) is False
      add(completion-list, set-index, filter(complete?, eset))

    ;Add scanned terminals to terminal set
    defn add-terminals-to-terminal-set () :
      defn scanned-terminal? (x:EItem) -> Maybe<GTerminal> :
        match(previous(x)) :
          (t:GTerminal) : One(t)
          (t) : None()
      for t in seq?(scanned-terminal?, eset) do :
        add(terminal-set, set-index - 1, t)

    ;Compute the new ends for items.
    defn add-ends-to-items () :
      for item in eset do :
        val num-tokens = length(tokens(rule(item)))
        val np = num-parsed(item)
        if np > 0 and np <= num-tokens - 1 :
          val new-end = set-index - parent(item)
          ends(item)[np - 1] = cons(new-end, ends(item)[np - 1])

    ;Compute production-count table.
    defn compute-production-count-table () :
      clear(production-count)
      for item in eset do :
        val t = upcoming(item)
        match(t:GProduction) :
          production-count[id(t)] = production-count[id(t)] + 1

    ;Determine whether deterministic reduction
    defn deterministic-reduction? (item:EItem) -> True|False :
      val num-tokens = length(tokens(rule(item)))
      if num-parsed(item) == num-tokens - 1 :
        val t = upcoming(item)
        match(t:GProduction) :
          production-count[id(t)] == 1

    ;Compute completion root for given item.
    defn compute-completion-root (item:EItem) -> CompletionRoot :
      val pitem = first-item(setlist, parent(item), production(item)) as EItem
      match(completion-root(pitem)) :
        (r:ChainRoot) : ChainLink(pitem, pitem)
        (r:ChainLink) : ChainLink(root(r), pitem)
        (r:NoCompletion) : ChainRoot()

    ;Compute completion roots for all items.
    defn compute-completion-roots () :
      for item in eset do :
        if deterministic-reduction?(item) :
          set-completion-root(item, compute-completion-root(item))

    ;Launch!
    add-items-to-setlist()
    add-items-to-completion-list()
    add-terminals-to-terminal-set()
    add-ends-to-items()
    compute-production-count-table()
    compute-completion-roots()

  defn process-all-sets () :
    ;Initialize current-set and next-set.
    val current-set = ESet(grammar)
    val next-set = ESet(grammar)
    val starting-rule = next(to-seq(rules(grammar,0)))
    add(current-set, make-eitem(grammar[starting-rule], 0))

    ;Process sets until finished.
    let loop (set-index:Int = 0,
              current-set:ESet = current-set,
              next-set:ESet = next-set,
              error-recovery?:True|False = false) :
      val next-input = peek(input-stream)
      val num-scanned = length(current-set)
      process-set(set-index, current-set, next-set, next-input, false, error-recovery?)
      val expand-list? = prune-conditional-matches(next-set)

      ;Dispatch to different cases
      defn* dispatch () :
        if empty?(next-set) :
          if start-completed?(current-set) : finished-parse()
          else : unexpected-input()
        else if scanned-rest?(next-set) :
          advance-to-next-set(true)
        else :
          advance-to-next-set(false)

      defn* finished-parse () :
        ;Complete and report completion
        commit-set(set-index, current-set)

      defn* advance-to-next-set (advance-rest?:True|False) :
        ;Compute the completion root and add to the setlist
        ;Add to setlist
        start(add-setlist-timer)
        commit-set(set-index, current-set)
        stop(add-setlist-timer)

        ;Debug
        ;print-current-set(grammar, set-index, current-set)

        ;Advance either to the end of the list, or by one token
        if advance-rest? : advance-rest(input-stream)
        else : advance(input-stream, expand-list?)

        ;Scan the next set
        clear(current-set, 0)
        loop(set-index + 1, next-set, current-set, false)

      defn* unexpected-input () :
        ;Compute the complete current set without using look-ahead prediction.
        clear(current-set, num-scanned)
        process-set(set-index, current-set, next-set, next-input, true, error-recovery?)

        ;Record context of missing input
        add(missing, MissingInput(next-input, set-index, info(input-stream), to-tuple(current-set)))

        ;Perform error recovery
        if list-end-expected?(current-set) : advance(input-stream, false)
        else if wildcard-expected?(current-set) : insert-wildcard(input-stream)
        else if list-expected?(current-set) : insert-list(input-stream)
        else : fatal("Unrecoverable")

        ;Scan current set again now with additional inserted tokens.
        clear(current-set, num-scanned)
        loop(set-index, current-set, next-set, true)

      ;Launch
      dispatch()

  ;Launch!
  defn main () :
    process-all-sets()
    println("PROCESSED SETS: %_" % [stz/earley-eitems/MAIN-TIMER])
    println(process-set-timer)
    println(prune-conditional-matches-timer)
    println(add-setlist-timer)
    println(compute-completion-root-timer)

    if empty?(missing) :
      SearchSuccess(completion-list, terminal-set, inputlist(input-stream), infolist(input-stream))
    else :
      SearchFailure(to-tuple(missing))

  main()