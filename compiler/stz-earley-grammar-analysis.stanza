defpackage stz/earley-grammar-analysis :
  import core
  import collections
  import stz/earley-grammar
  import stz/earley-sexp-stream
  import stz/earley-eval-result
  import stz/utils
  import stz/earley-eitems
  import stz/algorithms

;============================================================
;===================== Grammar Creation =====================
;============================================================

public defn Grammar (input-rules:GRules) -> Grammar :
  var grules = input-rules
  val matchers = let :
    val [grules*, matchers] = create-matcher-tokens $
                              ;convert-negation-rules(input-rules)
                              make-reluctant-productions $
                              order-rules $
                              input-rules
    grules = grules*
    matchers
  grules = remove-left-right-recursion(grules)
  ;grules = left-factor(grules)

  val rule-table = to-inttable(id, rules(grules))
  val production-table = ProductionTable<GDefProduction|False>(num-productions(grules), false)
  for def in productions(grules) do :
    production-table[id(def)] = def
  val grammar-properties = analyze-grammar-properties(grules, [])
  val null-prods = nullable-productions(grammar-properties)
  val forward-dispatch-sets = analyze-dispatch-sets(grules, grammar-properties, first-sets)
  val backward-dispatch-sets = analyze-dispatch-sets(grules, grammar-properties, last-sets)

  defn dispatch-rules (production:Int, dispatch-sets:DispatchSet, next-input:SExpToken) :
    match(next-input) :
      (input:SExpWildcard) :
        all-rules(dispatch-sets)[production]
      (input:SExpForm) :
        val x = unwrap-token(form(input))
        val obj-rules = match(x) :
          (x:Symbol) : keyword-rules(dispatch-sets)[[production, x]]
          (x) : List()
        val type-rules = match(x) :
          (x:Char) : prim-rules(dispatch-sets)[to-int(GCharType)][production]
          (x:Byte) : prim-rules(dispatch-sets)[to-int(GByteType)][production]
          (x:Int) : prim-rules(dispatch-sets)[to-int(GIntType)][production]
          (x:Long) : prim-rules(dispatch-sets)[to-int(GLongType)][production]
          (x:Float) : prim-rules(dispatch-sets)[to-int(GFloatType)][production]
          (x:Double) : prim-rules(dispatch-sets)[to-int(GDoubleType)][production]
          (x:String) : prim-rules(dispatch-sets)[to-int(GStringType)][production]
          (x:Symbol) : prim-rules(dispatch-sets)[to-int(GSymbolType)][production]
          (x:True) : prim-rules(dispatch-sets)[to-int(GTrueType)][production]
          (x:False) : prim-rules(dispatch-sets)[to-int(GFalseType)][production]
          (x:List) : list-rules(dispatch-sets)[production]
          (x) : List()
        cat-all $ [
          obj-rules,
          type-rules,
          any-rules(dispatch-sets)[production]
          null-rules(dispatch-sets)[production]]
      (input:SExpListEnd) :
        cat(
          list-end-rules(dispatch-sets)[production]
          null-rules(dispatch-sets)[production])

  new Grammar :
    defmethod production (this, id:Int) :
      production-table[id] as GDefProduction
    defmethod get (this, id:Int) :
      rule-table[id] as GTokenRule
    defmethod nullable? (this, production:Int) :
      null-prods[production]
    defmethod to-seq (this) :
      to-seq(rules(grules) as Tuple<GTokenRule>)
    defmethod rules (this, production:Int) :
      all-rules(forward-dispatch-sets)[production]
    defmethod rules-with-prefix (this, production:Int, next-input:SExpToken) :
      dispatch-rules(production, forward-dispatch-sets, next-input)
    defmethod match? (this, matcher-id:Int, form) :
      matchers[matcher-id](form)
    defmethod num-productions (this) :
      num-productions(grules)

;============================================================
;================== Grammar Properties ======================
;============================================================

defstruct GrammarProperties:
  nullable-productions: IntSet
  nullable-rules: IntSet
  left-sets: ProductionTable<List<GToken>>
  right-sets: ProductionTable<List<GToken>>
  first-sets: IntTable<Tuple<GTerminal>>
  last-sets: IntTable<Tuple<GTerminal>>
  first-tokens: IntTable<Tuple<GToken>>
  last-tokens: IntTable<Tuple<GToken>>

defn analyze-grammar-properties (grammar:GRules, blocks:Tuple<GProduction>) :
  ;Compute parent rules that contain each production.
  ;Each entry P => (i, j, k) means that production P exists in rule i, j, and k.
  val parent-table = ProductionTable<List<Int>>(num-productions(grammar), List())
  for rule in rules(grammar) do :
    for prod in filter-by<GProduction>(tokens(rule as GTokenRule)) do :
      add(parent-table, id(prod), id(rule))

  ;Compute rule table
  val rule-table = to-inttable(id, rules(grammar))

  ;Compute block set
  val blocked = to-intset(seq(id,blocks))

  ;Production worklist algorithm
  ;The given function is called repeatedly on all rules in the grammar.
  ;The function is given:
  ;- The rule index.
  ;- The rule
  ;- A progress function to report that progress has been made.
  ;If progress is made on one rule, then all rules that use that
  ;production are processed again.
  defn worklist (process:(GTokenRule, () -> False) -> ?) :
    val queue = Queue<Int>()
    add-all(queue, seq(id,rules(grammar)))
    while not empty?(queue) :
      val rule-index = pop(queue)
      val rule = rule-table[rule-index] as GTokenRule
      var progress?:True|False = false
      defn progress () : progress? = true
      process(rule, progress)
      if progress? :
        add-all(queue, parent-table[prod(rule)])

  ;Compute nullable productions and rules
  ;- null-prods holds all nullable productions.
  ;- null-rules holds indices of all nullable rules.
  val null-prods = IntSet()
  val null-rules = IntSet()
  defn nullable? (t:GToken) :
    match(t:GProduction) :
      null-prods[id(t)]
  defn nullable? (rule:GTokenRule) :
    all?(nullable?, tokens(rule))
  within (rule, progress) = worklist() :
    if nullable?(rule) :
      add(null-rules, id(rule))
      progress() when add(null-prods, prod(rule))

  ;Compute firstsets.
  ;Every entry P => (A B C) in first-set-table means that
  ;production P has first set equal to tokens (A B C).
  ;Furthermore, the entries P => A, P => B, P => C exist in
  ;first-set-entries.
  val first-set-entries = HashSet<KeyValue<Int,GToken>>()
  val first-set-table = ProductionTable<List<GToken>>(num-productions(grammar), List())
  val first-terminals = IntTable<Tuple<GTerminal>>()
  val first-tokens = IntTable<Tuple<GToken>>()
  defn first-set (t:GToken) -> List<GToken> :
    match(t) :
      (t:GMatcherToken) : List(terminal(t))
      (t:GTerminal) : List(t)
      (t:GProduction) :
        if blocked[id(t)] : List(t)
        else : cons(t, first-set-table[id(t)])
  defn first-set (rule:GTokenRule) -> List<GToken> :
    val ts = tokens(rule)
    let loop (i:Int = 0) :
      if i < length(ts) :
        val xs = first-set(ts[i])
        if nullable?(ts[i]) : append(xs, loop(i + 1))
        else : xs
      else : List()
  within (rule, progress) = worklist() :
    for t in first-set(rule) do :
      if add(first-set-entries, prod(rule) => t) :
        add(first-set-table, prod(rule), t)
        progress()
  for rule in rules(grammar) do :
    val ts = unique(first-set(rule as GTokenRule))
    first-terminals[id(rule)] = to-tuple(filter-by<GTerminal>(ts))
    first-tokens[id(rule)] = to-tuple(ts)

  ;Compute lastsets.
  ;Every entry P => (A B C) in last-set-table means that
  ;production P has last set equal to tokens (A B C).
  ;Furthermore, the entries P => A, P => B, P => C exist in
  ;last-set-entries.
  val last-set-entries = HashSet<KeyValue<Int,GToken>>()
  val last-set-table = ProductionTable<List<GToken>>(num-productions(grammar), List())
  val last-terminals = IntTable<Tuple<GTerminal>>()
  val last-tokens = IntTable<Tuple<GToken>>()
  defn last-set (t:GToken) -> List<GToken> :
    match(t) :
      (t:GMatcherToken) : List(terminal(t))
      (t:GTerminal) : List(t)
      (t:GProduction) :
        if blocked[id(t)] : List(t)
        else : cons(t, last-set-table[id(t)])
  defn last-set (rule:GTokenRule) -> List<GToken> :
    val ts = tokens(rule)
    val n = length(ts)
    let loop (i:Int = n - 1) :
      if i >= 0 :
        val xs = last-set(ts[i])
        if nullable?(ts[i]) : append(xs, loop(i - 1))
        else : xs
      else : List()
  within (rule, progress) = worklist() :
    for t in last-set(rule) do :
      if add(last-set-entries, prod(rule) => t) :
        add(last-set-table, prod(rule), t)
        progress()
  for rule in rules(grammar) do :
    val ts = unique(last-set(rule as GTokenRule))
    last-terminals[id(rule)] = to-tuple(filter-by<GTerminal>(ts))
    last-tokens[id(rule)] = to-tuple(ts)

  println("First Set Table")
  do(println, first-set-table)
  println("Last Set Table")
  do(println, last-set-table)

  ;Return all properties
  GrammarProperties(
    null-prods,
    null-rules,
    first-set-table,
    last-set-table,
    first-terminals,
    last-terminals,
    first-tokens,
    last-tokens)

;============================================================
;=================== Cache Utility ==========================
;============================================================

deftype Cache<T>
defmulti value<?T> (cache:Cache<?T>) -> T
defmulti invalidate (cache:Cache) -> False

defn Cache<?T> (f:() -> ?T) :
  var value:Maybe<T> = None()
  new Cache<T> :
    defmethod invalidate (this) :
      value = None()
    defmethod value (this) :
      if empty?(value) :
        value = One(f())
      value!(value)

;============================================================
;=================== Grammar Transformer ====================
;============================================================

deftype GrammarTransformer
defmulti fresh-rule (t:GrammarTransformer) -> Int
defmulti fresh-production (t:GrammarTransformer) -> GProduction
defmulti modify (t:GrammarTransformer, mod:GrammarModification) -> False
defmulti rules (t:GrammarTransformer) -> Tuple<GRule>
defmulti rules (t:GrammarTransformer, prod:GProduction) -> Tuple<GRule>
defmulti num-productions (t:GrammarTransformer) -> Int
defmulti grammar (t:GrammarTransformer) -> GRules

deftype GrammarMod
defstruct CloneProduction <: GrammarMod :
  prod: GProduction
  old: GProduction
defstruct SubstituteRule <: GrammarMod :
  rule: GRule
defstruct DeleteRule <: GrammarMod :
  id: Int
defstruct AddRule <: GrammarMod :
  rule: GRule
defstruct AddProduction <: GrammarMod :
  prod: GDefProduction
defstruct ReplaceAllRules <: GrammarMod :
  rules: Tuple<GRule>

defstruct GrammarModification :
  mods: Tuple<GrammarMod>

defn GrammarTransformer (grammar:GRules) -> GrammarTransformer :
  ;Table of productions
  val prod-table = to-inttable(id, productions(grammar))

  ;Counter to use to generate fresh productions
  val prod-counter = to-seq(num-productions(grammar) to false)

  ;Counter to use to generate fresh rules
  val rule-counter = to-seq(next-id to false) where :
    val next-id = maximum(-1, seq(id, rules(grammar))) + 1

  ;List of current rules
  val rule-list = to-vector<GRule>(rules(grammar))

  ;Create GrammarTransformer feature.
  new GrammarTransformer :
    defmethod rules (this, prod:GProduction) :
      to-tuple $ for r in rule-list filter :
        /prod(r) == id(prod)
    defmethod rules (this) :
      to-tuple(rule-list)
    defmethod fresh-production (this) :
      GProduction(next(prod-counter))
    defmethod fresh-rule (this) :
      next(rule-counter)
    defmethod modify (this, gmod:GrammarModification) :
      ;Perform production cloning, and additions.
      ;Gather deletions and substitutions.
      val delete-set = IntSet()
      val sub-table = IntTable<GRule>()
      for mod in mods(gmod) do :
        match(mod) :
          (mod:CloneProduction) :
            val old-def = prod-table[id(old(mod))]
            val name* = symbol-join $ [name(old-def), id(prod(mod))]
            val new-def = GDefProduction(id(prod(mod)), name*)
            prod-table[id(prod(mod))] = new-def
          (mod:SubstituteRule) :
            sub-table[id(rule(mod))] = rule(mod)
          (mod:DeleteRule) :
            add(delete-set, id(mod))
          (mod:AddRule) :
            add(rule-list, rule(mod))
          (mod:ReplaceAllRules) :
            clear(rule-list)
            add-all(rule-list, rules(mod))
          (mod:AddProduction) :
            val p = prod(mod)
            prod-table[id(p)] = p
      ;Perform deletions and substitutions
      for rule in rule-list update :
        if delete-set[id(rule)] : None()
        else if key?(sub-table, id(rule)) : One(sub-table[id(rule)])
        else : One(rule)
    defmethod num-productions (this) :
      peek(prod-counter)
    defmethod grammar (this) :
      GRules(to-tuple(values(prod-table)),
             to-tuple(rule-list))

defn token-rules (t:GrammarTransformer, prod:GProduction) -> Tuple<GTokenRule> :
  rules(t,prod) as Tuple<GTokenRule>

;<doc>=======================================================
;=============== Left-Right-Recursive Transform =============
;============================================================

Operations needed for manipulating rules:
- Create a new production with the same name as another.
- Create a new production with the same name and rules as another.
- Retrieve all rules for a given production.
- Change the definition of an existing rule.
- Delete an existing rule.
- Add a new rule.
- Retrieve immediate right sets.

;============================================================
;=======================================================<doc>

defn remove-null-endings (grammar:GRules,
                          atom-table:IntTable<GProduction>,
                          props:GrammarProperties) -> [GRules, IntSet] :
  ;Create transformer
  val gt = GrammarTransformer(grammar)

  ;Accumulate modifications
  val mods = Vector<GrammarMod>()

  ;Utility: Create a fresh identifier for the given rule.
  defn make-fresh (r:GTokenRule) -> GTokenRule :
    sub-id(r, fresh-rule(gt)) as GTokenRule

  ;Given a production for creating new rules, create a
  ;function that returns a new production cloned from an existing
  ;production with the analyzed rules.
  defn clone-and-analyze (analyze:GTokenRule -> Seqable<GTokenRule>) :
    val table = IntTable<GProduction>()
    defn analyze-prod (p:GProduction) -> GProduction :
      if key?(table, id(p)) :
        table[id(p)]
      else :
        val p* = fresh-production(gt)
        add(mods, CloneProduction(p*, p))
        table[id(p)] = p*
        for r in seq-cat(analyze, token-rules(gt, p)) do :
          add(mods, AddRule(sub-prod(make-fresh(r), id(p*))))
        p*
    [analyze-prod, table]

  ;Functions for analyzing productions
  var prod-with-null-rules:GProduction -> GProduction
  var remove-prod-null-lefts:GProduction -> GProduction
  var remove-prod-null-rights:GProduction -> GProduction

  ;Return true if the given token is nullable.
  ;Only returns true for productions.
  defn nullable? (t:GToken) -> True|False :
    match(t:GProduction) :
      nullable-productions(props)[id(t)]

  ;Returns a tuple containing all version of rule 'r'
  ;that expand to null. Output has either length 0 or 1.
  defn remove-non-null (r:GTokenRule) -> Tuple<GTokenRule> :
    val num-tokens = length(tokens(r))
    let loop (i:Int = 0,
              tokens:Tuple<GToken> = tokens(r)) :
      if i < num-tokens :
        val t = tokens[i]
        if nullable?(t) :
          val null-t = prod-with-null-rules(t as GProduction)
          loop(i + 1, sub-item(tokens, i, null-t))
        else : []
      else :
        [sub-tokens(r, tokens)]

  ;Returns all versions of rule 'r' that begins with
  ;either a fully null production or non-null production.
  defn remove-null-lefts (r:GTokenRule) -> Seqable<GTokenRule> :
    val rules* = Vector<GTokenRule>()
    val num-tokens = length(tokens(r))
    let loop (i:Int = 0,
              tokens:Tuple<GToken> = tokens(r)) :
      if i < num-tokens :
        val t = tokens[i]
        if nullable?(t) :
          val null-t = prod-with-null-rules(t as GProduction)
          val non-null-t = remove-prod-null-lefts(t as GProduction)
          add(rules*, sub-tokens(r, sub-item(tokens, i, non-null-t)))
          loop(i + 1, sub-item(tokens, i, null-t))
        else :
          add(rules*, sub-tokens(r, tokens))
    rules*

  ;Returns all versions of rule 'r' that ends with
  ;either a fully null production or non-null production.
  defn remove-null-rights (r:GTokenRule) -> Seqable<GTokenRule> :
    val rules* = Vector<GTokenRule>()
    val num-tokens = length(tokens(r))
    let loop (i:Int = num-tokens - 1,
              tokens:Tuple<GToken> = tokens(r)) :
      if i >= 0 :
        val t = tokens[i]
        if nullable?(t) :
          val null-t = prod-with-null-rules(t as GProduction)
          val non-null-t = remove-prod-null-rights(t as GProduction)
          add(rules*, sub-tokens(r, sub-item(tokens, i, non-null-t)))
          loop(i - 1, sub-item(tokens, i, null-t))
        else :
          add(rules*, sub-tokens(r, tokens))
    rules*

  ;Return all versions of rule 'r' that begins/ends with
  ;either a fully null production or non-null production.
  defn remove-null-lefts-and-rights (r:GTokenRule) -> Seqable<GTokenRule> :
    for r in remove-null-lefts(r) seq-cat :
      remove-null-rights(r)

  ;Main algorithm
  defn main () :
    defn fst<?T> ([x, y]:[?T, ?]) : x
    val [prod-null-rules-func, null-table] = clone-and-analyze(remove-non-null)
    prod-with-null-rules = prod-null-rules-func
    remove-prod-null-lefts = fst(clone-and-analyze(remove-null-lefts))
    remove-prod-null-rights = fst(clone-and-analyze(remove-null-rights))
    for e-id in keys(atom-table) do :
      val e = GProduction(e-id)
      for r in token-rules(gt,e) do :
        add(mods, DeleteRule(id(r)))
        for r* in remove-null-lefts-and-rights(r) do :
          add(mods, AddRule(make-fresh(r*)))
    modify(gt, GrammarModification(to-tuple(mods)))
    val null-set = to-intset(seq(id, values(null-table)))
    [/grammar(gt), null-set]

  ;Launch!
  main()

defn remove-partial-recursion (grammar:GRules,
                               atom-table:IntTable<GProduction>,
                               null-set:IntSet) -> GRules :
  ;Compute grammar properties
  val lr-prods = to-tuple(seq(GProduction, keys(atom-table)))
  var props:GrammarProperties = analyze-grammar-properties(grammar, lr-prods)

  ;Create transformer
  val gt = GrammarTransformer(grammar)

  ;Accumulate modifications
  val mods = Vector<GrammarMod>()

  ;Commit modifications and recompute properties
  defn commit-modifications () :
    modify(gt, GrammarModification(to-tuple(mods)))
    clear(mods)
    props = analyze-grammar-properties(/grammar(gt), lr-prods)

  ;Analyze LR productions using the given function.
  defn analyze-lr-prods (analyze-rule:GTokenRule -> Seqable<GTokenRule>) :
    for e in lr-prods do :
      for r in token-rules(gt,e) do :
        add(mods, DeleteRule(id(r)))
        for r* in analyze-rule(r) do :
          add(mods, AddRule(make-fresh(r*)))    

  ;Utility: Create a fresh identifier for the given rule.
  defn make-fresh (r:GTokenRule) -> GTokenRule :
    sub-id(r, fresh-rule(gt)) as GTokenRule

  ;Given a production for creating new rules, create a
  ;function that returns a new production cloned from an existing
  ;production with the analyzed rules.
  defn clone-and-analyze (analyze:GTokenRule -> Seqable<GTokenRule>) :
    val table = IntTable<GProduction>()
    fn (p:GProduction) -> GProduction :
      if key?(table, id(p)) :
        table[id(p)]
      else :
        val p* = fresh-production(gt)
        add(mods, CloneProduction(p*, p))
        table[id(p)] = p*
        for r in seq-cat(analyze, token-rules(gt, p)) do :
          add(mods, AddRule(sub-prod(make-fresh(r), id(p*))))
        p*

  ;Functions for analyzing productions
  var prod-with-left-rec:GProduction -> GProduction
  var prod-without-left-rec:GProduction -> GProduction
  var prod-with-right-rec:GProduction -> GProduction
  var prod-without-right-rec:GProduction -> GProduction

  ;Compute the recursion status of the given token.
  ;Must pass the production set to use, representing either the left-sets or right-sets of the
  ;production.
  defn rec-status (sets:GrammarProperties -> ProductionTable<List<GToken>>, t:GToken) -> RecStatus :
    defn lr-prod? (t:GToken) :
      match(t:GProduction) :
        key?(atom-table, id(t))        
    match(t) :
      (p:GProduction) :
        if null-set[id(p)] :
          NullProd
        else if lr-prod?(p) :
          Rec
        else :
          val set-tokens = sets(props)[id(p)]
          if any?(lr-prod?, set-tokens) :
            if any?({_ is GTerminal}, set-tokens) : Rec+NRec
            else : Rec
          else : NRec
      (t:GTerminal) :
        NRec

  ;Returns [rec?, nrec?] where:
  ;rec? is true if status indicates that recursive rules should be kept.
  ;nrec? is true if status indicates that nonrecursive rules should be kept.
  defn flags (status:RecStatus) -> [True|False, True|False] :
    switch(status) :
      Rec : [true, false]
      NRec : [false, true]
      Rec+NRec : [true, true]

  ;Split up the given rule into multiple rules such that,
  ;for every rule, the beginning token is either entirely left-recursive
  ;or never left-recursive.
  defn split-partial-left-recursion (r:GTokenRule, status:RecStatus) -> Seqable<GTokenRule> :
    ;Compute rules to keep.
    val [rec?, nrec?] = flags(status)    
    val rules* = Vector<GTokenRule>()
    let loop (i:Int = 0) :
      val t = tokens(r)[i]
      switch(rec-status(left-sets, t)) :
        NullProd :
          loop(i + 1)
        Rec+NRec :
          if rec? :
            val trec = prod-with-left-rec(t as GProduction)
            add(rules*, sub-tokens(r, sub-item(tokens(r), i, trec)))
          if nrec? :
            val tnrec = prod-without-left-rec(t as GProduction)
            add(rules*, sub-tokens(r, sub-item(tokens(r), i, tnrec)))
        Rec :
          add(rules*, r) when rec?
        NRec :
          add(rules*, r) when nrec?
    rules*

  ;Split up the given rule into multiple rules such that,
  ;for every rule, the ending token is either entirely right-recursive
  ;or never right-recursive.
  defn split-partial-right-recursion (r:GTokenRule, status:RecStatus) -> Seqable<GTokenRule> :
    ;Compute rules to keep.
    val [rec?, nrec?] = flags(status)    
    val rules* = Vector<GTokenRule>()
    val num-tokens = length(tokens(r))
    let loop (i:Int = num-tokens - 1) :
      val t = tokens(r)[i]
      switch(rec-status(right-sets, t)) :
        NullProd :
          loop(i - 1)
        Rec+NRec :
          if rec? :
            val trec = prod-with-right-rec(t as GProduction)
            add(rules*, sub-tokens(r, sub-item(tokens(r), i, trec)))
          if nrec? :
            val tnrec = prod-without-right-rec(t as GProduction)
            add(rules*, sub-tokens(r, sub-item(tokens(r), i, tnrec)))
        Rec :
          add(rules*, r) when rec?
        NRec :
          add(rules*, r) when nrec?
    rules*

  ;Split up the given rule into multiples rules such that rules do not
  ;begin/end with tokens that are neither entirely recursive nor non-recursive.
  defn split-partial-recursion (r:GTokenRule) -> Seqable<GTokenRule> :
    for r in split-partial-left-recursion(r, Rec+NRec) seq-cat :
      split-partial-right-recursion(r, Rec+NRec)

  ;Main algorithm
  defn main () :
    prod-with-left-rec = clone-and-analyze(split-partial-left-recursion{_, Rec})
    prod-without-left-rec = clone-and-analyze(split-partial-left-recursion{_, NRec})
    prod-with-right-rec = clone-and-analyze(split-partial-right-recursion{_, Rec})
    prod-without-right-rec = clone-and-analyze(split-partial-right-recursion{_, NRec})
    analyze-lr-prods(split-partial-recursion)
    ;analyze-lr-prods(split-partial-left-recursion{_, Rec+NRec})
    ;analyze-lr-prods(split-partial-right-recursion{_, Rec+NRec})
    commit-modifications()
    /grammar(gt)
    
  ;Launch!
  main()


defn remove-left-recursion (grammar:GRules, atom-table:IntTable<GProduction>) -> GRules :
  ;Compute grammar properties
  val lprods = to-tuple(seq(GProduction, keys(atom-table)))
  val props = analyze-grammar-properties(grammar, lprods)

  ;Create transformer
  val gt = GrammarTransformer(grammar)

  ;Collect all modifications
  val mods = Vector<GrammarMod>()
  defn modify (m:GrammarMod) :
    add(mods, m)

  ;Operation: Classify the left-recursion status of the given rule with respect to e.
  defn rec-status (rule:GTokenRule, e:GProduction) -> RecStatus :
    val left-tokens = first-tokens(props)[id(rule)]
    if contains?(left-tokens, e) :
      if any?({_ is GTerminal}, left-tokens) : Rec+NRec
      else : Rec
    else : NRec

  ;Table holding left-recursive and non-left-recursive versions of productions.
  ;Each entry [P,E] => P* in lr-replacement-table means that
  ;P* is the version of P where all rules begin with E.
  ;Each entry [P,E] => P* in nlr-replacement-table means that
  ;P* is the version of P where no rules begin with E.
  val lr-replacement-table = HashTable<[GProduction,GProduction],GProduction>()
  val nlr-replacement-table = HashTable<[GProduction,GProduction],GProduction>()

  ;Returns the version of p where left-occurrences of e has been replaced
  ;with e's atom. (Assumes that p has left-occurrences of e.)
  defn left-recursive (p:GProduction, e:GProduction) -> GProduction :
    if p == e :
      atom-table[id(e)]
    else if key?(lr-replacement-table, [p,e]) :
      lr-replacement-table[[p,e]]
    else :
      val p* = fresh-production(gt)
      lr-replacement-table[[p,e]] = p*
      modify(CloneProduction(p*,p))
      for rule in token-rules(gt,p) do :
        val rule* = left-recursive(rule,e)
        match(rule*:GTokenRule) :
          val id* = fresh-rule(gt)
          val rule** = sub-id{_, id*} $
                       sub-prod{_, id(p*)} $
                       rule*
          modify(AddRule(rule** as GTokenRule))
      p*

  ;Operation: Return the given rule with all left-occurrences of e replaced
  ;with e's atom. Rule is pruned such that all instantiations begin with e's atom.
  ;Returns false if rule never begins with e.
  defn left-recursive (rule:GTokenRule, e:GProduction) -> GTokenRule|False :
    if rec-status(rule,e) != NRec :
      val p0 = tokens(rule)[0] as GProduction
      val p0* = left-recursive(p0, e)
      val tokens* = sub-item(tokens(rule), 0, p0*)
      sub-tokens(rule, tokens*)

  ;Returns the version of p where no rules begin with e. (
  ;Assumes that a portion of the rules of p begins with e.)
  defn non-left-recursive (p:GProduction, e:GProduction) -> GProduction :
    if key?(nlr-replacement-table, [p,e]) :
      nlr-replacement-table[[p,e]]
    else :
      val p* = fresh-production(gt)
      nlr-replacement-table[[p,e]] = p*
      modify(CloneProduction(p*,p))
      for rule in token-rules(gt,p) do :
        val rule* = non-left-recursive(rule,e)
        match(rule*:GTokenRule) :
          val id* = fresh-rule(gt)
          val rule** = sub-id{_, id*} $
                       sub-prod{_, id(p*)} $
                       rule*
          modify(AddRule(rule** as GTokenRule))
      p*

  ;Operation: Return the rule pruned such that no instantiations begin with e.
  ;Returns false if rule always begins with e.
  defn non-left-recursive (rule:GTokenRule, e:GProduction) -> GTokenRule|False :
    switch(rec-status(rule,e)) :
      Rec : false
      NRec : rule
      Rec+NRec :
        val p0 = tokens(rule)[0] as GProduction
        val p0* = non-left-recursive(p0, e)
        val tokens* = sub-item(tokens(rule), 0, p0*)
        sub-tokens(rule, tokens*)

  ;Main algorithm: Remove left occurrences in all requested productions.
  defn remove-all-left-occurrences () :
    for entry in atom-table do :
      val e = GProduction(key(entry))
      val atom = value(entry)
      for rule in token-rules(gt, e) do :
        val lr-rule = left-recursive(rule,e)
        val nr-rule = non-left-recursive(rule,e)
        match(lr-rule, nr-rule) :
          (lr-rule:GTokenRule, nr-rule:False) :
            val optype = Postfix(id(atom))
            modify(SubstituteRule(sub-optype(lr-rule, optype)))
          (lr-rule:False, nr-rule:GTokenRule) :
            modify(SubstituteRule(nr-rule))
          (lr-rule:GTokenRule, nr-rule:GTokenRule) :
            val optype = Postfix(id(atom))
            modify(SubstituteRule(sub-optype(lr-rule, optype)))
            val id* = fresh-rule(gt)
            val nr-rule* = sub-id(nr-rule,id*)
            modify(AddRule(nr-rule* as GTokenRule))

  ;Launch!
  remove-all-left-occurrences()
  /modify(gt, GrammarModification(to-tuple(mods)))
  /grammar(gt)

defn move-right-recursion (grammar:GRules, atom-table:IntTable<GProduction>) -> GRules :
  ;Compute grammar properties
  val lprods = to-tuple(seq(GProduction, keys(atom-table)))
  val props = analyze-grammar-properties(grammar, lprods)

  ;Create transformer
  val gt = GrammarTransformer(grammar)

  ;Collect all modifications
  val mods = Vector<GrammarMod>()
  defn modify (m:GrammarMod) :
    add(mods, m)

  ;Operation: Classify the right-recursion status of the given rule with respect to e.
  defn rec-status (rule:GTokenRule, e:GProduction) -> RecStatus :
    val right-tokens = last-tokens(props)[id(rule)]
    if contains?(right-tokens, e) :
      if any?({_ is GTerminal}, right-tokens) : Rec+NRec
      else : Rec
    else : NRec

  ;Table holding right-recursive and non-right-recursive versions of productions.
  ;Each entry [P,E] => P* in rr-replacement-table means that
  ;P* is the version of P where all rules end with E.
  ;Each entry [P,E] => P* in nrr-replacement-table means that
  ;P* is the version of P where no rules end with E.
  val rr-replacement-table = HashTable<[GProduction,GProduction],GProduction>()
  val nrr-replacement-table = HashTable<[GProduction,GProduction],GProduction>()

  ;Operation: Returns the version of p where all rules end with e.
  ;Assumes that a portion of the rules for the given production ends with e.
  defn right-recursive (p:GProduction, e:GProduction) -> GProduction :
    if key?(rr-replacement-table, [p,e]) :
      rr-replacement-table[[p,e]]
    else :
      val p* = fresh-production(gt)
      rr-replacement-table[[p,e]] = p*
      modify(CloneProduction(p*,p))
      for rule in token-rules(gt,p) do :
        val rule* = right-recursive(rule, e)
        match(rule*:GTokenRule) :
          val id* = fresh-rule(gt)
          val rule** = sub-id{_, id*} $
                       sub-prod{_, id(p*)} $
                       rule*
          modify(AddRule(rule** as GTokenRule))
      p*

  ;Operation: Returns the rule pruned such that all instantiations end with e.
  ;Returns false if rule never ends with e.
  defn right-recursive (rule:GTokenRule, e:GProduction) -> GTokenRule|False :
    switch(rec-status(rule,e)) :
      Rec : rule
      NRec : false
      Rec+NRec :
        val n = length(tokens(rule))
        val pn = tokens(rule)[n - 1] as GProduction
        val pn* = right-recursive(pn, e)
        val tokens* = sub-item(tokens(rule), n - 1, pn*)
        sub-tokens(rule, tokens*)

  ;Operation: Returns the version of p where no rules end with e.
  ;Assumes that a portion of the rules for the given production ends with e.
  defn non-right-recursive (p:GProduction, e:GProduction) -> GProduction :
    if key?(nrr-replacement-table, [p,e]) :
      nrr-replacement-table[[p,e]]
    else :
      val p* = fresh-production(gt)
      nrr-replacement-table[[p,e]] = p*
      modify(CloneProduction(p*,p))
      for rule in token-rules(gt,p) do :
        val rule* = non-right-recursive(rule, e)
        match(rule*:GTokenRule) :
          val id* = fresh-rule(gt)
          val rule** = sub-id{_, id*} $
                       sub-prod{_, id(p*)} $
                       rule*
          modify(AddRule(rule** as GTokenRule))
      p*

  ;Operation: Returns the rule pruned such that no instantiations end with e.
  ;Returns false if rule always ends with e.
  defn non-right-recursive (rule:GTokenRule, e:GProduction) -> GTokenRule|False :
    switch(rec-status(rule,e)) :
      Rec : false
      NRec : rule
      Rec+NRec :
        val n = length(tokens(rule))
        val pn = tokens(rule)[n - 1] as GProduction
        val pn* = non-right-recursive(pn, e)
        val tokens* = sub-item(tokens(rule), n - 1, pn*)
        sub-tokens(rule, tokens*)

  ;Main algorithm: Move all non-right-recursive rules to their atom productions.
  defn move-non-right-recursive-rules () :
    for entry in atom-table do :
      val e = GProduction(key(entry))
      val atom = value(entry)
      modify(AddRule(rule*)) where :
        val id* = fresh-rule(gt)
        val rule* = GTokenRule(id*, id(e), [atom], FactoredParams())
      for rule in token-rules(gt,e) do :
        val rr-rule = right-recursive(rule, e)
        val nr-rule = non-right-recursive(rule, e)
        match(rr-rule:GTokenRule) :
          val optype = combine(optype(rule), Prefix(id(e)))
          modify(SubstituteRule(sub-optype(rr-rule,optype)))
        else :
          modify(DeleteRule(id(rule)))
        match(nr-rule:GTokenRule) :
          val id* = fresh-rule(gt)
          val nr-rule* = sub-id{_, id*} $
                         sub-prod{_, id(atom)} $
                         nr-rule
          modify(AddRule(nr-rule* as GTokenRule))

  ;Launch!
  move-non-right-recursive-rules()
  /modify(gt, GrammarModification(to-tuple(mods)))
  /grammar(gt)

defn remove-left-right-recursion (grammar:GRules) -> GRules :
  ;Compute grammar properties
  val props = analyze-grammar-properties(grammar, [])

  ;Discover all left-right-recursive productions.
  defn left-recursive? (prod:GProduction) -> True|False :
    contains?(left-sets(props)[id(prod)], prod)
  defn right-recursive? (prod:GProduction) -> True|False :
    contains?(right-sets(props)[id(prod)], prod)
  defn left-right-recursive? (prod:GProduction) -> True|False :
    left-recursive?(prod) and right-recursive?(prod)
  val lrprods = to-tuple(filter(left-right-recursive?, prods)) where :
    val prods = seq(GProduction{id(_)}, productions(grammar))

  ;Create atoms for all left-right-recursive productions
  val gt = GrammarTransformer(grammar)
  val mods = Vector<GrammarMod>()
  val atom-table = IntTable<GProduction>()
  for e in lrprods do :
    val atom = fresh-production(gt)
    add(mods, CloneProduction(atom,e))
    atom-table[id(e)] = atom

  ;Create atom productions
  modify(gt, GrammarModification(to-tuple(mods)))
  val grammar1 = /grammar(gt)
  println(grammar1)

  ;Remove null endings
  val [grammar15, null-set] = remove-null-endings(grammar1, atom-table, props)
  println("===== REMOVED NULL ENDINGS =====")
  println(grammar15)

  ;Remove partial recursion
  val grammar16 = remove-partial-recursion(grammar15, atom-table, null-set)
  println("===== REMOVED PARTIAL RECURSION =====")
  println(grammar16)

  ;Remove left recursion
  val grammar2 = remove-left-recursion(grammar1, atom-table)
  println(grammar2)

  ;Move right recursion
  val grammar3 = move-right-recursion(grammar2, atom-table)
  println(grammar3)

  grammar3

;Represents the recursion status of a production.
;Productions can be:
;- Only recursive (Rec). All rules for production end/begin with recursive production.
;- Not recursive (NRec). No rules for production end/begin with recursive production.
;- Both recursive and not recursive (Rec+NRec). Some rules for production
;  end/begin with recursive production.
defenum RecStatus :
  NullProd
  Rec
  NRec
  Rec+NRec

;Substitute entry in tuple
defn sub-item<?T> (xs:Tuple<?T>, index:Int, item:T) :
  to-tuple $ for (x in xs, i in 0 to false) seq :
    if i == index : item
    else : x

;Retrieve the operator type of the rule.
defn optype (r:GTokenRule) -> OperatorType|False :
  val params = params(r) as TokenRuleParams
  operator-type(params)

;Substitute the operator type in the given rule.
defn sub-optype (r:GTokenRule, optype:OperatorType|False) -> GTokenRule :
  val params = params(r) as TokenRuleParams
  val params* = sub-operator-type(params, optype)
  sub-params(r, params*) as GTokenRule

;Combine an existing optype (either Postfix or false) with a Prefix.
defn combine (a:OperatorType|False, b:Prefix) -> OperatorType :
  match(a) :
    (a:Postfix) : Binary(id(a), id(b))
    (a:False) : b

;============================================================
;=============== Left Factoring Analysis ====================
;============================================================
defn left-factor (grammar:GRules) -> GRules :
  ;Create transformer
  val gt = GrammarTransformer(grammar)
  val mods = Vector<GrammarMod>()
  val new-rules = Vector<GTokenRule>()

  ;Rule maker
  val rule-maker = new TreeRuleMaker :
    defmethod fresh-rule (this) :
      fresh-rule(gt)
    defmethod fresh-production (this, old-p:Int) :
      val p = fresh-production(gt)
      add(mods, CloneProduction(p, GProduction(old-p)))
      id(p)
    defmethod add-rule (this, rule:GTokenRule) :
      println(rule)
      add(new-rules, rule)

  ;Factor each production
  for production in productions(grammar) do :
    println("Factor production %_" % [production])
    within indented() :
      val rules = token-rules(gt, GProduction(id(production)))
      if length(rules) <= 1 :
        for r in rules do :
          add(new-rules, r)
      else :
        println("Rules are:")
        within indented() :
          do(println, rules)
        val tree = TokenTree(rules)
        println(tree)
        println("Make Rules:")
        within indented() :
          make-rules(id(production), tree, rule-maker)

  ;Commit modifications and return new grammar
  add(mods, ReplaceAllRules(to-tuple(new-rules)))
  modify(gt, GrammarModification(to-tuple(mods)))
  val result = /grammar(gt)
  println("Left Factored Grammar:")
  println(result)
  result

;------------------------------------------------------------
;--------------- Factor Rules into Tree ---------------------
;------------------------------------------------------------
deftype TokenTree
defstruct BranchNode <: TokenTree :
  nodes: List<TokenTree>
defstruct TokenNode <: TokenTree :
  token: GToken
  factored?: True|False
  child: TokenTree
defstruct RuleNode <: TokenTree :
  rule: GTokenRule

defmethod print (o:OutputStream, tree:TokenTree) :
  match(tree) :
    (tree:TokenNode) :
      print(o, "TokenNode(%_, %_, %_)" % [token(tree), factored?(tree), indented-list([child(tree)])])
    (tree:RuleNode) :
      print(o, "RuleNode(%_)" % [rule(tree)])
    (tree:BranchNode) :
      print(o, "BranchNode(%_)" % [indented-list(nodes(tree))])

defn indented-list (xs:Seqable) :
  new Printable :
    defmethod print (o:OutputStream, this) :
      val o2 = IndentedStream(o)
      do(lnprint{o2, _}, xs)

;Construct a TokenTree from a collection of rules.
defn TokenTree (rs:Seqable<GTokenRule>) -> TokenTree :
  reduce(add{_:TokenTree, _:TokenTree}, seq(TokenTree, rs))

;Construct a single linear TokenTree from the given token rule.
defn TokenTree (r:GTokenRule) -> TokenTree :
  val num-tokens = length(tokens(r))
  let loop (index:Int = 0) :
    if index < num-tokens :
      val factored? = params(r) is FactoredParams and index == num-tokens - 1
      TokenNode(tokens(r)[index], factored?, loop(index + 1))
    else : RuleNode(r)

;Return true if a and b are both TokenNodes and share their token.
defn shares-token? (a:TokenTree, b:TokenTree) -> True|False :
  match(a:TokenNode, b:TokenNode) :
    not factored?(a) and not factored?(b) and
    token(a) == token(b)

;Merge two TokenTrees into one.
defn add (a:TokenTree, b:TokenTree) -> TokenTree :
  if shares-token?(a,b) :
    val a = a as TokenNode
    val b = b as TokenNode
    TokenNode(token(a), factored?(a), add(child(a), child(b)))
  else :
    match(a:BranchNode) : BranchNode(add(nodes(a), b))
    else : BranchNode(List(a,b))

;Merge the given tree 'b' into the list of trees 'a'.
defn add (a:List<TokenTree>, b:TokenTree) -> List<TokenTree> :
  if empty?(a) : List(b)
  else if shares-token?(head(a),b) : cons(add(head(a), b), tail(a))
  else : cons(head(a), add(tail(a), b))

;------------------------------------------------------------
;--------------- Convert Tree Into Rules --------------------
;------------------------------------------------------------
deftype TreeRuleMaker
defmulti fresh-rule (m:TreeRuleMaker) -> Int
defmulti fresh-production (m:TreeRuleMaker, old-prod:Int) -> Int
defmulti add-rule (m:TreeRuleMaker, rule:GTokenRule) -> False

defn make-rules (prod-id:Int, tree:TokenTree, maker:TreeRuleMaker) :
  ;Convert the given tree into a single token rule
  ;for the given production.
  defn make-rule (prod-id:Int, tree:TokenTree) -> GTokenRule :
    val tokens = Vector<GToken>()
    let loop (tree:TokenTree = tree) :
      match(tree) :
        (tree:BranchNode) :
          ;Make a new factored production to represent
          ;the branch.
          val prod* = fresh-production(maker, prod-id)
          make-rules(prod*, tree)
          ;Finish off current rule
          val id* = fresh-rule(maker)
          add(tokens, GProduction(prod*))
          GTokenRule(id*, prod-id, to-tuple(tokens), FactoredParams(), false)
        (tree:TokenNode) :
          add(tokens, token(tree))
          loop(child(tree))
        (tree:RuleNode) :
          val rule = rule(tree)
          GTokenRule(id(rule), prod-id, to-tuple(tokens), params(rule), order(rule))

  ;Make rules for the given production corresponding to the
  ;given tree. Directly adds them to the maker.
  defn make-rules (prod-id:Int, tree:TokenTree) -> False :
    match(tree:BranchNode) :
      for node in nodes(tree) do :
        add-rule(maker, make-rule(prod-id, node))
    else :
      add-rule(maker, make-rule(prod-id, tree))

  ;Launch!
  make-rules(prod-id, tree)

;============================================================
;================== Dispatch Sets ===========================
;============================================================

defstruct DispatchSet :
  all-rules:ProductionTable<List<Int>>
  null-rules:ProductionTable<List<Int>>
  any-rules:ProductionTable<List<Int>>
  list-end-rules:ProductionTable<List<Int>>
  prim-rules:Array<ProductionTable<List<Int>>>
  list-rules:ProductionTable<List<Int>>
  keyword-rules:HashTable<[Int,Symbol],List<Int>>

defn analyze-dispatch-sets (grammar:GRules,
                            props:GrammarProperties,
                            prediction-set:GrammarProperties -> IntTable<Tuple<GTerminal>>) :
  ;Create rule sets
  val nprods = num-productions(grammar)
  val all-rules = ProductionTable<List<Int>>(nprods, List())
  val null-rules = ProductionTable<List<Int>>(nprods, List())
  val any-rules = ProductionTable<List<Int>>(nprods, List())
  val list-end-rules = ProductionTable<List<Int>>(nprods, List())
  val prim-rules = Array<ProductionTable<List<Int>>>(GPrimType-length)
  for i in 0 to length(prim-rules) do :
    prim-rules[i] = ProductionTable<List<Int>>(nprods, List())
  val list-rules = ProductionTable<List<Int>>(nprods, List())
  val keyword-rules = HashTable<[Int,Symbol],List<Int>>(List())

  ;Add to rule sets
  val predict-set = prediction-set(props)
  for rule in rules(grammar) do :
    defn add-to-set (table:ProductionTable<List<Int>>) :
      add(table, prod(rule), id(rule))
    add-to-set(all-rules)
    if nullable-rules(props)[id(rule)] :
      add-to-set(null-rules)
    val pset = predict-set[id(rule)]
    for token in pset do :
      let loop (token:GTerminal = token) :
        match(token) :
          (token:GAny|GListRest) : add-to-set(any-rules)
          (token:GListEnd) : add-to-set(list-end-rules)
          (token:GPrimToken) : add-to-set(prim-rules[to-int(type(token))])
          (token:GListStart) : add-to-set(list-rules)
          (token:GKeyword) : add(keyword-rules, [prod(rule), item(token)], id(rule))
          (token:GMatcherToken) : loop(terminal(token))

  ;Ensure subtraction relationships of sets
  val set-buffer = IntSet()
  defn minus (a:Seqable<Int>, b:Seqable<Int>) :
    add-all(set-buffer, b)
    val result = to-list $ filter({not set-buffer[_]}, a)
    clear(set-buffer)
    result
  defn subtract-map! (atable:ProductionTable<List<Int>>,
                      btables:Collection<ProductionTable<List<Int>>>) :
    for entry in atable map! :
      val prod = key(entry)
      val bset = seq-cat({_[prod]}, btables)
      value(entry) - bset
  defn subtract-map! (atable:HashTable<[Int,Symbol],List<Int>>,
                      btables:Collection<ProductionTable<List<Int>>>) :
    for entry in atable map! :
      val [prod, _] = key(entry)
      val bset = seq-cat({_[prod]}, btables)
      value(entry) - bset
  subtract-map!(keyword-rules, [prim-rules[to-int(GSymbolType)], any-rules, null-rules])
  for prim-i-rules in prim-rules do :
    subtract-map!(prim-i-rules, [any-rules, null-rules])
  subtract-map!(list-rules, [any-rules, null-rules])
  subtract-map!(list-end-rules, [null-rules])
  subtract-map!(any-rules, [null-rules])

  ;Return computed dispatch sets
  DispatchSet(
    all-rules
    null-rules
    any-rules
    list-end-rules
    prim-rules
    list-rules
    keyword-rules)

;============================================================
;================- Negation Set Analysis ====================
;============================================================

deftype KSet
defstruct KeywordSet <: KSet :
  keywords: Tuple<Symbol>
with:
  printer => true

defstruct ProdSet <: KSet :
  name: Symbol
with:
  printer => true

defstruct UnionSet <: KSet :
  sets: Tuple<KSet>
with:
  printer => true

defstruct MinusSet <: KSet :
  a: KSet
  b: KSet
with:
  printer => true

;<comment>
defn convert-negation-rules (rules:Tuple<GRule>) -> Tuple<GMatcherRule|GTokenRule> :
  ;Gather positive and negative tokens
  val negative-table = HashTable<Symbol,List<GToken>>(List())
  val positive-table = HashTable<Symbol,List<GToken>>(List())
  for rule in rules do :
    match(rule) :
      (rule:GNegationRule) :
        add(negative-table, name(rule), token(rule))
      (rule:GTokenRule) :
        if length(tokens(rule)) == 1 :
          val t = tokens(rule)[0]
          add(positive-table, name(rule), t)
      (rule:GMatcherRule) :
        false

  ;Create initial kset table
  val kset-table = HashTable<Symbol,KSet>()
  defn to-kset (name:Symbol) :
    set?(kset-table, name, fn () :
      val psets = to-tuple $ seq(to-kset, positive-table[name])
      val nsets = to-tuple $ seq(to-kset, negative-table[name])
      MinusSet(UnionSet(psets), UnionSet(nsets)))
  defn to-kset (t:GToken) :
    match(t) :
      (t:GProduction) : to-kset(name(t))
      (t:GKeyword) : KeywordSet([item(t)])

  ;Simplify kset
  val simplified-kset-table = HashTable<Symbol,KeywordSet>()
  defn simplify (name:Symbol) :
    set?(simplified-kset-table, name, fn () :
      simplify(to-kset(name)))
  defn simplify (kset:KSet) -> KeywordSet :
    match(kset) :
      (kset:UnionSet) :
        val keywords = seq-cat(keywords{simplify(_)}, sets(kset))
        KeywordSet $ to-tuple $ to-hashset<Symbol>(keywords)
      (kset:MinusSet) :
        val symbols = to-hashset<Symbol>(keywords(simplify(a(kset))))
        do(remove{symbols, _}, keywords(simplify(b(kset))))
        KeywordSet $ to-tuple $ symbols
      (kset:KeywordSet) :
        kset
      (kset:ProdSet) :
        simplify(name(kset))

  ;Compute keywords to subtract from each production
  val subtract-keyword-table = HashTable<Symbol,HashSet<Symbol>>()
  defn subtract-keywords (prod:Symbol) :
    set?(subtract-keyword-table, prod, fn () :
      to-hashset<Symbol> $
        for t in negative-table[prod] seq-cat :
          keywords(simplify(to-kset(t))))

  ;Update matcher rules
  defn update-rule (r:GRule) :
    if key?(negative-table, name(r)) :
      match(r) :
        (r:GMatcherRule) :
        (r:GTokenRule) :
          fatal("Illegal rule with negation.") when length(tokens(r)) != 1
          fatal("Illegal rule with negation.") when lazy-action?(r)
          val terminal = tokens(r)[0] as GTerminal
          GMatcherRule(name(r), terminal, matcher, action(r))
    else : r

  ;Create matcher rule
  defn to-matcher-rules (prod:Symbol) :
    val neg-tokens = negative-table[prod]
    val keywords = seq-cat(keywords{simplify(to-kset(_))}, neg-tokens)
    val keyword-set = to-hashset<Symbol>(keywords)
    defn match? (form) :
      match(unwrap-token(form)) :
        (s:Symbol) : not keyword-set[s]
        (s) : true
    val new-rules = Vector<GRule>()
    val old-prod = gensym(prod)
    add(new-rules, GMatcherRule(prod, [GProduction(old-prod)], match?, fn (result) : result[0]))
    for r in rules do :
      if name(r) == prod and r is-not GNegationRule :
        add(new-rules, sub-name(r, old-prod))
    new-rules

  ;Create matcher rules
  val matcher-rules = seq-cat(to-matcher-rules, keys(negative-table))
  defn standard-rule? (r:GRule) : not key?(negative-table, name(r))
  val remaining-rules = filter(standard-rule?, rules[1 to false])
  val new-rules = to-tuple $ cat-all $ [
    [rules[0]]
     matcher-rules
     remaining-rules]
  new-rules as Tuple<GMatcherRule|GTokenRule>
;<comment>

;============================================================
;================= Create Matcher Tokens ====================
;============================================================

defn create-matcher-tokens (grules:GRules) -> [GRules, Tuple<(? -> True|False)>] :
  val matchers = Vector<(? -> True|False)>()
  defn get-id (m:? -> True|False) :
    add(matchers, m)
    length(matchers) - 1
  val rules* = for r in rules(grules) map :
    match(r) :
      (r:GMatcherRule) :
        val token = GMatcherToken(token(r), get-id(matcher(r)))
        GTokenRule(id(r), prod(r), [token], TokenRuleParams(action(r), false), order(r))
      (r:GTokenRule) :
        r
  val grules* = GRules(productions(grules), rules*)
  [grules*, to-tuple(matchers)]

;<doc>=======================================================
;=============== Make Reluctant Productions =================
;============================================================

Special Productions for Handling Reluctant Matching
  A = Any
  A = LP* R RP
  R = Any* R
  R = LP* R RP R
  R = Rest
  R = empty

;============================================================
;=======================================================<doc>

defn make-reluctant-productions (grules:GRules) -> GRules :
  val gt = GrammarTransformer(grules)
  val mods = Vector<GrammarMod>()

  ;Define special productions
  val A = fresh-production(gt)
  val R = fresh-production(gt)
  add(mods, AddProduction(GDefProduction(id(A), `Any)))
  add(mods, AddProduction(GDefProduction(id(R), `Rest)))

  ;Define new rules for special productions
  defn make-rule (p:GProduction, ts:Tuple<GToken>, action:ParsedResult -> ?) :
    val rule = GTokenRule(rule-id, id(p), ts, params) where :
      val rule-id = fresh-rule(gt)
      val params = TokenRuleParams(default-action)
    add(mods, AddRule(rule))

  ;Shorthands
  val Any = GAny()
  val Any* = GAny(Reluctant)
  val LP* = GListStart(true) ;Left paren
  val RP = GListEnd()        ;Right paren
  val Rest = GListRest()

  ;Rules
  defn head (r:ParsedResult) : /head(form(r))
  defn rest (r:ParsedResult) : form(r)
  make-rule(A, [Any], head)
  make-rule(A, [LP* R RP], head)
  make-rule(R, [Any* R], rest)
  make-rule(R, [LP* R RP R], rest)
  make-rule(R, [Rest], rest)
  make-rule(R, [], rest)

  ;Replace special terminals with special productions
  defn replace-special-tokens (ts:Tuple<GToken>) -> Tuple<GToken> :
    for t in ts map :
      match(t) :
        (t:GListRest) : R
        (t:GAny) : A
        (t) : t

  ;Replace GAny with GAny(Atomic).
  defn replace-atomic (t:GTerminal) -> GTerminal :
    match(t:GAny) : GAny(Atomic)
    else : t

  ;Replace special terminals with special productions.
  for rule in rules(gt) do :
    match(rule) :
      (rule:GTokenRule) :
        val rule* = sub-tokens(rule, replace-special-tokens(tokens(rule)))
        add(mods, SubstituteRule(rule*))
      (rule:GMatcherRule) :
        val rule* = sub-token(rule, replace-atomic(token(rule)))
        add(mods, SubstituteRule(rule*))

  ;Return the modified grammar.
  modify(gt, GrammarModification(to-tuple(mods)))
  grammar(gt)

;============================================================
;==================== Order Rules ===========================
;============================================================
defn order-rules (grules:GRules) -> GRules :
  val rules* = to-tuple(seq(sub-order, rules(grules), 0 to false))
  GRules(productions(grules), rules*)

;============================================================
;======================== Utilities =========================
;============================================================

defn add-all<?T> (q:Queue<?T>, xs:Seqable<T>) :
  do(add{q, _}, xs)

defn add<?K,?V> (table:Table<?K,List<?V>>, k:K, v:V) :
  update(table, cons{v, _,}, k)