#use-added-syntax(tests)
defpackage stz/earley :
  import core
  import collections
  import stz/utils
  import stz/earley-search
  import stz/earley-eitems

;<doc>=======================================================
;========================= Notes ============================
;============================================================

Example Parsing Tables:

  Set 0
    (rule 0) [Start = • X X X AS, S0]
    (rule 5) [X = • x, S0]
  Set 1
    (rule 5) [X = x •, S0]
    (rule 0) [Start = X • X X AS, S0]
    (rule 5) [X = • x, S1]
  Set 2
    (rule 5) [X = x •, S1]
    (rule 0) [Start = X X • X AS, S0]
    (rule 5) [X = • x, S2]
  Set 3
    (rule 5) [X = x •, S2]
    (rule 0) [Start = X X X • AS, S0] (complete as (rule 0) [Start = X X X • AS, S0])
    (rule 1) [AS = • A X BS, S3]
    (rule 6) [A = • a, S3]
  Set 4
    (rule 6) [A = a •, S3]
    (rule 1) [AS = A • X BS, S3]
    (rule 5) [X = • x, S4]
  Set 5
    (rule 5) [X = x •, S4]
    (rule 1) [AS = A X • BS, S3] (complete as (rule 0) [Start = X X X • AS, S0])
    (rule 2) [BS = • B X CS, S5]
    (rule 7) [B = • b, S5]
  Set 6
    (rule 7) [B = b •, S5]
    (rule 2) [BS = B • X CS, S5]
    (rule 5) [X = • x, S6]
  Set 7
    (rule 5) [X = x •, S6]
    (rule 2) [BS = B X • CS, S5] (complete as (rule 0) [Start = X X X • AS, S0])
    (rule 4) [CS = • C X AS, S7]
    (rule 8) [C = • c, S7]
  ...

Explanation of One Set:

  Set 7
    (rule 5) [X = x •, S6]
    (rule 2) [BS = B X • CS, S5] (complete as (rule 0) [Start = X X X • AS, S0])
    (rule 4) [CS = • C X AS, S7]
    (rule 8) [C = • c, S7]

- 'Set 7' indicates that 7 terminals have been parsed thus
far.

- (rule 5) [X = x •, S6] indicates the progress of parsing rule 5,
  which was first started on Set 6, after parsing 6 terminals. 'x' was
  the terminal just parsed, and this rule is now completed, as
  evidenced by the dot at the end.

- (rule 2) [BS = B X • CS, S5]
  (complete as (rule 0) [Start = X X X • AS, S0])  
  indicates the progress of parsing rule 3, which was first started on
  Set 5. The completion rule says that when the last production for
  this rule (CS) is parsed, and this rule is completed, it will
  immediately result in the completion of a chain of other rules,
  ending eventually with the completion of rule 0 started on Set 0.  

- (rule 0) [Start = X X X AS •, S0]
  (complete as (rule 2) [BS = B X CS •, S17])
  indicates that rule 0 has been completed. It was the result of the
  completion of a chain of rules originating with the completion of
  rule 2 started on Set 17.

;============================================================
;=======================================================<doc>

;============================================================
;====================== Definitions =========================
;============================================================

public deftype GRule
public defmulti name (r:GRule) -> Symbol
public defmulti sub-name (r:GRule, name:Symbol) -> GRule

defstruct GNegationRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  token: GToken

public defstruct GMatcherRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  tokens: Tuple<GToken>
  matcher: ? -> True|False
  failure: True|False with: (default => false)
  priority: Int with: (default => 100)
  action: ParsedResult -> ? with: (default => default-action)
  lazy-action?: True|False with: (default => false)

defstruct GTokenRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  tokens: Tuple<GToken>
  failure: True|False with: (default => false)
  priority: Int with: (default => 100)
  associativity: Associativity with: (default => RightAssociative)
  action: ParsedResult -> ? with: (default => default-action)
  lazy-action?: True|False with: (default => false)

defn GMatcherRule (name:Symbol, tokens:Tuple<GToken>, matcher:? -> True|False,
                   action:ParsedResult -> ?, lazy-action?:True|False) :
  GMatcherRule(name, tokens, matcher, false, 100, action, lazy-action?)

defn GMatcherRule (name:Symbol, tokens:Tuple<GToken>, matcher:? -> True|False,
                   action:ParsedResult -> ?) :
  GMatcherRule(name, tokens, matcher, action, false)

defn GTokenRule (name:Symbol,
                 tokens:Tuple<GToken>,
                 action:ParsedResult -> ?,
                 lazy-action?:True|False) :
  GTokenRule(name, tokens, false, 100, RightAssociative, action, lazy-action?)

defn GTokenRule (name:Symbol,
                 tokens:Tuple<GToken>,
                 action:ParsedResult -> ?) :
  GTokenRule(name, tokens, action, false)

defenum Associativity :
  LeftAssociative
  RightAssociative

;+[Earley Matcher Tokens]
public deftype GToken <: Equalable & Hashable & Comparable<GToken>
public defstruct GProduction <: GToken :
  name: Symbol
public deftype GTerminal <: GToken
public defstruct GKeyword <: GTerminal :
  item: Symbol
public defstruct GCharToken <: GTerminal
public defstruct GByteToken <: GTerminal
public defstruct GIntToken <: GTerminal
public defstruct GLongToken <: GTerminal
public defstruct GFloatToken <: GTerminal
public defstruct GDoubleToken <: GTerminal
public defstruct GStringToken <: GTerminal
public defstruct GSymbolToken <: GTerminal
public defstruct GTrueToken <: GTerminal
public defstruct GFalseToken <: GTerminal
  
public defstruct GListStart <: GTerminal :
  reluctant?: True|False with: (default => false)
public defstruct GListEnd <: GTerminal
public defstruct GAny <: GTerminal :
  type: AnyType with: (default => Standard)
public defstruct GListRest <: GTerminal

public defenum AnyType :
  Atomic
  Reluctant
  Standard
;/[Earley Matcher Tokens]

public defstruct ParseNode :
  range: ParsedRange
  children: Tuple<ParseNode|False>

deftype ParsedResult
defmulti get (r:ParsedResult, i:Int) -> ?
defmulti info (r:ParsedResult) -> FileInfo|False
defmulti form (r:ParsedResult) -> List
defn default-action (r:ParsedResult) : false

;============================================================
;======================== Equalable =========================
;============================================================

defmethod equal? (a:GToken, b:GToken) :
  match(a, b) :
    (a:GKeyword, b:GKeyword) : item(a) == item(b)
    (a:GCharToken, b:GCharToken) : true
    (a:GByteToken, b:GByteToken) : true
    (a:GIntToken, b:GIntToken) : true
    (a:GLongToken, b:GLongToken) : true
    (a:GFloatToken, b:GFloatToken) : true
    (a:GDoubleToken, b:GDoubleToken) : true
    (a:GStringToken, b:GStringToken) : true
    (a:GSymbolToken, b:GSymbolToken) : true
    (a:GTrueToken, b:GTrueToken) : true
    (a:GFalseToken, b:GFalseToken) : true
    (a:GProduction, b:GProduction) : name(a) == name(b)
    (a:GListStart, b:GListStart) : true
    (a:GListEnd, b:GListEnd) : true
    (a:GAny, b:GAny) : type(a) == type(b)
    (a:GListRest, b:GListRest) : true
    (a, b) : false

defmethod hash (t:GToken) :
  match(t) :
    (t:GKeyword) : 1 + hash(item(t))
    (t:GProduction) : 2 + hash(name(t))
    (t:GListStart) : 3
    (t:GListEnd) : 4
    (t:GAny) : 5 + hash(to-int(type(t)))
    (t:GListRest) : 6
    (t:GCharToken) : 7
    (t:GByteToken) : 8
    (t:GIntToken) : 9
    (t:GLongToken) : 10
    (t:GFloatToken) : 11
    (t:GDoubleToken) : 12
    (t:GStringToken) : 13
    (t:GSymbolToken) : 14
    (t:GTrueToken) : 15
    (t:GFalseToken) : 16

defmethod compare (a:GToken, b:GToken) :
  defn rank (t:GToken) :
    match(t) :
      (t:GKeyword) : 0
      (t:GProduction) : 1
      (t:GListStart) : 2
      (t:GListEnd) : 3
      (t:GAny) : 4
      (t:GListRest) : 5
      (t:GCharToken) : 6
      (t:GByteToken) : 7
      (t:GIntToken) : 8
      (t:GLongToken) : 9
      (t:GFloatToken) : 10
      (t:GDoubleToken) : 11
      (t:GStringToken) : 12
      (t:GSymbolToken) : 13
      (t:GTrueToken) : 14
      (t:GFalseToken) : 15
  defn compare-token (a:GToken, b:GToken) :
    match(a, b) :
      (a:GProduction, b:GProduction) : compare(name(a), name(b))
      (a:GKeyword, b:GKeyword) : compare(item(a), item(b))
      (a:GAny, b:GAny) : compare(to-int(type(a)), to-int(type(b)))
      (a, b) : 0
  val c = compare(rank(a), rank(b))
  if c == 0 : compare-token(a,b)
  else : c

;============================================================
;======================= Printers ===========================
;============================================================

defmethod print (o:OutputStream, t:GToken) :
  print{o, _} $ match(t) :
    (t:GProduction) : name(t)
    (t:GKeyword) : item(t)
    (t:GCharToken) : "Char"
    (t:GByteToken) : "Byte"
    (t:GIntToken) : "Int"
    (t:GLongToken) : "Long"
    (t:GFloatToken) : "Float"
    (t:GDoubleToken) : "Double"
    (t:GStringToken) : "String"
    (t:GSymbolToken) : "Symbol"
    (t:GTrueToken) : "True"
    (t:GFalseToken) : "False"
    (t:GListStart) : "("
    (t:GListEnd) : ")"
    (t:GAny) : "_"
    (t:GListRest) : "_ ..."

defmethod print (o:OutputStream, r:GRule) :
  print{o, _} $ match(r) :
    (r:GTokenRule) : "%_ = %s" % [name(r), tokens(r)]
    (r:GMatcherRule) : "%_ = custom matcher" % [name(r)]
    (r:GNegationRule) : "%_ != %_" % [name(r), token(r)]

;============================================================
;======================== Utilities =========================
;============================================================

defn add-all<?T> (q:Queue<?T>, xs:Seqable<T>) :
  do(add{q, _}, xs)

defn add<?K,?V> (table:Table<?K,List<?V>>, k:K, v:V) :
  update(table, cons{v, _,}, k)

defn wrap (token, info:FileInfo|False) :
  match(info:FileInfo) : Token(token, info)
  else : token

public defn tokens! (rule:GRule) :
  tokens(rule as GMatcherRule|GTokenRule)

public defn associativity (rule:GMatcherRule) :
  RightAssociative

;============================================================
;==================== Grammar Analysis ======================
;============================================================

public deftype Grammar
public defmulti get (g:Grammar, i:Int) -> GRule
public defmulti nullable? (g:Grammar, production:Symbol) -> True|False
public defmulti rules (g:Grammar, production:Symbol, next-input:SExpToken) -> Seqable<Int>
public defmulti rules (g:Grammar, production:Symbol) -> Seqable<Int>

public defn Grammar (input-rules:Tuple<GRule>) :
  val rules = convert-negation-rules(input-rules)
  val grammar-properties = analyze-grammar-properties(rules)
  val null-prods = nullable-productions(grammar-properties)
  val dispatch-sets = analyze-dispatch-sets(rules, grammar-properties)
  new Grammar :
    defmethod get (this, i:Int) :
      rules[i]
    defmethod nullable? (this, production:Symbol) :
      null-prods[production]
    defmethod rules (this, production:Symbol) :
      all-rules(dispatch-sets)[production]
    defmethod rules (this, production:Symbol, next-input:SExpToken) :
      match(next-input) :
        (input:SExpWildcard) :
          all-rules(dispatch-sets)[production]
        (input:SExpForm) :
          val x = unwrap-token(form(input))
          val obj-rules = match(x) :
            (x:Symbol) : keyword-rules(dispatch-sets)[[production, x]]
            (x) : List()
          val type-rules = match(x) :
            (x:Char) : char-rules(dispatch-sets)[production]
            (x:Byte) : byte-rules(dispatch-sets)[production]
            (x:Int) : int-rules(dispatch-sets)[production]
            (x:Long) : long-rules(dispatch-sets)[production]
            (x:Float) : float-rules(dispatch-sets)[production]
            (x:Double) : double-rules(dispatch-sets)[production]
            (x:String) : string-rules(dispatch-sets)[production]
            (x:True) : true-rules(dispatch-sets)[production]
            (x:False) : false-rules(dispatch-sets)[production]
            (x:Symbol) : symbol-rules(dispatch-sets)[production]
            (x:List) : list-rules(dispatch-sets)[production]
            (x) : List()
          cat-all $ [
            obj-rules,
            type-rules,
            any-rules(dispatch-sets)[production]
            null-rules(dispatch-sets)[production]]              
        (input:SExpListEnd) :
          cat(
            list-end-rules(dispatch-sets)[production]
            null-rules(dispatch-sets)[production])

;------------------------------------------------------------
;------------------ Grammar Properties ----------------------
;------------------------------------------------------------

defstruct GrammarProperties:
  nullable-productions: HashSet<Symbol>
  nullable-rules: IntSet
  first-sets: Tuple<Tuple<GTerminal>>

defn analyze-grammar-properties (grammar:Tuple<GMatcherRule|GTokenRule>) :
  ;Compute parent rules that contain each production.
  val parent-table:HashTable<Symbol,List<Int>> = group-by{key, value, _} $
    for (rule in grammar, rule-index in 0 to false) seq-cat :
      for prod in filter-by<GProduction>(tokens(rule)) seq :
        name(prod) => rule-index

  ;Production worklist algorithm
  defn worklist (f:(Int, GMatcherRule|GTokenRule, () -> False) -> ?) :
    val queue = Queue<Int>()
    add-all(queue, 0 to length(grammar))
    while not empty?(queue) :
      val rule-index = pop(queue)
      val rule = grammar[rule-index]
      var progress?:True|False = false
      defn progress () : progress? = true
      f(rule-index, rule, progress)
      if progress? :
        add-all(queue, parent-table[name(rule)])

  ;Compute nullable productions and rules
  val null-prods = HashSet<Symbol>()
  val null-rules = IntSet()
  defn nullable? (t:GToken) :
    match(t:GProduction) :
      null-prods[name(t)]
  defn nullable? (rule:GMatcherRule|GTokenRule) :
    all?(nullable?, tokens(rule))
  within (rule-index, rule, progress) = worklist() :
    if nullable?(rule) :
      add(null-rules, rule-index)
      progress() when add(null-prods, name(rule))

  ;Compute firstsets
  val first-set-entries = HashSet<KeyValue<Symbol,GTerminal>>()
  val first-set-table = HashTable<Symbol,List<GTerminal>>(List())  
  defn first-set (t:GToken) :
    match(t) :
      (t:GTerminal) : [t]
      (t:GProduction) : first-set-table[name(t)]
  defn first-set (rule:GMatcherRule|GTokenRule) :
    generate<GTerminal> :
      let loop (i:Int = 0) :
        if i < length(tokens(rule)) :
          val t = tokens(rule)[i]
          do(yield, first-set(t))
          loop(i + 1) when nullable?(t)
  within (rule-index, rule, progress) = worklist() :
    for t in first-set(rule) do :
      if add(first-set-entries, name(rule) => t) :
        add(first-set-table, name(rule), t)
        progress()
  val first-sets = for rule in grammar map :
    to-tuple $ unique $ first-set(rule)

  ;Return all properties
  GrammarProperties(
    null-prods,
    null-rules,
    first-sets)

;------------------------------------------------------------
;------------------ Dispatch Sets ---------------------------
;------------------------------------------------------------

defstruct DispatchSet :
  all-rules:HashTable<Symbol,List<Int>>
  null-rules:HashTable<Symbol,List<Int>>
  any-rules:HashTable<Symbol,List<Int>>
  list-end-rules:HashTable<Symbol,List<Int>>
  char-rules:HashTable<Symbol,List<Int>>
  byte-rules:HashTable<Symbol,List<Int>>
  int-rules:HashTable<Symbol,List<Int>>
  long-rules:HashTable<Symbol,List<Int>>
  float-rules:HashTable<Symbol,List<Int>>
  double-rules:HashTable<Symbol,List<Int>>
  string-rules:HashTable<Symbol,List<Int>>
  true-rules:HashTable<Symbol,List<Int>>
  false-rules:HashTable<Symbol,List<Int>>
  symbol-rules:HashTable<Symbol,List<Int>>
  list-rules:HashTable<Symbol,List<Int>>
  keyword-rules:HashTable<[Symbol,Symbol],List<Int>>

defn analyze-dispatch-sets (grammar:Tuple<GRule>, props:GrammarProperties) :
  ;Create rule sets
  val all-rules = HashTable<Symbol,List<Int>>(List())
  val null-rules = HashTable<Symbol,List<Int>>(List())
  val any-rules = HashTable<Symbol,List<Int>>(List())
  val list-end-rules = HashTable<Symbol,List<Int>>(List())
  val char-rules = HashTable<Symbol,List<Int>>(List())
  val byte-rules = HashTable<Symbol,List<Int>>(List())
  val int-rules = HashTable<Symbol,List<Int>>(List())
  val long-rules = HashTable<Symbol,List<Int>>(List())
  val float-rules = HashTable<Symbol,List<Int>>(List())
  val double-rules = HashTable<Symbol,List<Int>>(List())
  val string-rules = HashTable<Symbol,List<Int>>(List())
  val true-rules = HashTable<Symbol,List<Int>>(List())
  val false-rules = HashTable<Symbol,List<Int>>(List())
  val symbol-rules = HashTable<Symbol,List<Int>>(List())
  val list-rules = HashTable<Symbol,List<Int>>(List())
  val keyword-rules = HashTable<[Symbol,Symbol],List<Int>>(List())

  ;Add to rule sets
  for (rule in grammar, rule-index in 0 to false, fset in first-sets(props)) do :
    defn add-to-set (table:HashTable<Symbol,List<Int>>) :
      add(table, name(rule), rule-index)
    add-to-set(all-rules)
    if nullable-rules(props)[rule-index] :
      add-to-set(null-rules)
    for token in fset do :
      match(token) :
        (token:GAny|GListRest) : add-to-set(any-rules)
        (token:GListEnd) : add-to-set(list-end-rules)
        (token:GCharToken) : add-to-set(char-rules)
        (token:GByteToken) : add-to-set(byte-rules)
        (token:GIntToken) : add-to-set(int-rules)
        (token:GLongToken) : add-to-set(long-rules)
        (token:GFloatToken) : add-to-set(float-rules)
        (token:GDoubleToken) : add-to-set(double-rules)
        (token:GStringToken) : add-to-set(string-rules)
        (token:GTrueToken) : add-to-set(true-rules)
        (token:GFalseToken) : add-to-set(false-rules)
        (token:GSymbolToken) : add-to-set(symbol-rules)
        (token:GListStart) : add-to-set(list-rules)
        (token:GKeyword) : add(keyword-rules, [name(rule), item(token)], rule-index)

  ;Ensure subtraction relationships of sets
  val set-buffer = IntSet()
  defn minus (a:Seqable<Int>, b:Seqable<Int>) :
    add-all(set-buffer, b)
    val result = to-list $ filter({not set-buffer[_]}, a)
    clear(set-buffer)
    result
  defn subtract-map! (atable:HashTable<Symbol,List<Int>>,
                      btables:Collection<HashTable<Symbol,List<Int>>>) :
    for entry in atable map! :
      val prod = key(entry)
      val bset = seq-cat({_[prod]}, btables)
      value(entry) - bset
  defn subtract-map! (atable:HashTable<[Symbol,Symbol],List<Int>>,
                      btables:Collection<HashTable<Symbol,List<Int>>>) :
    for entry in atable map! :
      val [prod, _] = key(entry)
      val bset = seq-cat({_[prod]}, btables)
      value(entry) - bset  
  subtract-map!(keyword-rules, [symbol-rules, any-rules, null-rules])
  subtract-map!(char-rules, [any-rules, null-rules])
  subtract-map!(byte-rules, [any-rules, null-rules])
  subtract-map!(int-rules, [any-rules, null-rules])
  subtract-map!(long-rules, [any-rules, null-rules])
  subtract-map!(float-rules, [any-rules, null-rules])
  subtract-map!(double-rules, [any-rules, null-rules])
  subtract-map!(string-rules, [any-rules, null-rules])
  subtract-map!(true-rules, [any-rules, null-rules])
  subtract-map!(false-rules, [any-rules, null-rules])
  subtract-map!(symbol-rules, [any-rules, null-rules])
  subtract-map!(list-rules, [any-rules, null-rules])
  subtract-map!(list-end-rules, [null-rules])
  subtract-map!(any-rules, [null-rules])
  
  ;Return computed dispatch sets
  DispatchSet(
    all-rules
    null-rules
    any-rules
    list-end-rules
    char-rules
    byte-rules
    int-rules
    long-rules
    float-rules
    double-rules
    string-rules
    true-rules
    false-rules
    symbol-rules
    list-rules
    keyword-rules)

;------------------------------------------------------------
;----------------- Negation Set Analysis --------------------
;------------------------------------------------------------

deftype KSet
defstruct KeywordSet <: KSet :
  keywords: Tuple<Symbol>
with:
  printer => true
  
defstruct ProdSet <: KSet :
  name: Symbol
with:
  printer => true
  
defstruct UnionSet <: KSet :
  sets: Tuple<KSet>
with:
  printer => true
  
defstruct MinusSet <: KSet :
  a: KSet
  b: KSet
with:
  printer => true

defn convert-negation-rules (rules:Tuple<GRule>) -> Tuple<GMatcherRule|GTokenRule> :
  ;Gather positive and negative tokens
  val negative-table = HashTable<Symbol,List<GToken>>(List())
  val positive-table = HashTable<Symbol,List<GToken>>(List())
  for rule in rules do :
    match(rule) :
      (rule:GNegationRule) :
        add(negative-table, name(rule), token(rule))
      (rule:GTokenRule) :
        if length(tokens(rule)) == 1 :
          val t = tokens(rule)[0]
          add(positive-table, name(rule), t)
      (rule:GMatcherRule) :
        false
        
  ;Create initial kset table
  val kset-table = HashTable<Symbol,KSet>()
  defn to-kset (name:Symbol) :
    set?(kset-table, name, fn () :
      val psets = to-tuple $ seq(to-kset, positive-table[name])
      val nsets = to-tuple $ seq(to-kset, negative-table[name])
      MinusSet(UnionSet(psets), UnionSet(nsets)))
  defn to-kset (t:GToken) :
    match(t) :
      (t:GProduction) : to-kset(name(t))
      (t:GKeyword) : KeywordSet([item(t)])
      
  ;Simplify kset
  val simplified-kset-table = HashTable<Symbol,KeywordSet>()
  defn simplify (name:Symbol) :
    set?(simplified-kset-table, name, fn () :
      simplify(to-kset(name)))
  defn simplify (kset:KSet) -> KeywordSet :
    match(kset) :
      (kset:UnionSet) :
        val keywords = seq-cat(keywords{simplify(_)}, sets(kset))
        KeywordSet $ to-tuple $ to-hashset<Symbol>(keywords)
      (kset:MinusSet) :
        val symbols = to-hashset<Symbol>(keywords(simplify(a(kset))))
        do(remove{symbols, _}, keywords(simplify(b(kset))))
        KeywordSet $ to-tuple $ symbols
      (kset:KeywordSet) :
        kset
      (kset:ProdSet) :
        simplify(name(kset))

  ;Create matcher rule
  defn to-matcher-rules (prod:Symbol) :
    val neg-tokens = negative-table[prod]
    val keywords = seq-cat(keywords{simplify(to-kset(_))}, neg-tokens)
    val keyword-set = to-hashset<Symbol>(keywords)
    defn match? (form) :
      match(unwrap-token(form)) :
        (s:Symbol) : not keyword-set[s]
        (s) : true
    val new-rules = Vector<GRule>()
    val old-prod = gensym(prod)
    add(new-rules, GMatcherRule(prod, [GProduction(old-prod)], match?, fn (result) : result[0]))
    for r in rules do :
      if name(r) == prod and r is-not GNegationRule :
        add(new-rules, sub-name(r, old-prod))
    new-rules

  ;Create matcher rules  
  val matcher-rules = seq-cat(to-matcher-rules, keys(negative-table))
  defn standard-rule? (r:GRule) : not key?(negative-table, name(r))
  val remaining-rules = filter(standard-rule?, rules[1 to false])
  val new-rules = to-tuple $ cat-all $ [
    [rules[0]]
     matcher-rules
     remaining-rules]
  new-rules as Tuple<GMatcherRule|GTokenRule>

;============================================================
;==================== Error Handling ========================
;============================================================

public defstruct MissingInput :
  input
  set-index: Int
  info: FileInfo|False
  items: Tuple<EItem>

defstruct MissingInputError <: Exception :
  input
  info: FileInfo|False
  productions: Tuple<Symbol>
  upcoming: Tuple<GToken>

public defstruct ParsingErrors <: Exception :
  errors: Tuple<Exception>

public defn to-exception (g:Grammar, m:MissingInput) :
  ;Compute earliest completed productions
  defn completed? (item:EItem) :
    val tokens = tokens!(g[rule(item)])
    num-parsed(item) == length(tokens)
  val completed-productions = HashTable<Symbol,Int>(INT-MAX)
  for item in filter(completed?,items(m)) do :
    update(completed-productions, min{_, parent(item)}, production(g,item))

  ;Compute productions and upcoming
  val productions = HashSet<Symbol>()
  val upcoming-tokens = HashSet<GToken>()
  for item in items(m) do :
    if passed-guard?(item) :
      val production = production(g,item)    
      val include? = match(upcoming(g,item)) :
        (t:GTerminal) :
          num-parsed(item) > 0 and
          completed-productions[production] > parent(item)
        (t:GProduction) :
          completed-productions[production] > parent(item)
        (t:False) :
          false
      if include? :
        add(productions, production)
        add(upcoming-tokens, upcoming(g, item) as GToken)

  ;Return error
  MissingInputError(input(m), info(m), to-tuple(productions), qsort(upcoming-tokens))

public defn to-exception (g:Grammar, input-ms:Collection<MissingInput>) :  
  val ms = to-tuple(input-ms)
  defn first-in-chain? (i:Int) : i == 0 or set-index(ms[i - 1]) < set-index(ms[i]) - 1
  val es = seq(to-exception{g, ms[_]}, filter(first-in-chain?, 0 to length(ms)))
  ParsingErrors $ to-tuple $ es

defmethod print (o:OutputStream, e:MissingInputError) :
  val info-str = "" when info(e) is False else "%_: " % [info(e)]
  val input-str = match(input(e)) :
    (x:EndOfInput) : "end of input"
    (x:SExpForm) :
      match(unwrap-token(form(x))) :
        (f:Symbol) : "symbol '%~'" % [f]
        (f:List) : "list"
        (f) : "input '%~'" % [f]
    (x:SExpListEnd) : "end of list"
  defn token-str (t:GToken) :
    match(t) :
      (t:GProduction) : "a '%~' production" % [name(t)]
      (t:GKeyword) : "'%~'" % [item(t)]
      (t:GListStart) : "a list"
      (t:GListEnd) : "the end of the list"
      (t:GAny) : "a form"
      (t) : t
  defn tokens-str (ts:Tuple<GToken>) :
    if length(ts) == 1 :
      token-str(ts[0])
    else :
      val but-last-t = ts[0 to length(ts) - 1]
      val last-t = ts[length(ts) - 1]
      "either %,, or %_" % [seq(token-str,but-last-t), token-str(last-t)]
  defn productions-str (names:Tuple<Symbol>) :
    tokens-str(map(GProduction,names))
  print(o, "%_Unexpected %_." % [info-str, input-str])
  if not empty?(productions(e)) :
    print(o, " Current parsing %_ and %_ is expected next." % [
      productions-str(productions(e)), tokens-str(upcoming(e))])

defmethod print (o:OutputStream, e:ParsingErrors) :
  print(o, "Could not parse the given input:")
  val o2 = IndentedStream(o)
  do(lnprint{o2, _}, errors(e))

;============================================================
;====================== Debugging ===========================
;============================================================

public defn print-current-set (grammar:Grammar, set-index:Int, current-set:ESet) :
  println("Set %_" % [set-index])
  within indented() :
    do(println{format(grammar,_)}, current-set)

;public defn format (grammar:Grammar, eset:Vector<EItem>) :
;  within o = printable-stream() :
;    val o2 = IndentedStream(o)
;    print(o, "ESet :")
;    do(lnprint{o2, format(grammar,_)}, eset)

public defn format (grammar:Grammar, r:ParsedRange) :
  "(rule %_) [%_ to %_] %_" % [rule(r), start(r), end(r), grammar[rule(r)]]

public defn format (grammar:Grammar, node:ParseNode) :
  within o = Printable() :
    print(o, format(grammar, range(node)))
    val o2 = IndentedStream(o)
    do(lnprint{o2, format(grammar,_)}, filter-by<ParseNode>(children(node)))

defn Printable (f:OutputStream -> ?) :
  new Printable :
    defmethod print (o:OutputStream, this) :
      f(o)

;============================================================
;=================== SExpression Stream =====================
;============================================================

;+[SExpStream Definition]
public deftype SExpStream
public defmulti peek (s:SExpStream) -> SExpToken
public defmulti advance (s:SExpStream, expand-list?:True|False) -> False
public defmulti advance-rest (s:SExpStream) -> False
public defmulti insert-wildcard (s:SExpStream) -> False
public defmulti insert-list (s:SExpStream) -> False
public defmulti info (s:SExpStream) -> FileInfo|False

;+[SExpToken Definition]
public deftype SExpToken
public defstruct SExpForm <: SExpToken :
  form
  list:List
with:
  printer => true
public defstruct SExpWildcard <: SExpToken
public defstruct SExpListEnd <: SExpToken
public defstruct EndOfInput <: SExpToken

public defn list (t:SExpListEnd) :
  List()

public defn SExpStream (input:List) :
  val stack = Vector<List>()
  var current:List|False = input
  var info:FileInfo|False = false

  defn update-info () :
    match(current:List) :
      if not empty?(current) :
        val t = head(current)
        match(t:Token) :
          info = /info(t)

  defn peek-stream () :
    match(current:List) :
      if empty?(current) : SExpListEnd()
      else :
        match(head(current)) :
          (t:SExpWildcard) : t
          (t) : SExpForm(t, current)
    else : EndOfInput()

  defn advance-stream (expand-list?:True|False) :
    fatal("No more tokens.") when current is False
    val curr = current as List
    if empty?(curr) :
      current = pop(stack) when not empty?(stack)
    else :
      val expand? = expand-list? and
                    unwrap-token(head(curr)) is List
      if expand? :
        add(stack, tail(curr))
        current = unwrap-token(head(curr)) as List
      else :
        current = tail(curr)
    update-info()

  update-info()
  new SExpStream :
    defmethod info (this) :
      info
    defmethod peek (this) :
      peek-stream()
    defmethod advance (this, expand-list?:True|False) :
      advance-stream(expand-list?)
    defmethod advance-rest (this) :
      current = List()
    defmethod insert-wildcard (this) :
      current = cons(SExpWildcard(), current as List)
    defmethod insert-list (this) :
      current = cons(List(), current as List)
;/[SExpStream Definition]

;============================================================
;====================== RangeTable ==========================
;============================================================

defstruct ParsedRange <: Equalable&Hashable :
  rule: Int
  start: Int
  end: Int
with:
  printer => true

defmethod equal? (a:ParsedRange, b:ParsedRange) :
  rule(a) == rule(b) and
  start(a) == start(b) and
  end(a) == end(b)

defmethod hash (a:ParsedRange) :
  hash(rule(a)) + 7 * hash(start(a)) + 11 * hash(end(a))

defn length (r:ParsedRange) :
  end(r) - start(r)

;============================================================
;================ Construct Parse Forest ====================
;============================================================

public deftype ParseForest
public defmulti get (f:ParseForest, r:ParsedRange, index:Int, position:Int) -> Seqable<ParsedRange>
public defmulti start (f:ParseForest) -> ParsedRange

defstruct RulePos <: Hashable&Equalable :
  rule: Int
  num-parsed: Int
  rule-start: Int
  position: Int
with:
  printer => true

defstruct ProdPos <: Hashable&Equalable :
  production: Symbol
  position: Int

defstruct EItemCore <: Hashable&Equalable :
  rule: Int
  num-parsed: Int
  parent: Int

public defn core (item:EItem) :
  EItemCore(rule(item), num-parsed(item), parent(item))

defn parts (k:EItemCore) : [rule(k), num-parsed(k), parent(k)]
defmethod equal? (a:EItemCore, b:EItemCore) : parts(a) == parts(b)
defmethod hash (k:EItemCore) : hash(parts(k))

val hash-timer = MillisecondTimer("Hash RulePos")
defn parts (k:RulePos) : [rule(k), num-parsed(k), rule-start(k), position(k)]
defmethod equal? (a:RulePos, b:RulePos) : parts(a) == parts(b)
defmethod hash (k:RulePos) :
  start(hash-timer)
  val result = hash(parts(k))
  stop(hash-timer)
  result

defn parts (k:ProdPos) : [production(k), position(k)]
defmethod equal? (a:ProdPos, b:ProdPos) : parts(a) == parts(b)
defmethod hash (k:ProdPos) : hash(parts(k))

public defn ParseForest (grammar:Grammar, setlist:ESetList) :
  ;Construct tables
  val rule-positions = HashSet<RulePos>()
  defn fill-rule-positions () :
    for eset in sets(setlist) do :
      for item in items(setlist,eset) do :
        add(rule-positions, RulePos(rule(item), num-parsed(item), parent(item), index(eset)))
  println(hash-timer)      

  ;Compute right recursion chains
  val completion-chains = HashTable<EItemCore, List<EItem>>()
  val completion-chain-productions-table = HashTable<EItemCore,List<Symbol>>()
  defn completion-parent? (item:EItem) -> Maybe<EItem> :
    fatal("Illegal argument.") when upcoming(grammar,item) is-not False
    val parent = first-item(setlist, parent(item), production(grammar,item)) as EItem
    val root = completion-root(parent) as EItem
    if core(parent) == core(root) : None()
    else : One(inc-num-parsed(parent))
    
  defn completion-chain (item:EItem) :
    set?(completion-chains, core(item), fn () :
      val p = completion-parent?(item)
      val rest = List() when empty?(p) else completion-chain(value!(p))
      cons(item, rest))

  defn completion-chain-productions (item:EItem) :
    set?(completion-chain-productions-table, core(item), fn () :
      val p = completion-parent?(item)
      val rest = List() when empty?(p) else completion-chain-productions(value!(p))
      val prod = production(grammar,item)
      rest when contains?(rest,prod) else cons(prod,rest))    

  ;Collect completion chains
  val pending-completion-chains = Vector<List<EItem>>()
  val pending-completions = HashTable<ProdPos,Int>()
  defn add-pending-completion-chain (set-index:Int, root:EItem) :
    val chain = completion-chain(root)
    val chain-index = length(pending-completion-chains)
    add(pending-completion-chains, chain)    
    for prod in completion-chain-productions(root) do :
      val prodpos = ProdPos(prod, set-index)
      pending-completions[prodpos] = chain-index
  defn pending-chains (return:EItem -> ?, prodpos:ProdPos) -> False :
    val index = get?(pending-completions, prodpos)
    match(index:Int) :
      if not empty?(pending-completion-chains[index]) :
        within with-timer("Compute pending completion chain") :
          do(return, pending-completion-chains[index])
      pending-completion-chains[index] = List()
      remove(pending-completions, prodpos)
      false
  defn collect-pending-completion-chains () :
    for eset in sets(setlist) do :
      for item in items(setlist, eset) do :
        if upcoming(grammar,item) is False :
          val root = completion-root(item)
          match(root:EItem) :
            println("Add completion chain for %_ with root %_" % [format(grammar,item), format(grammar,root)])
            add-pending-completion-chain(index(eset), root)

  ;Construct production tables
  val production-ranges = HashTable<ProdPos, List<ParsedRange>>(List())
  defn add-production-range (set-index:Int, item:EItem) :
    val prodpos = ProdPos(production(grammar,item), set-index)
    val range = ParsedRange(rule(item), parent(item), set-index)
    add(production-ranges, prodpos, range)
  defn fill-production-table () :
    for eset in sets(setlist) do :
      for item in items(setlist, eset) do :
        if upcoming(grammar,item) is False :
          add-production-range(index(eset), item)
  defn get-production-ranges (prodpos:ProdPos) :
    within item = pending-chains(prodpos) :
      add-production-range(position(prodpos), item)
    production-ranges[prodpos]

  ;Retrieve child ranges
  val child-range-timer = MillisecondTimer("Child Range Timer")
  defn child-ranges (range:ParsedRange, index:Int, end-position:Int) :
    start(child-range-timer)
    val token = tokens!(grammar[rule(range)])[index]
    val production = name(token as GProduction)
    val result = to-tuple $ for child in get-production-ranges(ProdPos(production, end-position)) filter :
      rule-positions[RulePos(rule(range), index, start(range), start(child))]
    stop(child-range-timer)
    println(child-range-timer)
    result

  ;Fill tables
  within with-timer("fill rule positions") :
    fill-rule-positions()
  within with-timer("collect pending completion chains") :
    collect-pending-completion-chains()
  within with-timer("fill production table") :
    fill-production-table()

  ;defn test-children (range:ParsedRange, index:Int, end-position:Int) :
  ;  println("Children of %_ (index %_) (ending at %_):" % [format(grammar,range), index, end-position])
  ;  within indented() :
  ;    for child in child-ranges(range, index, end-position) do :
  ;      println(format(grammar,child))
  ;
  ;;TEST
  ;let :
  ;  val end = length(setlist) - 1
  ;  test-children(ParsedRange(0, 0, end), 3, end)
  ;  test-children(ParsedRange(1, 3, 20), 2, 20)
  ;  test-children(ParsedRange(1, 3, 20), 1, 5)
  ;  test-children(ParsedRange(1, 3, 20), 0, 4)
  ;  test-children(ParsedRange(2, 5, 20), 2, 20)
  ;  test-children(ParsedRange(2, 5, 20), 1, 7)
  ;  test-children(ParsedRange(2, 5, 20), 0, 6)
          
  new ParseForest :
    defmethod get (this, range:ParsedRange, index:Int, end-position:Int) :
      child-ranges(range, index, end-position)
    defmethod start (this) :
      ParsedRange(0, 0, length(setlist) - 1)      

public defn with-timer<?T> (f:() -> ?T, name:String) :
  val timer = MillisecondTimer(name)
  start(timer)
  val result = f()
  stop(timer)
  println(timer)
  result
  
;============================================================
;================ Selecting the Parse Tree ==================
;============================================================

public defn select-tree (grammar:Grammar, forest:ParseForest) -> ParseNode :
  val node-table = HashTable<ParsedRange,ParseNode>()

  defn select (range:ParsedRange) -> ParseNode :
    set?(node-table, range, fn () :
      val grule = grammar[rule(range)] as GMatcherRule|GTokenRule
      val children = Vector<ParseNode|False>()
      val num-tokens = length(tokens(grule))
      let loop (index:Int = num-tokens - 1, position:Int = end(range)) :
        if index >= 0 :
          match(tokens(grule)[index]) :
            (t:GTerminal) :
              add(children, false)
              loop(index - 1, position - 1)
            (t:GProduction) :
              val child-ranges = forest[range, index, position]
              val child-range = minimum(child-ranges, {compare-specificity(grammar, rule(range), _, _) < 0})
              val child = select(child-range)
              add(children, child)
              loop(index - 1, start(/range(child)))
      reverse!(children)        
      ParseNode(range, to-tuple(children)))

  ;Launch!
  select(start(forest))

;Return -1 if a should take priority over b during a right-to-left disambiguation sweep of the parse forest.
defn compare-specificity (grammar:Grammar, parent-rule-index:Int, a:ParsedRange, b:ParsedRange) :
  val parent-rule = grammar[parent-rule-index] as GMatcherRule|GTokenRule
  val rule-a = grammar[rule(a)] as GMatcherRule|GTokenRule
  val rule-b = grammar[rule(b)] as GMatcherRule|GTokenRule
  defn compare-associativity () :
    switch(associativity(parent-rule)) :
      LeftAssociative : compare(length(a), length(b))
      RightAssociative : compare(length(b), length(a))
  defn compare-priority () :
    compare(priority(rule-b), priority(rule-a))
  defn compare-order () :
    compare(rule(a), rule(b))
  val c1 = compare-associativity()
  if c1 == 0 :
    val c2 = compare-priority()
    if c2 == 0 : compare-order()
    else : c2
  else : c1  

;============================================================
;================= Evaluate the Parse Tree ==================
;============================================================

defn evaluate-parse-tree (parse-result:ParseResult) :
  ;Pull out fields
  val grammar = grammar(parse-result)
  val inputlist = inputlist(parse-result)
  val infolist = infolist(parse-result)
  
  ;Accumulated errors                        
  val errors = Vector<Exception>()

  ;Attempt evaluation of a given ParseNode
  defn evaluate (tree:ParseNode) -> Maybe :
    ;Retrieve rule
    val rule = grammar[rule(range(tree))] as GMatcherRule|GTokenRule
    defn evaluate-child (i:Int) -> Maybe :
      match(children(tree)[i]) :
        (child:ParseNode) :
          evaluate(child)
        (f:False) :
          val token = tokens(rule)[i]
          val input = inputlist[start(range(tree)) + i]
          match(token, input) :
            (token:GListRest, input:SExpForm|SExpListEnd) : One(list(input))
            (token:GListEnd, input:SExpListEnd) : One(false)
            (token, input:SExpForm) : One(form(input))
            
    ;Lazy evaluation
    defn lazy-evaluation () :
      val result = new ParsedResult :
        defmethod get (this, i:Int) :
          val v = evaluate-child(i)
          throw(ChildNotEvaluated()) when empty?(v)
          value!(v)
        defmethod info (this) : infolist[start(range(tree))]
        defmethod form (this) : list(inputlist[start(range(tree))] as SExpForm|SExpListEnd)
      try :
        One(action(rule)(result))
      catch (e:ChildNotEvaluated) :
        None()
      catch (e:Exception) :
        add(errors, e)
        None()
        
    ;Eager evaluation
    defn eager-evaluation () :
      val results = to-tuple $
        seq(evaluate-child, 0 to length(tokens(rule)))
      if none?(empty?, results) :
        val result = new ParsedResult :
          defmethod get (this, i:Int) : value!(results[i])
          defmethod info (this) : infolist[start(range(tree))]
          defmethod form (this) : list(inputlist[start(range(tree))] as SExpForm|SExpListEnd)
        try :
          One(action(rule)(result))
        catch (e:Exception) :
          add(errors, e)
          None()
      else :
        None()

    ;Launch!
    if lazy-action?(rule) : lazy-evaluation()
    else : eager-evaluation()

  ;Launch!
  val v = evaluate(node(parse-result))
  if empty?(v) : throw(ParsingErrors(to-tuple(errors)))
  else : value!(v)

defstruct ChildNotEvaluated <: Exception

;============================================================
;==================== Overall Launcher ======================
;============================================================

defn parse (grammar:Grammar, input:List) :
  match(parse-result(grammar, input)) :
    (r:ParseResult) : evaluate-parse-tree(r)
    (e:ParsingErrors) : throw(e)  

;============================================================
;======================= Test Case ==========================
;============================================================

defn test-parse (rules:Tuple<GRule>, input:List) :
  val g = Grammar(rules)
  match(parse-result(g, input)) :
    (n:ParseResult) : println(format(g,node(n)))
    (e:ParsingErrors) : println(e)

defn test-parse-action (rules:Tuple<GRule>, input:List) :
  println(parse(Grammar(rules), input))

defn example-grammar () :
  val E = GProduction(`E)
  val N = GKeyword(`N)
  val PLUS = GKeyword(`+)
  val TIMES = GKeyword(`x)
  val LPAREN = GKeyword(`L)
  val RPAREN = GKeyword(`R)
  [GTokenRule(`S, [E])
   GTokenRule(`E, [E PLUS E], false, 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], false, 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])]

deftest print-grammar :
  val g = example-grammar()
  do(println, g)

deftest parse :
  test-parse(example-grammar(), `(N x N x L N + N R x N x N + N x N x N))

defn example-grammar-2 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val B = GKeyword(`B)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [E E X])
   GTokenRule(`S, [F F Y])
   GTokenRule(`E, [A A B])
   GTokenRule(`F, [A A B])]

deftest parse-2 :
  val g = example-grammar-2()
  test-parse(g, `(A A B A A B Y))

defn example-grammar-3 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [E F X])
   GTokenRule(`S, [F E X])
   GTokenRule(`S, [F F F Y])
   GTokenRule(`E, [A A])
   GTokenRule(`F, [A])]

deftest parse-3 :
  val g = example-grammar-3()
  test-parse(g, `(A A A X))

defn example-grammar-4 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [E E X])
   GTokenRule(`E, [A])
   GTokenRule(`E, [A A])]

deftest parse-4 :
  val g = example-grammar-4()
  test-parse(g, `(A A A A X))

defn example-grammar-5 () :
  #for E in [ES, E, IF-E, SCLAUSES, SCLAUSE, ECLAUSE] :
    val E = GProduction(`E)
  #for (X in [PLUS, TIMES, LPAREN, RPAREN, N, EQ, LET, IN, IF, COLON, ELSE, SWITCH],
        x in [+, x, L, R, N, =, let, in, if, :, else, switch]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [E PLUS E], false, 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], false, 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])
   GTokenRule(`E, [E EQ E])
   GTokenRule(`E, [LET E EQ E IN E])
   GTokenRule(`E, [IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE COLON E])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES ECLAUSE RPAREN])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES RPAREN])
   GTokenRule(`SCLAUSES, [SCLAUSE SCLAUSES])
   GTokenRule(`SCLAUSES, [])
   GTokenRule(`SCLAUSE, [E COLON E])
   GTokenRule(`ECLAUSE, [ELSE COLON E])]

deftest grammar-calc :
  Grammar(example-grammar-5())

deftest parse-5 :
  val g = example-grammar-5()
  test-parse(g, `(
    switch L
      N : N x N
      N x N : N
      N + N : N + N 
      else : N x N
    R))

deftest parse-5-2 :
  val g = example-grammar-5()
  test-parse(g, `(N + N x N + N))

deftest parse-6 :
  test-parse(example-grammar-5(), reader/read-file("test.txt"))

defn example-grammar-6 () :
  #for E in [ES, E] :
    val E = GProduction(`E)
  #for (X in [A B C],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [ES])
   GTokenRule(`ES, [E, ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [A])
   GTokenRule(`E, [B C])]

deftest parse-7 :
  val g = example-grammar-6()
  test-parse(g, `(a a b c a a b c b c a a a a a a a a a a a a a a a a))

let :;deftest parse-mutually-right-recursive :
  #for E in [AS BS CS A B C X] :
    val E = GProduction(`E)
  #for (X in [x a b c],
        x in [x a b c]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [X X X AS])
    GTokenRule(`AS, [A, X, BS])
    GTokenRule(`BS, [B, X, CS])
    GTokenRule(`CS, [X])
    GTokenRule(`CS, [C, X, AS])
    GTokenRule(`X, [x])
    GTokenRule(`A, [a])
    GTokenRule(`B, [b])
    GTokenRule(`C, [c])]
  test-parse(rules, `(x x x a x b x c x a x b x c x a x b x x))

deftest right-recursive-priority :
  #for E in [E A BS] :
    val E = GProduction(`E)
  #for (X in [a],
        x in [a]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [E])
    GTokenRule(`E, [A BS])
    GTokenRule(`E, [A A A A], false, 200)
    GTokenRule(`BS, [A BS])
    GTokenRule(`BS, [])
    GTokenRule(`A, [a])]
  test-parse(rules, `(a a a a))

defn example-null-grammar () :
  #for X in [S Ap E] :
    val X = GProduction(`X)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [Ap Ap Ap Ap])
   GTokenRule(`Ap, [A])
   GTokenRule(`Ap, [E])
   GTokenRule(`E, [])]

deftest parse-null :
  val g = example-null-grammar()
  test-parse(g, `(a a a))

defn example-tricky-null-grammar () :
  #for E in [S, A, B] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [w A d])
   GTokenRule(`S, [A d])
   GTokenRule(`S, [w B A A A d])
   GTokenRule(`A, [x])
   GTokenRule(`A, [])
   GTokenRule(`B, [x])]

deftest parse-tricky-null :
  val g = example-tricky-null-grammar()
  test-parse(g, `(w x x d))

defn example-tricky-null-grammar-2 () :
  #for E in [B S A] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [B])
   GTokenRule(`B, [S])
   GTokenRule(`B, [A])
   GTokenRule(`S, [w x A A A A d], false, 100, LeftAssociative)
   GTokenRule(`A, [w x])
   GTokenRule(`A, [])]

deftest parse-tricky-null-2 :
  val g = example-tricky-null-grammar-2()
  test-parse(g, `(w x w x w x w x d))

defn list-grammar () :
  #for E in [S, A, B, C, D, L, R, CD, CDs] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [A B CDs L CDs R CDs])
   GTokenRule(`S, [A B C])
   GTokenRule(`CDs, [CD, CDs])
   GTokenRule(`CDs, [])
   GTokenRule(`CD, [L C D R])
   GTokenRule(`A, [a])
   GTokenRule(`B, [b])
   GTokenRule(`C, [c])
   GTokenRule(`D, [d])
   GTokenRule(`L, [GListStart()])
   GTokenRule(`R, [GListEnd()])]

deftest parse-list :
  val g = list-grammar()
  test-parse(g, `(a b (c d) (c d) ((c d) (c d) (c d)) (c d)))

defn any-vs-list-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [done],
        x in [done]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [GAny() done])
   GTokenRule(`S, [GListStart() done GListEnd() done])]

deftest parse-any-vs-list :
  val g = any-vs-list-grammar()
  test-parse(g, `((done) done))

defn any-as-list-grammar () :
  #for E in [S A As Xs] :
    val E = GProduction(`E)
;  #for (X in [],
;        x in [a b c d]) :
;    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [Xs Xs])
   GTokenRule(`S, [A A])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [GListStart(true) As GListEnd()])
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`Xs, [GListStart() GKeyword(`x) GListEnd()])]

deftest parse-any-as-list :
  val g = any-as-list-grammar()
  test-parse(g, `((x) (x y z)))

defn list-recovery-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [a GListStart() b GListEnd() c])]

deftest parse-list-recovery :
  val g = list-recovery-grammar()
  test-parse(g, `(a b c))

defn rest-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [GListStart() a b c GListEnd()])
   GTokenRule(`S, [GListStart() a b GListRest() GListEnd()])]

deftest parse-rest :
  val g = rest-grammar()
  test-parse(g, `((a b d e f)))

defn full-any-grammar () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [LP a b LP c d R RP RP])   
   GTokenRule(`S, [LP a b LP c d As d RP RP])   
   
   GTokenRule(`S, [A])
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]  

deftest parse-full-any-grammar :
  val g = full-any-grammar()
  test-parse(g, `((a b (c d x y z d g d))))

defn full-any-grammar-2 () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [A a b c]) 
   GTokenRule(`S, [R])   
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]  

deftest parse-full-any-grammar-2 :
  val g = full-any-grammar-2()
  test-parse(g, `((x y z) a b c))

defn amb-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], false, 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])]    

deftest parse-amb-grammar :
  val g = amb-grammar()
  test-parse(g, `(red red dog dog red dog dog dog))

defn amb-grammar-2 () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E])
   GTokenRule(`ES, [E ES], false, 100, LeftAssociative)
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])]    

deftest parse-amb-grammar-2 :
  val g = amb-grammar-2()
  test-parse(g, `(red dog dog red dog dog red dog dog red dog dog red dog dog))

defn if-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [IF THEN ELSE N],
        x in [if then else N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], false, 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [LP E RP])   
   GTokenRule(`E, [IF E THEN E], false, 100, LeftAssociative)      
   GTokenRule(`E, [IF E THEN E ELSE E], false, 100, LeftAssociative)
   GTokenRule(`E, [N])]    

deftest parse-if-grammar :
  val g = if-grammar()
  test-parse(g, `(if N then if N then N else N))

defn matcher-grammar () :
  #for E in [ES E Id BId RId] :
    val E = GProduction(`E)
  #for (X in [VAR EQ N DOT],
        x in [var = N .]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn prefix-symbol? (form, prefix:String) :
    match(unwrap-token(form)) :
      (f:Symbol) : prefix?(name(f), prefix)
      (f) : false
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [VAR Id EQ E])
   GTokenRule(`E, [N])
   GTokenRule(`Id, [BId DOT RId])
   GMatcherRule(`BId, [GAny()], prefix-symbol?{_, "B"})
   GMatcherRule(`RId, [GAny()], prefix-symbol?{_, "R"})]

deftest parse-matcher-grammar :
  val g = matcher-grammar()
  test-parse(g, `(var B10.R18 = N N))

deftest parse-matcher-grammar-error :
  val g = matcher-grammar()
  test-parse(g, `("hello world"))

defn core-form-grammar () :
  #for E in [ES E A R] :
    val E = GProduction(`E)
  #for (X in [CORE],
        x in [$core]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn core-form? (form) :
    match(unwrap-token(form)) :
      (f:List) : not empty?(f) and unwrap-token(head(f)) == `$core
      (f) : false
      
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [CORE])
   GTokenRule(`E, [LP ES RP])   
   GMatcherRule(`E, [GAny(Atomic)], core-form?)

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP R RP])
   GTokenRule(`R, [GAny() R])
   GTokenRule(`R, [LP R RP R])
   GTokenRule(`R, [GListRest()])]

deftest parse-core-form-grammar :
  val g = core-form-grammar()
  test-parse(g, `($core ($core a b c d) $core))

defn exp-grammar () :
  #for E in [ES E ID A R] :
    val E = GProduction(`E)
  #for (X in [VAR VAL FOR LET IN EQ COLON PLUS TIMES N DO],
        x in [var val for let in = : + * N @do]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
      
  [GTokenRule(`Start, [ES GListEnd()], fn (result) :
     result[0])
  
   GTokenRule(`keywords, [VAR])     
   GTokenRule(`keywords, [VAL])     
   GTokenRule(`keywords, [FOR])     
   GTokenRule(`keywords, [LET])     
   GTokenRule(`keywords, [IN])
   GTokenRule(`keywords, [EQ])
   GTokenRule(`keywords, [COLON])
   GTokenRule(`keywords, [DO])

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])

   GTokenRule(`ID, [A], fn (result) :
     result[0])
   GNegationRule(`ID, GProduction(`keywords))
   
   GTokenRule(`ES, [E ES], fn (result) :
     cons(result[0], result[1]))
   GTokenRule(`ES, [], fn (result) :
     List())
   
   GTokenRule(`E, [VAR ID EQ E], fn (result) :
     qquote($var ~(result[1]) ~(result[3])))
   GTokenRule(`E, [VAL ID EQ E], fn (result) :
     qquote($val ~(result[1]) ~(result[3])))
   GTokenRule(`E, [FOR ID IN E COLON E], fn (result) :
       qquote($for ~(result[1]) ~(result[3]) ~(result[5])))
   GTokenRule(`E, [LET ID EQ E COLON E], fn (result) :
     qquote($let ~(result[1]) ~(result[3]) ~(result[5])))
   GTokenRule(`E, [LET ID EQ E R], true, 100, RightAssociative, fn (result) :
     throw(Exception("%_: Expected a colon after let binding" % [info(result)])))
   GTokenRule(`E, [E LP DO ES RP], false, 70, LeftAssociative, fn (result) :
     qquote($call ~(result[0]) ~@(result[3])))
   GTokenRule(`E, [LP E RP], fn (result) :
     result[1])
   GTokenRule(`E, [LP ES RP], fn (result) :
     qquote($begin ~@(result[1])))
   GTokenRule(`E, [N], fn (result) :
     result[0])
   GTokenRule(`E, [GIntToken()], fn (result) :
     result[0])
   GTokenRule(`E, [E PLUS E], false, 90, LeftAssociative, fn (result) :
     qquote($plus ~(result[0]), ~(result[2])))
   GTokenRule(`E, [E TIMES E], false, 80, LeftAssociative, fn (result) :
     qquote($times ~(result[0]), ~(result[2])))]

deftest parse-exp-grammar :
  test-parse(exp-grammar(), reader/read-file("exp-test.txt"))

deftest action-exp-grammar :
  test-parse-action(exp-grammar(), reader/read-file("exp-test.txt"))

defn rest-priority-grammar () :
  #for E in [ES E F A R] :
    val E = GProduction(`E)
  #for (X in [PLUS N],
        x in [+ N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
      
  [GTokenRule(`Start, [F GListEnd()])

   GTokenRule(`F, [E E], false, 100, LeftAssociative)
   
   GTokenRule(`E, [E PLUS E], false, 90, LeftAssociative)
   GTokenRule(`E, [N R], true)
   GTokenRule(`E, [N])

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]

deftest parse-rest-priority-grammar :
  val g = rest-priority-grammar()
  test-parse(g, `(N + N + N N + N))

deftest parse-blowup-grammar :
  #for E in [E] :
    val E = GProduction(`E)
  #for (X in [N],
        x in [N]) :
    val X = GKeyword(`x)
  val grammar = [
    GTokenRule(`Start, [E GListEnd()])
    GTokenRule(`E, [E E E])
    GTokenRule(`E, [N])]  

;  test-parse(grammar, `(N N N N N N N N N N N N N N N N N
;                        N N N N N N N N N N N N N N N N N N
;                        N N N N N N N N N N N N N N N N N
;                        N N N N N N N N N N N N N N N N N))

  test-parse(grammar, `(N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N N))