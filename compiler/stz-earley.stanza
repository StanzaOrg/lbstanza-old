#use-added-syntax(tests)
defpackage stz/earley :
  import core
  import collections
  import stz/utils

;============================================================
;====================== Definitions =========================
;============================================================

defstruct GRule :
  name: Symbol
  tokens: Tuple<GToken>
  priority: Int with: (default => 100)
  associativity: Associativity with: (default => RightAssociative)

defenum Associativity :
  LeftAssociative
  RightAssociative

deftype GToken <: Equalable & Hashable & Comparable<GToken>
defstruct GProduction <: GToken :
  name: Symbol
defstruct GKeyword <: GToken :
  item: Symbol
defstruct GListStart <: GToken :
  reluctant?:True|False with: (default => false)
defstruct GListEnd <: GToken
defstruct GAny <: GToken
defstruct GListRest <: GToken

defstruct EItem :
  rule:Int
  num-parsed:Int
  parent:Int
  completion-root:EItem|False with: (init => false, updater => sub-completion-root)

defstruct EParent :
  rule: Int
  start: Int
  index: Int
  id: Int
  direct?: True|False
with:
  printer => true

defstruct ECondParent :
  rule: Int
  start: Int
  child-start: Int
  production: Symbol
with:
  printer => true

defstruct ParsedRange :
  id: Int
  rule: Int
  start: Int
  end: Int
with:
  printer => true

defstruct ParseNode :
  rule: Int
  start: Int
  end: Int
  children: Tuple<ParseNode>

;============================================================
;======================== Equalable =========================
;============================================================

defmethod equal? (a:GToken, b:GToken) :
  match(a, b) :
    (a:GKeyword, b:GKeyword) : item(a) == item(b)
    (a:GProduction, b:GProduction) : name(a) == name(b)
    (a:GListStart, b:GListStart) : reluctant?(a) == reluctant?(b)
    (a:GListEnd, b:GListEnd) : true
    (a:GAny, b:GAny) : true
    (a:GListRest, b:GListRest) : true
    (a, b) : false

defmethod hash (t:GToken) :
  match(t) :
    (t:GKeyword) : 1 + hash(item(t))
    (t:GProduction) : 2 + hash(name(t))
    (t:GListStart) : 3 + hash(reluctant?(t))
    (t:GListEnd) : 4
    (t:GAny) : 5
    (t:GListRest) : 6

defmethod compare (a:GToken, b:GToken) :
  defn rank (t:GToken) :
    match(t) :
      (t:GKeyword) : 0
      (t:GProduction) : 1
      (t:GListStart) : 2
      (t:GListEnd) : 3
      (t:GAny) : 4
      (t:GListRest) : 5
  defn to-int (x:True|False) :
    1 when x else 0
  defn compare-token (a:GToken, b:GToken) :
    match(a, b) :
      (a:GProduction, b:GProduction) : compare(name(a), name(b))
      (a:GKeyword, b:GKeyword) : compare(item(a), item(b))
      (a:GListStart, b:GListStart) : compare(to-int(reluctant?(a)), to-int(reluctant?(b)))
      (a, b) : 0
  val c = compare(rank(a), rank(b))
  if c == 0 : compare-token(a,b)
  else : c

;============================================================
;======================= Printers ===========================
;============================================================

defmethod print (o:OutputStream, t:GToken) :
  print{o, _} $ match(t) :
    (t:GProduction) : name(t)
    (t:GKeyword) : item(t)
    (t:GListStart) : "("
    (t:GListEnd) : ")"
    (t:GAny) : "_"
    (t:GListRest) : "_ ..."

defmethod print (o:OutputStream, r:GRule) :
  print(o, "%_ = %s" % [name(r), tokens(r)])

;============================================================
;======================== Utilities =========================
;============================================================

defn wrap (token, info:FileInfo|False) :
  match(info:FileInfo) : Token(token, info)
  else : token

defn inc-num-parsed (x:EItem) :
  EItem(rule(x), num-parsed(x) + 1, parent(x))

defn upcoming (grammar:Grammar, item:EItem) -> GToken|False :
  val r = grammar[rule(item)]
  val i = num-parsed(item)
  val num-tokens = length(tokens(r))
  tokens(r)[i] when i < num-tokens

defn previous (grammar:Grammar, item:EItem) -> GToken|False :
  val r = grammar[rule(item)]
  val i = num-parsed(item) - 1
  tokens(r)[i] when i >= 0

defn production (grammar:Grammar, item:EItem) -> Symbol :
  name(grammar[rule(item)])

;============================================================
;==================== Grammar Analysis ======================
;============================================================

deftype Grammar
defmulti get (g:Grammar, i:Int) -> GRule
defmulti nullable? (g:Grammar, production:Symbol) -> True|False
defmulti rules (g:Grammar, production:Symbol, next-input) -> Seqable<Int>

defn Grammar (rules:Tuple<GRule>) :
  val [null-table, null-rules, rule-fsets] = nullables-and-firstsets(rules)
  val null-rules-table = nullables-to-rule-table(rules, null-rules)
  ;val input-rule-table = input-to-rule-table(rules, null-rules-table, rule-fsets)
  val prod-rules-table = group-by(name{rules[_]}, 0 to length(rules))
  new Grammar :
    defmethod get (this, i:Int) :
      rules[i]
    defmethod nullable? (this, production:Symbol) :
      null-table[production]
    defmethod rules (this, production:Symbol, next-input) :
      prod-rules-table[production] ;[TODO]
      ;match(unwrap-token(next-input)) :
      ;  (t:Symbol) :
      ;    cat(null-rules-table[production],
      ;        input-rule-table[[production, t]])
      ;  (t:EndOfInput) :
      ;    null-rules-table[production]
      ;  (t:InsertedInput) :
      ;    prod-rules-table[production]

defn input-to-rule-table (rules:Tuple<GRule>,
                          null-rules-table:HashTable<Symbol,List<Int>>,
                          rule-fsets:Tuple<Tuple<Symbol>>) ->
                          HashTable<[Symbol, Symbol],List<Int>> :
  ;Utility to subtract one set from another.
  val buffer = IntSet()
  defn minus (a:Collection<Int>, b:Collection<Int>) :
    add-all(buffer, a)
    for x in b do : remove(buffer,x)
    val result = to-list(buffer)
    clear(buffer)
    result

  ;Compute [prod, input-terminal] => (rules ...) table.
  val table = group-by{key, value, _} $
    for (rule in rules, rule-index in 0 to false) seq-cat :
      for terminal in rule-fsets[rule-index] seq :
        [name(rule), terminal] => rule-index

  ;Remove all rules that are already accounted for by null table.
  for entry in table map! :
    val [prod, input] = key(entry)
    value(entry) - null-rules-table[prod]

  ;Return final table
  table

defn nullables-to-rule-table (rules:Tuple<GRule>, null-rules:Tuple<Int>) ->
                              HashTable<Symbol,List<Int>> :
  defn production (i:Int) : name(rules[i])
  group-by(production, null-rules)

defn nullables-and-firstsets (grammar:Tuple<GRule>) ->
                             [HashTable<Symbol,True|False>,
                              Tuple<Int>,
                              Tuple<Tuple<Symbol>>] :
  ;Compute parent rules that contain each production.
  val parent-table:HashTable<Symbol,List<Int>> = group-by{key, value, _} $
    for (rule in grammar, rule-index in 0 to false) seq-cat :
      for prod in filter-by<GProduction>(tokens(rule)) seq :
        name(prod) => rule-index

  ;Worklist algorithm
  defn worklist (f:(GRule, Symbol -> False) -> ?) :
    val queue = Queue<Int>()
    do(add{queue, _}, 0 to length(grammar))
    defn enqueue (prod:Symbol) :
      do(add{queue, _}, parent-table[prod])
    while not empty?(queue) :
      val rule = grammar[pop(queue)]
      f(rule, enqueue)

  ;Compute null table
  val null-table = HashTable<Symbol,True|False>(false)
  defn nullable? (t:GToken) :
    match(t) :
      (t:GProduction) : null-table[name(t)]
      (t:GKeyword) : false
      (t:GListStart) : false
      (t:GListEnd) : false
      (t:GAny) : false
      (t:GListRest) : true
  defn nullable? (rule:GRule) :
    all?(nullable?, tokens(rule))
  within (rule, enqueue) = worklist() :
    if not null-table[name(rule)] and nullable?(rule) :
      null-table[name(rule)] = true
      enqueue(name(rule))

  ;;Compute first sets
  ;val fset-table = HashTable<Symbol,Tuple<Symbol>>([])
  ;defn first-sets (t:GToken) :
  ;  match(t) :
  ;    (t:GKeyword) : [item(t)]
  ;    (t:GProduction) : fset-table[name(t)]
  ;defn first-sets (rule:GRule) :
  ;  val terminals = Vector<Symbol>()
  ;  let loop (i:Int = 0) :
  ;    if i < length(tokens(rule)) :
  ;      val t = tokens(rule)[i]
  ;      add-all(terminals, first-sets(t))
  ;      loop(i + 1) when nullable?(t)
  ;  terminals
  ;within (rule, enqueue) = worklist() :
  ;  val fset = to-hashset<Symbol> $ fset-table[name(rule)]
  ;  val old-length = length(fset)
  ;  add-all(fset, first-sets(rule))
  ;  if length(fset) > old-length :
  ;    fset-table[name(rule)] = to-tuple(fset)
  ;    enqueue(name(rule))
  ;
  ;Compute null rules
  val null-rules = to-tuple $
    filter(nullable?{grammar[_]}, 0 to length(grammar))
  ;
  ;;Compute rule first sets
  ;val rule-fsets = for rule in grammar map :
  ;  to-tuple $ unique $ first-sets(rule)
  val rule-fsets = [[]]

  ;Return all tables
  [null-table, null-rules, rule-fsets]

defn nullable-productions (grammar:Tuple<GRule>) :
  val [null-table, null-rules, rule-fsets] = nullables-and-firstsets(grammar)
  to-hashset<Symbol> $ seq(key, filter(value, null-table))

;============================================================
;===================== Specificity ==========================
;============================================================

defstruct SpecificityKey <: Comparable<SpecificityKey> :
  parent-associativity: Associativity
  length: Int
  priority: Int
  rule: Int
with:
  printer => true

;Return -1 if a should take priority over b during
;a right-to-left disambiguation sweep of the parse forest.
defmethod compare (a:SpecificityKey, b:SpecificityKey) :
  fatal("Incomparable keys!") when parent-associativity(a) != parent-associativity(b)
  ;Retrieve fields
  defn compare-associativity () :
    switch(parent-associativity(a)) :
      RightAssociative : compare(length(b), length(a))
      LeftAssociative : compare(length(a), length(b))
  defn compare-priority () :
    compare(priority(b), priority(a))
  defn compare-order () :
    compare(rule(a), rule(b))
  val c1 = compare-associativity()
  if c1 == 0 :
    val c2 = compare-priority()
    if c2 == 0 : compare-order()
    else : c2
  else : c1

;============================================================
;======================== ESetList ==========================
;============================================================

deftype ESetList
defmulti add (l:ESetList, items:Seqable<EItem>) -> False
defmulti clear-markers (l:ESetList) -> False
defmulti items (return:EItem -> ?, l:ESetList, index:Int, production:Symbol, mark?:True|False) -> False
defmulti first-item (l:ESetList, index:Int, production:Symbol) -> EItem|False
defmulti sets (l:ESetList) -> Seqable<Seqable<EItem>>

defstruct EItemSet :
  start: Int
  length: Int

defn ESetList (grammar:Grammar) :
  val items = Vector<EItem>()
  val markers = Vector<Int>()
  val sets = Vector<EItemSet>()
  val buffer = Vector<EItem>()
  var current-marker:Int = 1

  defn production! (item:EItem) :
    name(upcoming(grammar,item) as GProduction)

  defn productions (return:EItem -> ?, start:Int, end:Int, production:Symbol) :
    let loop (i:Int = start) :
      if i < end :
        val item = items[i]
        if production!(item) == production :
          return(item)
          loop(i + 1)

  new ESetList :
    defmethod add (this, new-items:Seqable<EItem>) :
      add-all(buffer, new-items)
      qsort!(production!, buffer)
      add(sets, EItemSet(length(items), length(buffer)))
      add-all(items, buffer)
      lengthen(markers, length(items), 0)
      clear(buffer)
    defmethod items (return:EItem -> ?, this, index:Int, production:Symbol, mark?:True|False) :
      val eset = sets[index]
      val i = bsearch(production!, items, start(eset), start(eset) + length(eset), production)
      match(i:Int) :
        if mark? :
          if markers[i] != current-marker :
            productions(return, i, start(eset) + length(eset), production)
            markers[i] = current-marker
        else :
          productions(return, i, start(eset) + length(eset), production)
    defmethod first-item (this, index:Int, production:Symbol) :
      val eset = sets[index]
      val i = bsearch(production!, items, start(eset), start(eset) + length(eset), production)
      match(i:Int) : items[i]
    defmethod clear-markers (this) :
      current-marker = current-marker + 1
    defmethod sets (this) :
      for eset in sets seq :
        for i in 0 to length(eset) seq :
          items[start(eset) + i]

;Binary search:
;It returns i such that all items at index < i satisfy key(xs[i]) < v.
defn bsearch<?T> (key:T -> Comparable, xs:Vector<?T>, start:Int, end:Int, v:Comparable) -> Int|False :
  bsearch(xs, start, end, compare{key(_), v})

defn bsearch<?T> (xs:Vector<?T>, start:Int, end:Int, compare:T -> Int) -> Int|False :
  ;All items with index less than i are known to return -1 for compare.
  ;All items with index greater than j are known to return 0/1 for compare.
  let loop (i:Int = start, j:Int = end) :
    if i == j :
      i when i < end and compare(xs[i]) == 0
    else :
      val m = (i + j) / 2
      if compare(xs[m]) < 0 : loop(m + 1, j)
      else : loop(i, m)

defn bsearch<?T> (xs:Vector<?T>, compare:T -> Int) -> Int|False :
  bsearch(xs, 0, length(xs), compare)

;============================================================
;======================= ESet ===============================
;============================================================

deftype ESet <: Collection<EItem>
;Returns true if a wildcard can match against any of the upcoming
;terminals.
defmulti wildcard-expected? (s:ESet) -> True|False
defmulti list-expected? (s:ESet) -> True|False
defmulti list-end-expected? (s:ESet) -> True|False
defmulti rest-expected? (s:ESet) -> True|False
defmulti add (s:ESet, item:EItem) -> False
defmulti clear (s:ESet, length:Int) -> False
defmulti length (s:ESet) -> Int
defmulti get (s:ESet, i:Int) -> EItem
defmulti map! (f:EItem -> EItem, s:ESet) -> False
defmulti remove! (f:EItem -> True|False, s:ESet) -> False

defn ESet (grammar:Grammar) :
  ;Accumulate items
  val items = Vector<EItem>()

  ;Track flags
  var wildcard-expected?: True|False = false
  var list-expected?: True|False = false
  var list-end-expected?: True|False = false
  var rest-expected?:True|False = false
  defn process-flags (item:EItem) :
    match(upcoming(grammar,item)) :
      (upcoming:GKeyword|GAny) :
        wildcard-expected? = true
      (upcoming:GListStart) :
        if not reluctant?(upcoming) :
          list-expected? = true
      (upcoming:GListEnd) :
        list-end-expected? = true
      (upcoming:GListRest) :
        rest-expected? = true
      (upcoming) :
        false
      
  defn recompute-flags () :
    wildcard-expected? = false
    list-expected? = false
    list-end-expected? = false
    rest-expected? = false
    do(process-flags, items)

  ;Return set
  new ESet :
    defmethod get (this, i:Int) :
      items[i]
    defmethod wildcard-expected? (this) :
      wildcard-expected?
    defmethod list-expected? (this) :
      list-expected?
    defmethod list-end-expected? (this) :
      list-end-expected?
    defmethod rest-expected? (this) :
      rest-expected?
    defmethod clear (this, l:Int) :
      shorten(items, l)
      recompute-flags()
    defmethod add (this, item:EItem) :
      add(items, item)
      process-flags(item)
    defmethod length (this) :
      length(items)
    defmethod to-seq (this) :
      to-seq(items)
    defmethod map! (f:EItem -> EItem, this) :
      map!(f, items)
    defmethod remove! (f:EItem -> True|False, this) :
      remove-when(f, items)

defmethod do (f:EItem -> ?, eset:ESet) :
  val item-index = to-seq(0 to false)
  while peek(item-index) < length(eset) :
    f(eset[next(item-index)])

defn empty? (s:ESet) :
  length(s) == 0

;============================================================
;==================== Error Handling ========================
;============================================================

defstruct MissingInput :
  input
  set-index: Int
  info: FileInfo|False
  items: Tuple<EItem>

defstruct MissingInputError <: Exception :
  input
  info: FileInfo|False
  productions: Tuple<Symbol>
  upcoming: Tuple<GToken>

defstruct ParsingErrors <: Exception :
  errors: Tuple<Exception>

defn to-exception (g:Grammar, m:MissingInput) :
  println("MAKE EXCEPTION")
  do(println{format(g, _)}, items(m))
  
  ;Compute earliest completed productions
  defn completed? (item:EItem) :
    val tokens = tokens(g[rule(item)])
    num-parsed(item) == length(tokens)
  val completed-productions = HashTable<Symbol,Int>(INT-MAX)
  for item in filter(completed?,items(m)) do :
    update(completed-productions, min{_, parent(item)}, production(g,item))

  ;Compute productions and upcoming
  val productions = HashSet<Symbol>()
  val upcoming-tokens = HashSet<GToken>()
  for item in items(m) do :
    val production = production(g,item)
    val include? = match(upcoming(g,item)) :
      (t:GKeyword|GAny|GListStart|GListEnd) :
        num-parsed(item) > 0 and
        completed-productions[production] > parent(item)
      (t:GProduction) :
        completed-productions[production] > parent(item)
      (t:False) :
        false
    if include? :
      add(productions, production)
      add(upcoming-tokens, upcoming(g, item) as GToken)

  ;Return error
  MissingInputError(input(m), info(m), to-tuple(productions), qsort(upcoming-tokens))

defn to-exception (g:Grammar, input-ms:Collection<MissingInput>) :  
  val ms = to-tuple(input-ms)
  defn first-in-chain? (i:Int) : i == 0 or set-index(ms[i - 1]) < set-index(ms[i]) - 1
  val es = seq(to-exception{g, ms[_]}, filter(first-in-chain?, 0 to length(ms)))
  ParsingErrors $ to-tuple $ es

defmethod print (o:OutputStream, e:MissingInputError) :
  val info-str = "" when info(e) is False else "%_: " % [info(e)]
  val input-str = match(input(e)) :
    (x:EndOfInput) : "end of input"
    (x:SExpForm) :
      match(unwrap-token(form(x))) :
        (f:Symbol) : "symbol '%~'" % [f]
        (f:List) : "list"
        (f) : "input '%~'" % [f]
    (x:SExpListEnd) : "end of list"
  defn token-str (t:GToken) :
    match(t) :
      (t:GProduction) : "a '%~' production" % [name(t)]
      (t:GKeyword) : "'%~'" % [item(t)]
      (t:GListStart) : "a list"
      (t:GListEnd) : "the end of the list"
      (t:GAny) : "a form"
  defn tokens-str (ts:Tuple<GToken>) :
    if length(ts) == 1 :
      token-str(ts[0])
    else :
      val but-last-t = ts[0 to length(ts) - 1]
      val last-t = ts[length(ts) - 1]
      "either %,, or %_" % [seq(token-str,but-last-t), token-str(last-t)]
  defn productions-str (names:Tuple<Symbol>) :
    tokens-str(map(GProduction,names))
  print(o, "%_Unexpected %_." % [info-str, input-str])
  if not empty?(productions(e)) :
    print(o, " Current parsing %_ and %_ is expected next." % [
      productions-str(productions(e)), tokens-str(upcoming(e))])

defmethod print (o:OutputStream, e:ParsingErrors) :
  print-all(o, join(errors(e), '\n'))

;============================================================
;============== ProductionTable/ProductionSet ===============
;============================================================

deftype ProductionTable<T>
defmulti get<?T> (t:ProductionTable<?T>, key:Symbol) -> T
defmulti set<?T> (t:ProductionTable<?T>, key:Symbol, v:T) -> False
defmulti clear (t:ProductionTable) -> False

defn ProductionTable<T> (default:T) :
  val table = HashTable<Symbol,T>(default)
  new ProductionTable<T> :
    defmethod get (this, key:Symbol) : table[key]
    defmethod set (this, key:Symbol, v:T) : table[key] = v
    defmethod clear (this) : clear(table)

deftype ProductionSet
defmulti get (t:ProductionSet, key:Symbol) -> True|False
defmulti add (t:ProductionSet, key:Symbol) -> True|False
defmulti clear (t:ProductionSet) -> False

defn ProductionSet () :
  val keys = HashSet<Symbol>()
  new ProductionSet :
    defmethod get (this, key:Symbol) : keys[key]
    defmethod add (this, key:Symbol) : add(keys,key)
    defmethod clear (this) : clear(keys)

deftype CompletionSet
defmulti add (s:CompletionSet, item:EItem) -> True|False
defmulti get (s:CompletionSet, item:EItem) -> True|False
defmulti clear (s:CompletionSet) -> False

defn CompletionSet () :
  val keys = HashSet<[Int,Int,Int]>()
  new CompletionSet :
    defmethod add (this, item:EItem) :
      add(keys, [rule(item), num-parsed(item), parent(item)])
    defmethod get (this, item:EItem) :
      keys[[rule(item), num-parsed(item), parent(item)]]
    defmethod clear (this) :
      clear(keys)

;============================================================
;====================== Debugging ===========================
;============================================================

defn printable-stream (return:OutputStream -> ?) :
  new Printable :
    defmethod print (o:OutputStream, this) :
      return(o)

defn print-current-set (grammar:Grammar, set-index:Int, current-set:ESet) :
  println("Completed set %_" % [set-index])
  within indented() :
    do(println{format(grammar,_)}, current-set)

defn format (grammar:Grammar, e:EItem) :
  within o = printable-stream() :
    val r = grammar[rule(e)]
    print(o, "(rule %_) [%_ =" % [rule(e), name(r)])
    for (t in tokens(r), i in 0 to false) do :
      val prefix = " • " when num-parsed(e) == i else " "
      print-all(o, [prefix, t])
    if num-parsed(e) == length(tokens(r)) :
      print(o, " •")
    print(o, ", S%_]" % [parent(e)])
    if completion-root(e) is EItem :
      val msg = format(grammar, completion-root(e) as EItem)
      print(o, " (complete as %_)" % [msg])

defn format (grammar:Grammar, setlist:ESetList) :
  within o = printable-stream() :
    val o2 = IndentedStream(o)
    for (eset in sets(setlist), i in 0 to false) do :
      print(o, "\n") when i > 0
      print(o, "Set %_:" % [i])
      do(lnprint{o2, format(grammar,_)}, eset)

defn format (grammar:Grammar, eset:Vector<EItem>) :
  within o = printable-stream() :
    val o2 = IndentedStream(o)
    print(o, "ESet :")
    do(lnprint{o2, format(grammar,_)}, eset)

defn format (grammar:Grammar, r:ParsedRange) :
  "(range %_) [%_ to %_] %_" % [id(r), start(r), end(r), grammar[rule(r)]]

defn format (grammar:Grammar, node:ParseNode) :
  within o = printable-stream() :
    val rule = grammar[rule(node)]
    print(o, "[%_ to %_] %_" % [start(node), end(node), rule])
    val o2 = IndentedStream(o)
    do(lnprint{o2, format(grammar,_)}, children(node))

defn format (grammar:Grammar, ranges:Vector<ParsedRange>, p:EParent) :
  val parent-rule = grammar[rule(p)]
  val child = ranges[id(p)]
  val child-rule = grammar[rule(child)]
  val direct-str = " (direct)" when direct?(p) else ""
  "[%_ onwards] %_ (index %_) => [%_ to %_] %_%_" % [
    start(p), parent-rule, index(p), start(child), end(child), child-rule, direct-str]

;============================================================
;=================== SExpression Stream =====================
;============================================================

deftype SExpStream
defmulti peek (s:SExpStream) -> SExpToken
defmulti advance (s:SExpStream, expand-list?:True|False) -> False
defmulti advance-rest (s:SExpStream) -> SExpTail
defmulti insert-wildcard (s:SExpStream) -> False
defmulti insert-list (s:SExpStream) -> False
defmulti info (s:SExpStream) -> FileInfo|False

deftype SExpToken
defstruct SExpForm <: SExpToken :
  form
with:
  printer => true
defstruct SExpWildcard <: SExpToken
defstruct SExpListEnd <: SExpToken
defstruct EndOfInput <: SExpToken
defstruct SExpTail <: SExpToken :
  list
with:
  printer => true

defn SExpStream (input:List) :
  val stack = Vector<List>()
  var current:List|False = input
  var info:FileInfo|False = false

  defn update-info () :
    match(current:List) :
      if not empty?(current) :
        val t = head(current)
        match(t:Token) :
          info = /info(t)

  defn peek-stream () :
    match(current:List) :
      if empty?(current) : SExpListEnd()
      else :
        match(head(current)) :
          (t:SExpWildcard) : t
          (t) : SExpForm(t)
    else : EndOfInput()

  defn advance-stream (expand-list?:True|False) :
    fatal("No more tokens.") when current is False
    val curr = current as List
    if empty?(curr) :
      current = pop(stack) when not empty?(stack)
    else :
      val expand? = expand-list? and
                    unwrap-token(head(curr)) is List
      if expand? :
        add(stack, tail(curr))
        current = unwrap-token(head(curr)) as List
      else :
        current = tail(curr)
    update-info()

  update-info()
  new SExpStream :
    defmethod info (this) :
      info
    defmethod peek (this) :
      peek-stream()
    defmethod advance (this, expand-list?:True|False) :
      advance-stream(expand-list?)
    defmethod advance-rest (this) :
      val ret = SExpTail(current as List)
      current = List()
      ret
    defmethod insert-wildcard (this) :
      current = cons(SExpWildcard(), current as List)
    defmethod insert-list (this) :
      current = cons(List(), current as List)

;============================================================
;====================== Algorithm ===========================
;============================================================

defn parse (grammar:Grammar, input:List) -> ParseNode|ParsingErrors :
  val setlist = ESetList(grammar)
  val prediction-set = ProductionSet()
  val completion-set = CompletionSet()
  val production-count = ProductionTable<Int>(0)
  val parents = Vector<EParent|ECondParent>()
  val ranges = Vector<ParsedRange>()
  val inputlist = Vector<?>()
  val missing = Vector<MissingInput>()

  ;Returns true if the given terminal matches against the given input.
  defn matches-input? (t:GToken, input:SExpToken) :
    match(t, input) :
      (t:GKeyword|GAny, input:SExpWildcard) : true
      (t, input:SExpWildcard) : false
      (t:GKeyword, input:SExpForm) : unwrap-token(form(input)) == item(t)
      (t:GKeyword, input) : false
      (t:GAny, input:SExpForm) : true
      (t:GAny, input) : false
      (t:GListStart, input:SExpForm) : unwrap-token(form(input)) is List
      (t:GListStart, input) : false
      (t:GListEnd, input:SExpListEnd) : true
      (t:GListEnd, input) : false

  ;Returns true if the starting rule has been completed
  defn process-set (set-index:Int,
                    current-set:ESet,
                    next-set:ESet,
                    next-input) -> True|False :
    ;Clear state
    clear-markers(setlist)
    clear(prediction-set)
    clear(completion-set)

    ;Track whether starting rule has been completed
    var start-completed = false

    ;Iterate through each item
    for item in current-set do :
      match(upcoming(grammar,item)) :
        (t:GKeyword|GListStart|GListEnd|GAny) : upcoming-terminal(item, t)
        (p:GProduction) : upcoming-production(item, p)
        (f:False) : end-of-rule(item)
        (t:GListRest) : false
      where :
        defn add-completion (item:EItem) :
          add(current-set, item) when add(completion-set, item)
        defn upcoming-terminal (item:EItem, t:GKeyword|GListStart|GListEnd|GAny|GListRest) :
          if matches-input?(t, next-input) :
            add(next-set, inc-num-parsed(item))
        defn upcoming-production (item:EItem, t:GProduction) :
          add-completion(inc-num-parsed(item)) when nullable?(grammar, name(t))
          if add(prediction-set, name(t)) :
            for rule in rules(grammar, name(t), next-input) do :
              add(current-set, EItem(rule, 0, set-index))
        defn end-of-rule (completed-item:EItem) :
          if rule(completed-item) == 0 : start-completed = true
          val prod = production(grammar,completed-item)
          if parent(completed-item) < set-index :
            within item = items(setlist, parent(completed-item), prod, true) :
              val root = match(completion-root(item)) :
                (root:EItem) : root
                (f:False) : item
              add-completion(inc-num-parsed(root))

    ;Return whether the starting production has been completed.
    start-completed

  ;Process all rests within the current set
  defn process-rests (current-set:ESet, next-set:ESet) :
    for item in current-set do :
      if upcoming(grammar,item) is GListRest :
        add(next-set, inc-num-parsed(item))

  defn compute-completion-root (set-index:Int, current-set:ESet) :
    ;Compute count table
    clear(production-count)
    for item in current-set do :
      val t = upcoming(grammar,item)
      match(t:GProduction) :
        production-count[name(t)] = production-count[name(t)] + 1
    ;Determine whether deterministic reduction
    defn deterministic-reduction? (item:EItem) :
      val num-tokens = length(tokens(grammar[rule(item)]))
      if num-parsed(item) == num-tokens - 1 :
        val t = upcoming(grammar,item)
        match(t:GProduction) : production-count[name(t)] == 1
    ;Compute completion
    defn complete (item:EItem) :
      if parent(item) < set-index :
        val pitem = first-item(setlist, parent(item), production(grammar,item))
        match(pitem:EItem) : completion-root(pitem)
    ;Compute completions of all deterministic reductions.
    for item in current-set map! :
      if deterministic-reduction?(item) :
        match(complete(item)) :
          (c:EItem) : sub-completion-root(item,c)
          (f:False) : sub-completion-root(item, item)
      else : item

  defn add-to-setlist (current-set:ESet) :
    defn prod? (e:EItem) : upcoming(grammar,e) is GProduction
    add(setlist, filter(prod?, current-set))

  defn record-completions (set-index:Int, current-set:ESet) -> Int|False :
    defn complete? (item:EItem) : upcoming(grammar,item) is False
    var start-id:Int|False = false
    for item in current-set do :
      if complete?(item) :
        val id = length(ranges)
        (start-id = id) when rule(item) == 0
        add(ranges, ParsedRange(id, rule(item), parent(item), set-index))
        within pitem = items(setlist, parent(item), production(grammar, item), false) :
          add(parents, EParent(rule(pitem), parent(pitem), num-parsed(pitem), id, true))
          if completion-root(pitem) is-not False :
            val pitem = completion-root(pitem) as EItem
            add(parents, EParent(rule(pitem), parent(pitem), num-parsed(pitem), id, false))
      else if completion-root(item) is-not False :
        val production = name(upcoming(grammar,item) as GProduction)
        add(parents, ECondParent(rule(item), parent(item), set-index, production))

    start-id

  defn record-missing-input (next-input, index:Int, info:FileInfo|False, eset:ESet) :
    add(missing, MissingInput(next-input, index, info, to-tuple(eset)))

  defn advance-input (input-stream:SExpStream, next-input:SExpToken, current-set:ESet, next-set:ESet) :
    defn list-form? (token:SExpToken) :
      match(token:SExpForm) : unwrap-token(form(token)) is List
    defn prev (item:EItem) : previous(grammar,item)      
    add(inputlist, next-input)
    if list-form?(next-input) :
      if list-expected?(current-set) :
        advance(input-stream, true)
        remove!({prev(_) is GAny}, next-set)
      else :
        advance(input-stream, false)
        remove!({prev(_) is GListStart}, next-set)
    else :
      advance(input-stream, false)
      
  defn process-all-sets () -> Int|False :
    ;Initialize current-set and next-set.
    val current-set = ESet(grammar)
    val next-set = ESet(grammar)
    add(current-set, EItem(0, 0, 0))
    ;Initialize input stream
    val input-stream = SExpStream(input)
    ;Process sets until finished.
    let loop (set-index:Int = 0,
              current-set:ESet = current-set,
              next-set:ESet = next-set) :
      println("===== Processing Set %_ =====" % [set-index])
      val next-input = peek(input-stream)
      println("With input: %_" % [next-input])
      val num-scanned = length(current-set)
      println("Before Processing:")
      print-current-set(grammar, set-index, current-set)
      val start-completed = process-set(set-index, current-set, next-set, next-input)
      compute-completion-root(set-index, current-set)
      println("After Processing:")
      print-current-set(grammar, set-index, current-set)
      println("Next Set:")
      print-current-set(grammar, set-index + 1, next-set)
      ;Case: Not yet finished parsing
      if not empty?(next-set) :
        advance-input(input-stream, next-input, current-set, next-set)  
        add-to-setlist(current-set)
        record-completions(set-index, current-set)
        clear(current-set, 0)
        loop(set-index + 1, next-set, current-set)
      ;Case: Finished parsing successfully
      else if start-completed :
        add-to-setlist(current-set)
        record-completions(set-index, current-set)
      ;Case: Can advance using rest terminal
      else if rest-expected?(current-set) :
        process-rests(current-set, next-set)
        println("Rest Set:")
        print-current-set(grammar, set-index + 1, next-set)
        add(inputlist, advance-rest(input-stream))
        add-to-setlist(current-set)
        record-completions(set-index, current-set)
        clear(current-set, 0)
        loop(set-index + 1, next-set, current-set)
      ;Case: Unexpected input
      else :
        record-missing-input(next-input, set-index, info(input-stream), current-set)
        if list-end-expected?(current-set) : advance(input-stream, false)          
        else if wildcard-expected?(current-set) : insert-wildcard(input-stream)
        else if list-expected?(current-set) : insert-list(input-stream)
        else : fatal("Unrecoverable")
        clear(current-set, num-scanned)
        loop(set-index, current-set, next-set)

  ;Retrieve a child property
  defn child<?T> (field:ParsedRange -> ?T, p:EParent) :
    field(ranges[id(p)])

  ;Lookup key for use in child table.
  defn lookup-key (p:EParent) :
    [rule(p), start(p), index(p), child(end,p)]

  defn parent-key (p:EParent) :
    [child(rule, p), child(start,p), child(end,p)]

  defn lookup-key (rule:Int, start:Int, index:Int, end:Int) :
    [rule, start, index, end]

  ;Select a single tree after disambiguation.
  defn select-tree (start-id:Int) -> ParseNode :
    ;Create children/parent table
    val children-table = group-by(lookup-key, filter-by<EParent>(parents))
    val parent-table = to-hashtable(parent-key, filter-by<ECondParent>(parents)) where :
      defn parent-key (p:ECondParent) : [child-start(p), production(p)]

    defn lookup-child (rule:Int, start:Int, index:Int, end:Int) :
      val cs = children-table[lookup-key(rule, start, index, end)]
      if empty?(tail(cs)) : head(cs)
      else : minimum(specificity-key, cs)

    defn specificity-key (p:EParent) :
      defn make-key (parent-rule:Int, start:Int, end:Int, child-rule:Int) :
        SpecificityKey(associativity(grammar[parent-rule]),
                       end - start,
                       priority(grammar[child-rule]),
                       child-rule)
      val r = ranges[id(p)]
      if direct?(p) :
        make-key(rule(p), start(r), end(r), rule(r))
      else :
        let loop (c-rule:Int = rule(r), c-start:Int = start(r)) :
          val c-production = name(grammar[c-rule])
          val parent = parent-table[[c-start, c-production]]
          if rule(parent) == rule(p) and start(parent) == start(p) :
            make-key(rule(p), c-start, end(r), c-rule)
          else :
            loop(rule(parent), start(parent))

    defn select-tokens (rule:Int,
                        start-position:Int,
                        end-position:Int,
                        rightmost-child:ParseNode|False) -> Tuple<ParseNode>|EParent :
      val grule = grammar[rule]
      val children = Vector<ParseNode>()
      match(rightmost-child:ParseNode) : add(children, rightmost-child)
      val last-index = length(tokens(grule)) - 1
      val start-index = last-index - length(children)
      let loop (index:Int = start-index, end-position:Int = end-position) :
        if index >= 0 :
          match(tokens(grule)[index]) :
            (t:GKeyword|GListStart|GListEnd|GAny|GListRest) :
              loop(index - 1, end-position - 1)
            (t:GProduction) :
              val child-edge = lookup-child(rule, start-position, index, end-position)
              if direct?(child-edge) :
                add(children, select(id(child-edge)))
                loop(index - 1, child(start, child-edge))
              else :
                fatal("Indirect child only allowed on right-most production.") when index < last-index
                child-edge
        else :
          reverse!(children)
          to-tuple(children)

    defn select (range-id:Int) -> ParseNode :
      val range = ranges[range-id]
      match(select-tokens(rule(range), start(range), end(range), false)) :
        (children:Tuple<ParseNode>) :
          ParseNode(rule(range), start(range), end(range), children)
        (indirect-child:EParent) :
          val node = right-recursive-chain(indirect-child)
          if rule(node) != rule(range) or
             start(node) != start(range) or
             end(node) != end(range) :
            fatal("Inconsistent right recursive chain!")
          node

    defn right-recursive-chain (p:EParent) :
      val seed-id = id(p)
      val seed-range = ranges[seed-id]
      let loop (seed-rule:Int = rule(seed-range),
                seed-start:Int = start(seed-range),
                seed:ParseNode = select(seed-id)) :
        val seed-production = name(grammar[seed-rule])
        val parent = parent-table[[seed-start, seed-production]]
        val children = select-tokens(rule(parent), start(parent), seed-start, seed) as Tuple<ParseNode>
        val seed* = ParseNode(rule(parent), start(parent), end(seed-range), children)
        if rule(parent) == rule(p) and start(parent) == start(p) : seed*
        else : loop(rule(parent), start(parent), seed*)

    ;Launch
    select(start-id)

  ;Launch!
  defn main () :
    val start-id = process-all-sets()
    if empty?(missing) : select-tree(start-id as Int)
    else : to-exception(grammar, missing)

  main()

;============================================================
;======================= Test Case ==========================
;============================================================

defn test-parse (rules:Tuple<GRule>, input:List) :
  val g = Grammar(rules)
  match(parse(g, input)) :
    (n:ParseNode) : println(format(g,n))
    (e:ParsingErrors) : println(e)

defn example-grammar () :
  val E = GProduction(`E)
  val N = GKeyword(`N)
  val PLUS = GKeyword(`+)
  val TIMES = GKeyword(`x)
  val LPAREN = GKeyword(`L)
  val RPAREN = GKeyword(`R)
  [GRule(`S, [E])
   GRule(`E, [E PLUS E], 90, LeftAssociative)
   GRule(`E, [E TIMES E], 80, LeftAssociative)
   GRule(`E, [LPAREN E RPAREN])
   GRule(`E, [N])]

deftest print-grammar :
  val g = example-grammar()
  do(println, g)

deftest parse :
  test-parse(example-grammar(), `(N x N x L N + N R x N x N + N x N x N))

defn example-grammar-2 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val B = GKeyword(`B)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GRule(`Start, [S])
   GRule(`S, [E E X])
   GRule(`S, [F F Y])
   GRule(`E, [A A B])
   GRule(`F, [A A B])]

deftest parse-2 :
  val g = example-grammar-2()
  test-parse(g, `(A A B A A B Y))

defn example-grammar-3 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GRule(`Start, [S])
   GRule(`S, [E F X])
   GRule(`S, [F E X])
   GRule(`S, [F F F Y])
   GRule(`E, [A A])
   GRule(`F, [A])]

deftest parse-3 :
  val g = example-grammar-3()
  test-parse(g, `(A A A X))

defn example-grammar-4 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  [GRule(`Start, [S])
   GRule(`S, [E E X])
   GRule(`E, [A])
   GRule(`E, [A A])]

deftest parse-4 :
  val g = example-grammar-4()
  test-parse(g, `(A A A A X))

defn example-grammar-5 () :
  #for E in [ES, E, IF-E, SCLAUSES, SCLAUSE, ECLAUSE] :
    val E = GProduction(`E)
  #for (X in [PLUS, TIMES, LPAREN, RPAREN, N, EQ, LET, IN, IF, COLON, ELSE, SWITCH],
        x in [+, x, L, R, N, =, let, in, if, :, else, switch]) :
    val X = GKeyword(`x)
  [GRule(`Start, [ES GListEnd()])
   GRule(`ES, [E ES])
   GRule(`ES, [])
   GRule(`E, [E PLUS E], 90, LeftAssociative)
   GRule(`E, [E TIMES E], 80, LeftAssociative)
   GRule(`E, [LPAREN E RPAREN])
   GRule(`E, [N])
   GRule(`E, [E EQ E])
   GRule(`E, [LET E EQ E IN E])
   GRule(`E, [IF-E])
   GRule(`IF-E, [IF E COLON E ELSE IF-E])
   GRule(`IF-E, [IF E COLON E ELSE COLON E])
   GRule(`E, [SWITCH LPAREN SCLAUSES ECLAUSE RPAREN])
   GRule(`E, [SWITCH LPAREN SCLAUSES RPAREN])
   GRule(`SCLAUSES, [SCLAUSE SCLAUSES])
   GRule(`SCLAUSES, [])
   GRule(`SCLAUSE, [E COLON E])
   GRule(`ECLAUSE, [ELSE COLON E])]

deftest grammar-calc :
  Grammar(example-grammar-5())

deftest parse-5 :
  val g = example-grammar-5()
  test-parse(g, `(
    switch L
      N : N x N else
      N x N : N
      N + N : N + N +
      else : N x N
    R))

deftest parse-6 :
  test-parse(example-grammar-5(), reader/read-file("test.txt"))

defn example-grammar-6 () :
  #for E in [ES, E] :
    val E = GProduction(`E)
  #for (X in [A B C],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GRule(`Start, [ES])
   GRule(`ES, [E, ES])
   GRule(`ES, [])
   GRule(`E, [A])
   GRule(`E, [B C])]

deftest parse-7 :
  val g = example-grammar-6()
  test-parse(g, `(a a b c a a b c b c a a a a a a a a a a a a a a a a))

deftest parse-mutually-right-recursive :
  #for E in [AS BS CS A B C X] :
    val E = GProduction(`E)
  #for (X in [x a b c],
        x in [x a b c]) :
    val X = GKeyword(`x)
  val rules = [
    GRule(`Start, [X X X AS])
    GRule(`AS, [A, X, BS])
    GRule(`BS, [B, X, CS])
    GRule(`CS, [X])
    GRule(`CS, [C, X, AS])
    GRule(`X, [x])
    GRule(`A, [a])
    GRule(`B, [b])
    GRule(`C, [c])]
  test-parse(rules, `(x x x a x b x c x a x b x c x a x b x x))

deftest right-recursive-priority :
  #for E in [E A BS] :
    val E = GProduction(`E)
  #for (X in [a],
        x in [a]) :
    val X = GKeyword(`x)
  val rules = [
    GRule(`Start, [E])
    GRule(`E, [A BS])
    GRule(`E, [A A A A], 200)
    GRule(`BS, [A BS])
    GRule(`BS, [])
    GRule(`A, [a])]
  test-parse(rules, `(a a a a))

defn example-null-grammar () :
  #for X in [S Ap E] :
    val X = GProduction(`X)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  [GRule(`Start, [S])
   GRule(`S, [Ap Ap Ap Ap])
   GRule(`Ap, [A])
   GRule(`Ap, [E])
   GRule(`E, [])]

deftest parse-null :
  val g = example-null-grammar()
  test-parse(g, `(a a a))

defn example-tricky-null-grammar () :
  #for E in [S, A, B] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GRule(`Start, [S])
   GRule(`S, [w A d])
   GRule(`S, [A d])
   GRule(`S, [w B A A A d])
   GRule(`A, [x])
   GRule(`A, [])
   GRule(`B, [x])]

deftest parse-tricky-null :
  val g = example-tricky-null-grammar()
  test-parse(g, `(w x x d))

defn example-tricky-null-grammar-2 () :
  #for E in [B S A] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GRule(`Start, [B])
   GRule(`B, [S])
   GRule(`B, [A])
   GRule(`S, [w x A A A A d], 100, LeftAssociative)
   GRule(`A, [w x])
   GRule(`A, [])]

deftest parse-tricky-null-2 :
  val g = example-tricky-null-grammar-2()
  test-parse(g, `(w x w x d))

defn list-grammar () :
  #for E in [S, A, B, C, D, L, R, CD, CDs] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  [GRule(`Start, [S GListEnd()])
   GRule(`S, [A B CDs L CDs R CDs])
   GRule(`S, [A B C])
   GRule(`CDs, [CD, CDs])
   GRule(`CDs, [])
   GRule(`CD, [L C D R])
   GRule(`A, [a])
   GRule(`B, [b])
   GRule(`C, [c])
   GRule(`D, [d])
   GRule(`L, [GListStart()])
   GRule(`R, [GListEnd()])]

deftest parse-list :
  val g = list-grammar()
  test-parse(g, `(a b (c d) (c d) ((c d) (c d) (c d)) (c d)))

defn any-vs-list-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [done],
        x in [done]) :
    val X = GKeyword(`x)
  [GRule(`Start, [S GListEnd()])
   GRule(`S, [GAny() done])
   GRule(`S, [GListStart(true) done GListEnd() done])]

deftest parse-any-vs-list :
  val g = any-vs-list-grammar()
  test-parse(g, `((done) done))

defn any-as-list-grammar () :
  #for E in [S A As Xs] :
    val E = GProduction(`E)
;  #for (X in [],
;        x in [a b c d]) :
;    val X = GKeyword(`x)
  [GRule(`Start, [S GListEnd()])
   GRule(`S, [A Xs Xs])
   GRule(`S, [A A A])
   GRule(`A, [GAny()])
   GRule(`A, [GListStart(true) As GListEnd()])
   GRule(`As, [A As])
   GRule(`As, [])
   GRule(`Xs, [GListStart() GKeyword(`a) GKeyword(`b) GKeyword(`c) GListEnd()])]

deftest parse-any-as-list :
  val g = any-as-list-grammar()
  test-parse(g, `(x (a b c) (a b c)))

defn list-recovery-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GRule(`Start, [S GListEnd()])
   GRule(`S, [a GListStart() b GListEnd() c])]

deftest parse-list-recovery :
  val g = list-recovery-grammar()
  test-parse(g, `(a b c))

defn rest-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GRule(`Start, [S GListEnd()])
   GRule(`S, [GListStart() a b GListRest() GListEnd()])]

let :;deftest parse-rest :
  val g = rest-grammar()
  test-parse(g, `(a))