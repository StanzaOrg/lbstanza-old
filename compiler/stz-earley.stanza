#use-added-syntax(tests)
defpackage stz/earley :
  import core
  import collections
  import stz/utils
  import stz/earley-search
  import stz/earley-grammar
  import stz/earley-grammar-analysis
  import stz/earley-eval
  import stz/earley-eval-result
  import stz/earley-parse-tree
  import stz/earley-errors
  import stz/earley-precedence

;============================================================
;======================== Main ==============================
;============================================================

public deftype ParseProgress
public defmulti created-grammar (p:ParseProgress, g:Grammar) -> False
public defmulti parsed (p:ParseProgress, node:ParseNode) -> False
public defmulti reordered (p:ParseProgress, node:ParseNode) -> False
public defmulti failed (p:ParseProgress, e:ParsingErrors) -> False
defmethod created-grammar (p:ParseProgress, g:Grammar) : false
defmethod parsed (p:ParseProgress, node:ParseNode) : false
defmethod failed (p:ParseProgress, e:ParsingErrors) : false
defmethod reordered (p:ParseProgress, node:ParseNode) : false

public defn parse (rules:GRules, input:List) :
  parse(rules, input, new ParseProgress)

public defn parse (rules:GRules, input:List, progress:ParseProgress) -> ? :
  val grammar = Grammar(rules)
  created-grammar(progress,grammar)
  match(search(grammar, input)) :
    (r:SearchSuccess) :
      val parse-node = parse(grammar, setlist(r))
      parsed(progress, parse-node)
      val reordered-node = reorder-operators(grammar, parse-node)
      reordered(progress, reordered-node)
      evaluate-parse-tree(grammar, reordered-node, inputlist(r), infolist(r))
    (f:SearchFailure) :
      val errors = to-exception(grammar, missing(f))
      failed(progress, errors)
      throw(errors)

;============================================================
;====================== Testing =============================
;============================================================

deftype RulesCreator
defmulti make-production (rc:RulesCreator, name:Symbol) -> GProduction
defmulti add (rc:RulesCreator, r:GRule) -> False
defmulti rules (rc:RulesCreator) -> GRules

public defn RulesCreator () :
  val prods = Vector<GDefProduction>()
  val rules = Vector<GRule>()
  new RulesCreator :
    defmethod make-production (this, name:Symbol) :
      val id = length(prods)
      add(prods, GDefProduction(id, name))
      GProduction(id)
    defmethod add (this, r:GRule) :
      add(rules, r)
    defmethod rules (this) :
      GRules(to-tuple(prods), to-tuple(rules))

defn make-matcher (rc:RulesCreator, p:GProduction, t:GTerminal, matcher:? -> True|False, action:ParsedResult -> ?) :
  add(rc, GMatcherRule(id(p), t, matcher, action))
defn make-rule (rc:RulesCreator, p:GProduction, tokens:Tuple<GToken>, params:RuleParams) :
  add(rc, GTokenRule(id(p), tokens, params))
defn make-rule (rc:RulesCreator, p:GProduction, tokens:Tuple<GToken>) :
  add(rc, GTokenRule(id(p), tokens, TokenRuleParams()))

public defn test-parse-without-action (rules:GRules, input:List) :
  label break :
    var grammar:Grammar
    val progress = new ParseProgress :
      defmethod created-grammar (this, g:Grammar) :
        grammar = g
      defmethod parsed (this, node:ParseNode) :
        println("Parsed:")
        println(format(grammar, node))
      defmethod reordered (this, node:ParseNode) :
        println("Reordered:")
        println(format(grammar, node))
        break()
      defmethod failed (this, e:ParsingErrors) :
        println(e)
        break()
    parse(rules, input, progress)

public defn test-parse (rules:GRules, input:List) :
  label break :
    var grammar:Grammar
    val progress = new ParseProgress :
      defmethod created-grammar (this, g:Grammar) :
        grammar = g
      defmethod parsed (this, node:ParseNode) :
        println(format(grammar, node))
      defmethod reordered (this, node:ParseNode) :
        println(format(grammar, node))
      defmethod failed (this, e:ParsingErrors) :
        println(e)
        break()
    val result = parse(rules, input, progress)
    println("Parsed:")
    println(result)

;============================================================
;===================== Examples =============================
;============================================================

defn example-grammar () :
  val rc = RulesCreator()
  val S = make-production(rc,`S)
  val E = make-production(rc,`E)
  val N = GKeyword(`N)
  val PLUS = GKeyword(`+)
  val TIMES = GKeyword(`x)
  val LPAREN = GKeyword(`L)
  val RPAREN = GKeyword(`R)
  make-rule(rc, S, [GListStart(), E, GListEnd()])
  make-rule(rc, E, [E PLUS E], TokenRuleParams(90, LeftAssociative))
  make-rule(rc, E, [E TIMES E], TokenRuleParams(80, LeftAssociative))
  make-rule(rc, E, [LPAREN E RPAREN])
  make-rule(rc, E, [N])
  rules(rc)

deftest print-grammar :
  val g = example-grammar()
  println(g)

deftest parse :
  test-parse-without-action(example-grammar(), `(N x N x L N + N R x N x N + N x N x N))

defn example-grammar-2 () :
  val rc = RulesCreator()
  #for E in [Start, S, E, F] :
    val E = make-production(rc, `E)
  #for (X in [A B X Y],
        x in [A B X Y]) :
    val X = GKeyword(`x)
  make-rule(rc, Start, [GListStart() S GListEnd()])
  make-rule(rc, S, [E E X])
  make-rule(rc, S, [F F Y])
  make-rule(rc, E, [A A B])
  make-rule(rc, F, [A A B])
  rules(rc)

deftest parse-2 :
  val g = example-grammar-2()
  test-parse-without-action(g, `(A A B A A B X))

defn example-grammar-3 () :
  val rc = RulesCreator()
  #for E in [Start, S, E, F] :
    val E = make-production(rc, `E)
  #for (X in [A X Y],
        x in [A X Y]) :
    val X = GKeyword(`x)
  make-rule(rc, Start, [GListStart() S GListEnd()])
  make-rule(rc, S, [E F X])
  make-rule(rc, S, [F E X])
  make-rule(rc, S, [F F F Y])
  make-rule(rc, E, [A A])
  make-rule(rc, F, [A])
  rules(rc)

deftest parse-3 :
  val g = example-grammar-3()
  test-parse-without-action(g, `(A A A X))

defn example-grammar-10 () :
  val rc = RulesCreator()
  #for E in [Start, S, W, X, Y, Z] :
    val E = make-production(rc, `E)
  #for (X in [A B C],
        x in [A B C]) :
    val X = GKeyword(`x)
  make-rule(rc, Start, [GListStart() S GListEnd()])
  make-rule(rc, S, [X Y Z])
  make-rule(rc, S, [W X Y])
  make-rule(rc, W, [A])
  make-rule(rc, X, [A A])
  make-rule(rc, Y, [B B])
  make-rule(rc, Z, [C C])
  rules(rc)
  
deftest parse-10 :
  val g = example-grammar-10()
  test-parse-without-action(g, `(A A A B B))

defn example-grammar-4 () :
  val rc = RulesCreator()
  #for E in [Start, S, E] :
    val E = make-production(rc, `E)
  #for (X in [A X],
        x in [A X]) :
    val X = GKeyword(`x)
  make-rule(rc, Start, [GListStart() S GListEnd()])
  make-rule(rc, S, [E E X])
  make-rule(rc, E, [A])
  make-rule(rc, E, [A A])
  rules(rc)

deftest parse-4 :
  val g = example-grammar-4()
  test-parse-without-action(g, `(A A A A X))

defn precedence-grammar () :
  val rc = RulesCreator()
  val LP = GListStart()
  val RP = GListEnd()
  #for E in [Start, E, EA, IFE] :
    val E = make-production(rc, `E)
  #for (X in [X PLUS MINUS TIMES DIV TILDE EXCLAME IF THEN ELSE],
        x in [X + - * / ~ ! if then else]) :
    val X = GKeyword(`x)
  make-rule(rc, Start, [GListStart() E GListEnd()])
  make-rule(rc, E, [EA PLUS E], TokenRuleParams(90, LeftAssociative, Binary(id(EA), id(E))))
  make-rule(rc, E, [EA MINUS E], TokenRuleParams(90, LeftAssociative, Binary(id(EA), id(E))))
  make-rule(rc, E, [EA TIMES E], TokenRuleParams(80, LeftAssociative, Binary(id(EA), id(E))))
  make-rule(rc, E, [EA DIV E], TokenRuleParams(80, LeftAssociative, Binary(id(EA), id(E))))
  make-rule(rc, E, [TILDE E], TokenRuleParams(70, NonAssociative, Prefix(id(E))))
  make-rule(rc, E, [IFE], TokenRuleParams(100, NonAssociative, Prefix(id(E))))
  make-rule(rc, IFE, [IF E THEN E])
  make-rule(rc, IFE, [IF E THEN E ELSE IFE])
  make-rule(rc, E, [EA], InheritParams())  
  make-rule(rc, EA, [EA EXCLAME], TokenRuleParams(70, NonAssociative, Postfix(id(EA))))
  make-rule(rc, EA, [LP E RP])
  make-rule(rc, EA, [X])
  rules(rc)

deftest test-precedence-grammar-1 :
  val g = precedence-grammar()
  test-parse-without-action(g, `(X + X + X - X * (X / X) ! - (X * X - X) ! + ~ X - X * X))

deftest test-precedence-grammar-2 :
  val g = precedence-grammar()
  val forms = `(
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X)
  test-parse-without-action(g, forms)

deftest test-precedence-grammar-3 :
  val g = precedence-grammar()
  test-parse-without-action(g, `(X * X - if X - X then X + X else if X then X !))

defn bad-precedence-grammar () :
  val rc = RulesCreator()
  val LP = GListStart()
  val RP = GListEnd()
  #for E in [Start, E, EA, IFE] :
    val E = make-production(rc, `E)
  #for (X in [X PLUS MINUS TIMES DIV TILDE EXCLAME IF THEN ELSE],
        x in [X + - * / ~ ! if then else]) :
    val X = GKeyword(`x)
  make-rule(rc, Start, [GListStart() E GListEnd()])
  make-rule(rc, E, [E TIMES E], TokenRuleParams(80, LeftAssociative))
  make-rule(rc, E, [E DIV E], TokenRuleParams(80, LeftAssociative))
  make-rule(rc, E, [E PLUS E], TokenRuleParams(90, LeftAssociative))
  make-rule(rc, E, [E MINUS E], TokenRuleParams(90, LeftAssociative))
  make-rule(rc, E, [TILDE E], TokenRuleParams(70, NonAssociative))
  make-rule(rc, E, [IFE], TokenRuleParams(100, NonAssociative))
  make-rule(rc, IFE, [IF E THEN E])
  make-rule(rc, IFE, [IF E THEN E ELSE IFE])
  make-rule(rc, E, [E EXCLAME], TokenRuleParams(70, NonAssociative))
  make-rule(rc, E, [LP E RP])
  make-rule(rc, E, [X])
  rules(rc)

deftest test-bad-precedence-grammar :
  val g = bad-precedence-grammar()
  val forms = `(
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X +
    X + ~ X * ~ X / X - X ! + X * ~ X ! - X ! - X)
  test-parse-without-action(g, forms)

;<testing>

defn example-grammar-5 () :
  #for E in [ES, E, IF-E, SCLAUSES, SCLAUSE, ECLAUSE] :
    val E = GProduction(`E)
  #for (X in [PLUS, TIMES, LPAREN, RPAREN, N, EQ, LET, IN, IF, COLON, ELSE, SWITCH],
        x in [+, x, L, R, N, =, let, in, if, :, else, switch]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])
   GTokenRule(`E, [E EQ E])
   GTokenRule(`E, [LET E EQ E IN E])
   GTokenRule(`E, [IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE COLON E])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES ECLAUSE RPAREN])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES RPAREN])
   GTokenRule(`SCLAUSES, [SCLAUSE SCLAUSES])
   GTokenRule(`SCLAUSES, [])
   GTokenRule(`SCLAUSE, [E COLON E])
   GTokenRule(`ECLAUSE, [ELSE COLON E])]

deftest grammar-calc :
  Grammar(example-grammar-5())

deftest parse-5 :
  val g = example-grammar-5()
  test-parse-without-action(g, `(
    switch L
      N : N x N
      N x N : N
      N + N : N + N
      else : N x N
    R))

deftest parse-5-2 :
  val g = example-grammar-5()
  test-parse-without-action(g, `(N + N x N + N))

deftest parse-6 :
  test-parse-without-action(example-grammar-5(), reader/read-file("test.txt"))

;<testing>

defn terminal-handling-grammar () :
  val rc = RulesCreator()
  #for E in [Start, S, X, Y] :
    val E = make-production(rc,`E)
  #for (X in [A B PLUS MINUS],
        x in [a b + -]) :
    val X = GKeyword(`x)
  make-rule(rc, Start, [GListStart() S GListEnd()])
  make-rule(rc, S, [X PLUS Y])
  make-rule(rc, S, [X MINUS Y])
  make-rule(rc, X, [A PLUS B])
  make-rule(rc, X, [A])
  make-rule(rc, Y, [B])
  make-rule(rc, Y, [B MINUS B])
  rules(rc)

deftest parse-terminal-handling :
  ;Should not parse using X + Y where
  ;  X = a + b
  ;  Y = b
  val g = terminal-handling-grammar()
  test-parse-without-action(g, `(a + b - b))

defn example-grammar-6 () :
  val rc = RulesCreator()
  #for E in [Start, ES, E] :
    val E = make-production(rc,`E)
  #for (X in [A B C],
        x in [a b c]) :
    val X = GKeyword(`x)
  make-rule(rc, Start, [GListStart() ES GListEnd()])
  make-rule(rc, ES, [E, ES])
  make-rule(rc, ES, [])
  make-rule(rc, E, [A])
  make-rule(rc, E, [B C])
  rules(rc)

deftest parse-7 :
  val g = example-grammar-6()
  test-parse-without-action(g, `(a a b c a a b c b c a a a b c a a a a a a a a a a a a a a))

defn example-grammar-8 () :
  val rc = RulesCreator()
  #for E in [Start AS BS] :
    val E = make-production(rc,`E)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  make-rule(rc, Start, [GListStart() AS GListEnd()])
  make-rule(rc, AS, [A, BS])
  make-rule(rc, BS, [A, AS])
  make-rule(rc, BS, [A])
  rules(rc)

deftest parse-simple-mutual-right-recursive :
  val g = example-grammar-8()
  test-parse-without-action(g, `(a a a a a a a a a a a a a a a a a a a a a a a a a a))

;<testing>
defn example-grammar-9 () :
  #for E in [AS, BS] :
    val E = GProduction(`E)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() AS GListEnd()])
   GTokenRule(`AS, [BS, A])
   GTokenRule(`BS, [AS, A])
   GTokenRule(`BS, [A])]

deftest parse-simple-mutual-left-recursive :
  val g = example-grammar-9()
  test-parse-without-action(g, `(a a a a a a a a a a a a a a a a a a a a a a a a a a))
;<testing>

deftest parse-mutually-right-recursive :
  val rc = RulesCreator()
  #for E in [Start AS BS CS A B C X] :
    val E = make-production(rc,`E)
  #for (X in [x a b c],
        x in [x a b c]) :
    val X = GKeyword(`x)

  make-rule(rc, Start, [GListStart() X X X AS GListEnd()])
  make-rule(rc, AS, [A, X, BS])
  make-rule(rc, BS, [B, X, CS])
  make-rule(rc, CS, [X])
  make-rule(rc, CS, [C, X, AS])
  make-rule(rc, X, [x])
  make-rule(rc, A, [a])
  make-rule(rc, B, [b])
  make-rule(rc, C, [c])
  test-parse-without-action(rules(rc), `(x x x a x b x c x a x b x c x a x b x x))
  
;<testing>
deftest right-recursive-priority :
  #for E in [E A BS] :
    val E = GProduction(`E)
  #for (X in [a],
        x in [a]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [GListStart() E GListEnd()])
    GTokenRule(`E, [A BS])
    GTokenRule(`E, [A A A A], 200)
    GTokenRule(`BS, [A BS])
    GTokenRule(`BS, [])
    GTokenRule(`A, [a])]
  test-parse-without-action(rules, `(a a a a))

defn example-null-grammar () :
  #for X in [S Ap E] :
    val X = GProduction(`X)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [Ap Ap Ap Ap])
   GTokenRule(`Ap, [A])
   GTokenRule(`Ap, [E])
   GTokenRule(`E, [])]

deftest parse-null :
  val g = example-null-grammar()
  test-parse-without-action(g, `(a a a))

defn example-tricky-null-grammar () :
  #for E in [S, A, B] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [w A d])
   GTokenRule(`S, [A d])
   GTokenRule(`S, [w B A A A d])
   GTokenRule(`A, [x])
   GTokenRule(`A, [])
   GTokenRule(`B, [x])]

deftest parse-tricky-null :
  val g = example-tricky-null-grammar()
  test-parse-without-action(g, `(w x x d))

defn example-tricky-null-grammar-2 () :
  #for E in [B S A] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() B GListEnd()])
   GTokenRule(`B, [S])
   GTokenRule(`B, [A])
   GTokenRule(`S, [w x A A A A d], 100, LeftAssociative)
   GTokenRule(`A, [w x])
   GTokenRule(`A, [])]

deftest parse-tricky-null-2 :
  val g = example-tricky-null-grammar-2()
  test-parse-without-action(g, `(w x w x w x w x d))

defn list-grammar () :
  #for E in [S, A, B, C, D, L, R, CD, CDs] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [A B CDs L CDs R CDs])
   GTokenRule(`S, [A B C])
   GTokenRule(`CDs, [CD, CDs])
   GTokenRule(`CDs, [])
   GTokenRule(`CD, [L C D R])
   GTokenRule(`A, [a])
   GTokenRule(`B, [b])
   GTokenRule(`C, [c])
   GTokenRule(`D, [d])
   GTokenRule(`L, [GListStart()])
   GTokenRule(`R, [GListEnd()])]

deftest parse-list :
  val g = list-grammar()
  test-parse-without-action(g, `(a b (c d) (c d) ((c d) (c d) (c d)) (c d)))

defn any-vs-list-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [done],
        x in [done]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [GAny() done])
   GTokenRule(`S, [GListStart() done GListEnd() done])]

deftest parse-any-vs-list :
  val g = any-vs-list-grammar()
  test-parse-without-action(g, `((done) done))

defn any-as-list-grammar () :
  #for E in [S A As Xs] :
    val E = GProduction(`E)
;  #for (X in [],
;        x in [a b c d]) :
;    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [Xs Xs])
   GTokenRule(`S, [A A])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [GListStart(true) As GListEnd()])
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`Xs, [GListStart() GKeyword(`x) GListEnd()])]

deftest parse-any-as-list :
  val g = any-as-list-grammar()
  test-parse-without-action(g, `((x) (x y z)))

defn list-recovery-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [a GListStart() b GListEnd() c])]

deftest parse-list-recovery :
  val g = list-recovery-grammar()
  test-parse-without-action(g, `(a b c))

defn rest-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [GListStart() a b c GListEnd()])
   GTokenRule(`S, [GListStart() a b GListRest() GListEnd()])]

deftest parse-rest :
  val g = rest-grammar()
  test-parse-without-action(g, `((a b d e f)))

defn full-any-grammar () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [LP a b LP c d R RP RP])
   GTokenRule(`S, [LP a b LP c RP RP])

   GTokenRule(`S, [A])
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]

deftest parse-full-any-grammar :
  val g = full-any-grammar()
  test-parse-without-action(g, `((a b (c d))))

defn full-any-grammar-2 () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [A a b c])
   GTokenRule(`S, [R])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]

deftest parse-full-any-grammar-2 :
  val g = full-any-grammar-2()
  test-parse-without-action(g, `((x y z) a b c))

defn amb-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [LP S RP])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])]

deftest parse-amb-grammar :
  val g = amb-grammar()
  test-parse-without-action(g, `(red red dog dog red dog dog dog))

defn amb-grammar-2 () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [LP S RP])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])
   GTokenRule(`E, [red dog])]

deftest parse-amb-grammar-2 :
  val g = amb-grammar-2()
  test-parse-without-action(g, `(red dog dog dog dog red red dog dog red red dog dog dog red dog dog red dog dog))

defn if-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [IF THEN ELSE N],
        x in [if then else N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [LP S RP])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [LP E RP])
   GTokenRule(`E, [IF E THEN E], 100, LeftAssociative)
   GTokenRule(`E, [IF E THEN E ELSE E], 100, LeftAssociative)
   GTokenRule(`E, [N])]

deftest parse-if-grammar :
  val g = if-grammar()
  test-parse-without-action(g, `(if N then if N then N else N))

defn matcher-grammar () :
  #for E in [ES E Id BId RId] :
    val E = GProduction(`E)
  #for (X in [VAR EQ N DOT],
        x in [var = N .]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn prefix-symbol? (form, prefix:String) :
    val s = unwrap-token(form) as Symbol
    prefix?(name(s), prefix)
  [GTokenRule(`Start, [LP ES RP])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [VAR Id EQ E])
   GTokenRule(`E, [N])
   GTokenRule(`Id, [BId DOT RId])
   GMatcherRule(`BId, GPrimToken(GSymbolType), prefix-symbol?{_, "B"})
   GMatcherRule(`RId, GPrimToken(GSymbolType), prefix-symbol?{_, "R"})]

deftest parse-matcher-grammar :
  val g = matcher-grammar()
  test-parse-without-action(g, `(var B10.R18 = N N))

deftest parse-matcher-grammar-error :
  val g = matcher-grammar()
  test-parse-without-action(g, `("hello world"))

defn core-form-grammar () :
  #for E in [ES E A R] :
    val E = GProduction(`E)
  #for (X in [CORE],
        x in [$core]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn core-form? (form) :
    match(unwrap-token(form)) :
      (f:List) : not empty?(f) and unwrap-token(head(f)) == `$core
      (f) : false

  [GTokenRule(`Start, [LP ES RP])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [CORE])
   GTokenRule(`E, [LP ES RP])
   GMatcherRule(`E, GAny(Atomic), core-form?)

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP R RP])
   GTokenRule(`R, [GAny() R])
   GTokenRule(`R, [LP R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]

deftest parse-core-form-grammar :
  val g = core-form-grammar()
  test-parse-without-action(g, `($core ($core a b c d) $core))

defn exp-grammar () :
  #for E in [ES E ID A R] :
    val E = GProduction(`E)
  #for (X in [VAR VAL FOR LET IN EQ COLON PLUS TIMES N DO],
        x in [var val for let in = : + * N @do]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()

  [GTokenRule(`Start, [LP ES RP], fn (result) :
     result[1])

   GTokenRule(`keywords, [VAR])
   GTokenRule(`keywords, [VAL])
   GTokenRule(`keywords, [FOR])
   GTokenRule(`keywords, [LET])
   GTokenRule(`keywords, [IN])
   GTokenRule(`keywords, [EQ])
   GTokenRule(`keywords, [COLON])
   GTokenRule(`keywords, [DO])

   GTokenRule(`A, [GAny()], fn (result) : result[0])
   GTokenRule(`A, [LP* R RP], fn (result) : result[0])
   GTokenRule(`R, [GAny(Reluctant) R], fn (result) : form(result))
   GTokenRule(`R, [LP* R RP R], fn (result) : form(result))
   GTokenRule(`R, [GListRest()], fn (result) : form(result))
   GTokenRule(`R, [], fn (result) : form(result))

   GTokenRule(`ID, [A], fn (result) :
     result[0])
   ;GNegationRule(`ID, GProduction(`keywords))

   GTokenRule(`ES, [E ES], 100, LeftAssociative, fn (result) :
     cons(result[0], result[1]))
   GTokenRule(`ES, [], fn (result) :
     List())

   GTokenRule(`E, [VAR ID EQ E], fn (result) :
     qquote($var ~(result[1]) ~(result[3])))
   GTokenRule(`E, [VAL ID EQ E], fn (result) :
     qquote($val ~(result[1]) ~(result[3])))
   GTokenRule(`E, [FOR ID IN E COLON E], fn (result) :
       qquote($for ~(result[1]) ~(result[3]) ~(result[5])))
   GTokenRule(`E, [LET ID EQ E COLON E], fn (result) :
     qquote($let ~(result[1]) ~(result[3]) ~(result[5])))
   GTokenRule(`E, [E LP DO ES RP], 70, LeftAssociative, fn (result) :
     qquote($call ~(result[0]) ~@(result[3])))
   GTokenRule(`E, [LP E RP], fn (result) :
     result[1])
   GTokenRule(`E, [LP ES RP], fn (result) :
     qquote($begin ~@(result[1])))
   GTokenRule(`E, [N], fn (result) :
     result[0])
   GTokenRule(`E, [GPrimToken(GIntType)], fn (result) :
     result[0])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative, fn (result) :
     qquote($plus ~(result[0]), ~(result[2])))
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative, fn (result) :
     qquote($times ~(result[0]), ~(result[2])))]

deftest parse-exp-grammar :
  test-parse(exp-grammar(), reader/read-file("exp-test.txt"))

deftest action-exp-grammar :
  test-parse-without-action(exp-grammar(), reader/read-file("exp-test.txt"))

defn rest-priority-grammar () :
  #for E in [ES E F A R] :
    val E = GProduction(`E)
  #for (X in [PLUS N],
        x in [+ N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()

  [GTokenRule(`Start, [LP F RP])

   GTokenRule(`F, [E E], 100, LeftAssociative)

   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   ;GTokenRule(`E, [N R], true)
   GTokenRule(`E, [N])

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]

deftest parse-rest-priority-grammar :
  val g = rest-priority-grammar()
  test-parse-without-action(g, `(N + N + N N + N))

;<testing>

deftest parse-blowup-grammar :
  val rc = RulesCreator()
  #for E in [Start E] :
    val E = make-production(rc,`E)
  #for (X in [N],
        x in [N]) :
    val X = GKeyword(`x)
  make-rule(rc, Start, [GListStart() E GListEnd()])
  make-rule(rc, E, [E E E])
  make-rule(rc, E, [N])
  test-parse-without-action(rules(rc),
                          `(N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N
                            N N N N N N N N N N N N N N N N N N N))



defn substanza-grammar () :
  val rc = RulesCreator()
  ;Define productions
  #for E in [Start, ES E EA EB EC ID A R IFE TYPE TYPES] :
    val E = make-production(rc,`E)

  ;Define keywords
  #for (X in [X Y VAR VAL FOR LET IN EQ COLON PLUS MINUS TIMES DIV, MOD, DO TUPLE IF ELSE AND OR ARROW OF QUESTION VOID CAP
              AND-WORD, OR-WORD, NOT, EQEQ, NOTEQ, LESS, LESSEQ, GREATER, GREATEREQ, SHL, SHR, ASHR, CARAT, SUF, PRE, END],
        x in [x y var val for let in = : + - * / % @do @tuple if else & | -> @of ? Void @cap
              and or not == != < <= > >= << >> >>> ^, suf, pre, end]) :
    val X = GKeyword(`x)

  ;Define list terminals
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()

  ;Define reserved keywords
  val reserved = to-hashset<Symbol> $ `(
    @do @get @do-afn @afn @quote @tuple @of @cap
    var val for let in if else = : + - / * % & | -> ? Void
    and or not == < <= > >= << >> >>> ^ suf pre)
  defn identifier? (x) :
    not reserved[unwrap-token(x)]

  ;Starting Rule
  make-rule(rc, Start, [LP ES RP], TokenRuleParams(fn (result) : result[1]))

  ;Any Rules
;  make-rule(rc, A, [GAny()], TokenRuleParams(fn (result) : result[0]))
;  make-rule(rc, A, [LP* R RP], TokenRuleParams(fn (result) : result[0]))
;  make-rule(rc, R, [GAny(Reluctant) R], TokenRuleParams(fn (result) : form(result)))
;  make-rule(rc, R, [LP* R RP R], TokenRuleParams(fn (result) : form(result)))
;  make-rule(rc, R, [GListRest()], TokenRuleParams(fn (result) : form(result)))
;  make-rule(rc, R, [], TokenRuleParams(fn (result) : form(result)))

  ;Identifier
  make-matcher(rc, ID, GPrimToken(GSymbolType), identifier?, fn (result) : result[0])

  ;Expression List
  make-rule(rc, ES, [E ES], TokenRuleParams(fn (result) : cons(result[0], result[1])))
  make-rule(rc, ES, [], TokenRuleParams(fn (result) : List()))

;  ;Type List
;  make-rule(rc, TYPES, [TYPE TYPES], TokenRuleParams(fn (result) : cons(result[0], result[1])))
;  make-rule(rc, TYPES, [], TokenRuleParams(fn (result) : List()))
;
;  ;Type
;  make-rule(rc, TYPE, [TYPE ARROW TYPE], TokenRuleParams(100, RightAssociative, fn (result) :
;    qquote($-> (~(result[0])) ~(result[2]))))
;  make-rule(rc, TYPE, [LP TYPES RP ARROW TYPE], TokenRuleParams(100, RightAssociative, fn (result) :
;    qquote($-> (~@(result[1])) ~(result[4]))))
;  make-rule(rc, TYPE, [TYPE OR TYPE], TokenRuleParams(80, LeftAssociative, fn (result) :
;    qquote($or ~(result[0]) ~(result[2]))))
;  make-rule(rc, TYPE, [TYPE AND TYPE], TokenRuleParams(70, LeftAssociative, fn (result) :
;    qquote($and ~(result[0]) ~(result[2]))))
;  make-rule(rc, TYPE, [TYPE LP OF TYPES RP], TokenRuleParams(fn (result) :
;    qquote($of ~(result[0]) ~@(result[3]))))
;  make-rule(rc, TYPE, [LP TYPE RP], TokenRuleParams(fn (result) :
;    result[1]))
;  make-rule(rc, TYPE, [LP CAP ID RP], TokenRuleParams(fn (result) :
;    qquote($cap ~(result[2]))))
;  make-rule(rc, TYPE, [ID], TokenRuleParams(fn (result) :
;    result[0]))
;  make-rule(rc, TYPE, [QUESTION], TokenRuleParams(fn (result) :
;    `($?)))
;  make-rule(rc, TYPE, [VOID], TokenRuleParams(fn (result) :
;    `($void)))
;  make-rule(rc, TYPE, [LP TUPLE TYPES RP], TokenRuleParams(fn (result) :
;    qquote($tuple ~@(result[2]))))


  ;Expression
;  make-rule(rc, E, [ID], TokenRuleParams(fn (result) : result[0]))
;  make-rule(rc, E, [VAR ID COLON TYPE], TokenRuleParams(fn (result) :
;    qquote($var ~(result[1]) ~(result[3]) ($none))))
;  make-rule(rc, E, [VAR ID EQ E], TokenRuleParams(fn (result) :
;    qquote($var ~(result[1]) ($none) ~(result[3]))))
;  make-rule(rc, E, [VAL ID EQ E], TokenRuleParams(fn (result) :
;    qquote($val ~(result[1]) ($none) ~(result[3]))))
;  make-rule(rc, E, [FOR ID IN E COLON E], TokenRuleParams(fn (result) :
;      qquote($for ~(result[1]) ~(result[3]) ~(result[5]))))
;  make-rule(rc, E, [LET COLON E], TokenRuleParams(fn (result) :
;    qquote($let ~(result[2]))))
;  make-rule(rc, E, [E LP DO ES RP], TokenRuleParams(30, LeftAssociative, fn (result) :
;    qquote($do ~(result[0]) ~@(result[3]))))
    
;  make-rule(rc, E, [IFE], TokenRuleParams(fn (result) : result[0]))
;  make-rule(rc, IFE, [IF E COLON E], TokenRuleParams(fn (result) :
;    qquote($if ~(result[1]) ~(result[3]))))
;  make-rule(rc, IFE, [IF E COLON E ELSE IFE], TokenRuleParams(fn (result) :
;    qquote($if ~(result[1]) ~(result[3]) ~(result[5]))))
;  make-rule(rc, IFE, [IF E COLON E ELSE COLON E], TokenRuleParams(fn (result) :
;    qquote($if ~(result[1]) ~(result[3]) ~(result[6]))))

;  make-rule(rc, E, [LP E RP], TokenRuleParams(fn (result) :
;    result[1]))
;  make-rule(rc, E, [LP ES RP], TokenRuleParams(fn (result) :
;    qquote($begin ~@(result[1]))))
;  make-rule(rc, E, [GPrimToken(GIntType)], TokenRuleParams(fn (result) :
;    result[0]))


  ;DEBUG
  ;make-rule(rc, E, [IFE], TokenRuleParams(fn (result) : result[0]))
;  make-rule(rc, E, [E IF], TokenRuleParams(fn (result) :
;    qquote($if ~(result[0]))))
;  make-rule(rc, E, [E PLUS E], TokenRuleParams(70, LeftAssociative, fn (result) :
;    qquote($plus ~(result[0]), ~(result[2]))))
;  make-rule(rc, E, [EA], InheritParams())

  ;;Operators
  ;make-rule(rc, E, [E AND-WORD E], TokenRuleParams(90, LeftAssociative, fn (result) :
  ;  qquote($and ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E OR-WORD E], TokenRuleParams(90, LeftAssociative, fn (result) :
  ;  qquote($or ~(result[0]), ~(result[2]))))
  ;
  ;;Comparison Operators
  ;make-rule(rc, E, [NOT E], TokenRuleParams(80, NonAssociative, fn (result) :
  ;  qquote($not ~(result[1]))))
  ;make-rule(rc, E, [E EQEQ E], TokenRuleParams(80, LeftAssociative, fn (result) :
  ;  qquote($eq ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E NOTEQ E], TokenRuleParams(80, LeftAssociative, fn (result) :
  ;  qquote($noteq ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E LESS E], TokenRuleParams(80, LeftAssociative, fn (result) :
  ;  qquote($less ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E LESSEQ E], TokenRuleParams(80, LeftAssociative, fn (result) :
  ;  qquote($less-eq ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E GREATER E], TokenRuleParams(80, LeftAssociative, fn (result) :
  ;  qquote($greater ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E GREATEREQ E], TokenRuleParams(80, LeftAssociative, fn (result) :
  ;  qquote($greater-eq ~(result[0]), ~(result[2]))))

  ;Arithmetic Operators
;  make-rule(rc, EA, [E PLUS EB], TokenRuleParams(70, LeftAssociative, fn (result) :
;    qquote($plus ~(result[0]), ~(result[2]))))
;  make-rule(rc, EA, [EB], InheritParams())
    
  ;make-rule(rc, E, [E MINUS E], TokenRuleParams(70, LeftAssociative, fn (result) :
  ;  qquote($minus ~(result[0]), ~(result[2]))))

  ;Multiply Operators
  ;make-rule(rc, E, [E TIMES E], TokenRuleParams(60, LeftAssociative, fn (result) :
  ;  qquote($times ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E DIV E], TokenRuleParams(60, LeftAssociative, fn (result) :
  ;  qquote($div ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E MOD E], TokenRuleParams(60, LeftAssociative, fn (result) :
  ;  qquote($mod ~(result[0]), ~(result[2]))))

  ;Bit operators
  ;make-rule(rc, E, [E OR E], TokenRuleParams(50, LeftAssociative, fn (result) :
  ;  qquote($bit-or ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E AND E], TokenRuleParams(50, LeftAssociative, fn (result) :
  ;  qquote($bit-and ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E CARAT E], TokenRuleParams(50, LeftAssociative, fn (result) :
  ;  qquote($bit-xor ~(result[0]), ~(result[2]))))

  ;Bit shift operators
  ;make-rule(rc, E, [E SHL E], TokenRuleParams(40, LeftAssociative, fn (result) :
  ;  qquote($bit-shl ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E SHR E], TokenRuleParams(40, LeftAssociative, fn (result) :
  ;  qquote($bit-shr ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E ASHR E], TokenRuleParams(40, LeftAssociative, fn (result) :
  ;  qquote($bit-ashr ~(result[0]), ~(result[2]))))

;  make-rule(rc, E, [ID], TokenRuleParams(fn (result) : result[0]))
;  make-rule(rc, E, [E IF], TokenRuleParams(fn (result) :
;    qquote($if ~(result[0]))))
;  make-rule(rc, E, [X PLUS Y], TokenRuleParams(fn (result) :
;    qquote($x+y)))
;  make-rule(rc, E, [E PLUS E], TokenRuleParams(70, RightAssociative, fn (result) :
;    qquote($plus ~(result[0]), ~(result[2]))))
;  make-rule(rc, E, [E TIMES E], TokenRuleParams(60, RightAssociative, fn (result) :
;    qquote($times ~(result[0]), ~(result[2]))))


  ;Pre-Transformation
  ;make-rule(rc, E, [PRE E], TokenRuleParams(100, NonAssociative, fn (result) :
  ;  qquote($pre ~(result[1]))))
  ;make-rule(rc, E, [E SUF], TokenRuleParams(100, NonAssociative, fn (result) :
  ;  qquote($suf ~(result[0]))))
  ;make-rule(rc, E, [E PLUS E], TokenRuleParams(70, RightAssociative, fn (result) :
  ;  qquote($plus ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [E TIMES E], TokenRuleParams(60, RightAssociative, fn (result) :
  ;  qquote($times ~(result[0]), ~(result[2]))))
  ;make-rule(rc, E, [ID], TokenRuleParams(fn (result) : result[0]))

  make-rule(rc, E, [E Y E SUF], TokenRuleParams(70, RightAssociative, fn (result) :
    qquote($suf ~(result[0]))))
  make-rule(rc, E, [PRE E], TokenRuleParams(70, RightAssociative, fn (result) :
    qquote($pre ~(result[0]))))
  make-rule(rc, E, [X], TokenRuleParams(70, RightAssociative, fn (result) :
    qquote($id ~(result[0]))))

;  ;Post-Transformation
;  make-rule(rc, E, [EA PLUS E], TokenRuleParams(70, RightAssociative, fn (result) :
;    qquote($plus ~(result[0]), ~(result[2]))))
;  make-rule(rc, E, [EA TIMES E], TokenRuleParams(60, RightAssociative, fn (result) :
;    qquote($times ~(result[0]), ~(result[2]))))
;  make-rule(rc, E, [PRE E], TokenRuleParams(100, NonAssociative, fn (result) :
;    qquote($pre ~(result[1]))))
;  make-rule(rc, E, [IFE], TokenRuleParams(100, NonAssociative, fn (result) :
;    qquote($pre ~(result[0]))))
;  make-rule(rc, E, [EA], InheritParams())
;
;  make-rule(rc, IFE, [IF E COLON E], TokenRuleParams(100, NonAssociative, fn (result) :
;    qquote($if ~(result[1]) ~(result[3]))))    
;  make-rule(rc, IFE, [IF E], TokenRuleParams(100, NonAssociative, fn (result) :
;    qquote($if ~(result[1]))))    
;
;  make-rule(rc, EA, [EA SUF], TokenRuleParams(100, NonAssociative, fn (result) :
;    qquote($suf ~(result[0]))))
;  make-rule(rc, EA, [ID], TokenRuleParams(fn (result) : result[0]))

  ;Return rules
  rules(rc)

deftest parse-stanza-grammar :
  test-parse(substanza-grammar(), reader/read-file("stanza-test.txt"))


defn inherit-grammar () :
  val rc = RulesCreator()
  ;Define productions
  #for E in [Start, ES E EA ID] :
    val E = make-production(rc,`E)

  ;Define keywords
  #for (X in [X, PLUS, TIMES, CARAT],
        x in [x, + * ^]) :
    val X = GKeyword(`x)

  ;Define list terminals
  val LP = GListStart()
  val RP = GListEnd()

  ;Define reserved keywords
  val reserved = to-hashset<Symbol> $ `(+ -)
  defn identifier? (x) :
    not reserved[unwrap-token(x)]

  ;Starting Rule
  make-rule(rc, Start, [LP E RP], TokenRuleParams(fn (result) : result[1]) )

  ;Identifier
  make-matcher(rc, ID, GPrimToken(GSymbolType), identifier?, fn (result) : result[0])

  ;Operators
  make-rule(rc, E, [ID], TokenRuleParams(100, NonAssociative))
  make-rule(rc, E, [E PLUS E], TokenRuleParams(90, LeftAssociative))
  make-rule(rc, E, [EA], InheritParams())

  make-rule(rc, EA, [E TIMES E], TokenRuleParams(80, LeftAssociative))
  make-rule(rc, EA, [E CARAT E], TokenRuleParams(70, LeftAssociative))
  make-rule(rc, EA, [X PLUS E], TokenRuleParams(100, LeftAssociative))

  ;Return rules
  rules(rc)

deftest inherit-grammar :
  val forms = `(x + x + y)
  test-parse-without-action(inherit-grammar(), forms)

defn bad-performance-grammar () :
  val rc = RulesCreator()
  ;Define productions
  #for E in [Start, ES E EA ID] :
    val E = make-production(rc,`E)

  ;Define keywords
  #for (X in [X, PLUS, TIMES, CARAT],
        x in [x + * ^]) :
    val X = GKeyword(`x)

  ;Define list terminals
  val LP = GListStart()
  val RP = GListEnd()

  ;Define reserved keywords
  val reserved = to-hashset<Symbol> $ `(+ - + ^)
  defn identifier? (x) :
    not reserved[unwrap-token(x)]

  ;Starting Rule
  make-rule(rc, Start, [LP E RP], TokenRuleParams(fn (result) : result[1]) )

  ;Identifier
  make-matcher(rc, ID, GPrimToken(GSymbolType), identifier?, fn (result) : result[0])

  ;Operators
  make-rule(rc, E, [ID], TokenRuleParams(100, NonAssociative))
  make-rule(rc, E, [E PLUS E], TokenRuleParams(90, LeftAssociative))
  make-rule(rc, E, [E TIMES E], TokenRuleParams(80, LeftAssociative))
  make-rule(rc, E, [E CARAT E], TokenRuleParams(70, RightAssociative))

  ;Return rules
  rules(rc)

deftest bad-performance-grammar :
  val forms = `(x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w)
  test-parse-without-action(bad-performance-grammar(), forms)

defn good-performance-grammar () :
  val rc = RulesCreator()
  ;Define productions
  #for E in [Start, ES E EA EB EC ID] :
    val E = make-production(rc,`E)

  ;Define keywords
  #for (X in [PLUS, TIMES, CARAT],
        x in [+ * ^]) :
    val X = GKeyword(`x)

  ;Define list terminals
  val LP = GListStart()
  val RP = GListEnd()

  ;Define reserved keywords
  val reserved = to-hashset<Symbol> $ `(+ - + ^)
  defn identifier? (x) :
    not reserved[unwrap-token(x)]

  ;Starting Rule
  make-rule(rc, Start, [LP E RP], TokenRuleParams(fn (result) : result[1]) )

  ;Identifier
  make-matcher(rc, ID, GPrimToken(GSymbolType), identifier?, fn (result) : result[0])

  ;Operators
  make-rule(rc, E, [E PLUS EA], TokenRuleParams(90, LeftAssociative))
  make-rule(rc, E, [EA], InheritParams())

  make-rule(rc, EA, [EA TIMES EB], TokenRuleParams(80, LeftAssociative))
  make-rule(rc, EA, [EB], InheritParams())

  make-rule(rc, EB, [EB CARAT EC], TokenRuleParams(70, LeftAssociative))
  make-rule(rc, EB, [EC], InheritParams())

  make-rule(rc, EC, [ID], TokenRuleParams(100, NonAssociative))

  ;Return rules
  rules(rc)

deftest good-performance-grammar :
  val forms = `(x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w +
                x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w * x ^ y ^ z ^ w)

  test-parse-without-action(good-performance-grammar(), forms)


defn hard-precedence-grammar () :
  val rc = RulesCreator()
  ;Define productions
  #for E in [Start, E, ID] :
    val E = make-production(rc,`E)

  ;Define keywords
  val reserved = HashSet<Symbol>()
  #for (X in [PLUS, TIMES, L, R],
        x in [+ * L R]) :
    val X = GKeyword(`x)
    add(reserved, `x)

  ;Define reserved keywords
  defn identifier? (x) :
    not reserved[unwrap-token(x)]

  ;Starting Rule
  make-rule(rc, Start, [GListStart() E GListEnd()], TokenRuleParams(fn (result) : result[1]))

  ;Identifier
  make-matcher(rc, ID, GPrimToken(GSymbolType), identifier?, fn (result) : result[0])

  ;Operators
  make-rule(rc, E, [E PLUS E], TokenRuleParams(100, LeftAssociative))
  make-rule(rc, E, [E L E], TokenRuleParams(100, LeftAssociative))
  make-rule(rc, E, [L E R], TokenRuleParams(100, LeftAssociative))
  make-rule(rc, E, [R], TokenRuleParams(100, LeftAssociative))
  make-rule(rc, E, [ID], TokenRuleParams(100, NonAssociative))

  ;Return rules
  rules(rc)

deftest hard-precedence-grammar :
  val forms = `(x L L R R)
  test-parse-without-action(hard-precedence-grammar(), forms)

;Parameters that we need to know:
;1. Is it a LR production?
;2. Is it a Prefix Rule, Postfix Rule, Binary Rule