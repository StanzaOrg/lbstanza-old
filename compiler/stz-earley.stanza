#use-added-syntax(tests)
defpackage stz/earley :
  import core
  import collections
  import stz/utils
  import stz/earley-search
  import stz/earley-eitems
  import stz/earley-grammar
  import stz/earley-eval-result
  import stz/earley-sexp-stream

;============================================================
;======================== Utilities =========================
;============================================================

defn add-all<?T> (q:Queue<?T>, xs:Seqable<T>) :
  do(add{q, _}, xs)

defn add<?K,?V> (table:Table<?K,List<?V>>, k:K, v:V) :
  update(table, cons{v, _,}, k)

defn wrap (token, info:FileInfo|False) :
  match(info:FileInfo) : Token(token, info)
  else : token 

;============================================================
;==================== Error Handling ========================
;============================================================

public defstruct MissingInput :
  input
  set-index: Int
  info: FileInfo|False
  items: Tuple<EItem>

defstruct MissingInputError <: Exception :
  input
  info: FileInfo|False
  productions: Tuple<Symbol>
  upcoming: Tuple<GToken>

public defstruct ParsingErrors <: Exception :
  errors: Tuple<Exception>

public defn to-exception (g:Grammar, m:MissingInput) :
  println("Form Exception from:")
  for item in items(m) do :
    println(format(g,item))
  println("input = %_" % [input(m)])
    
  ;Compute earliest completed productions
  defn completed? (item:EItem) :
    val tokens = tokens!(g[rule(item)])
    num-parsed(item) == length(tokens)
  val completed-productions = HashTable<Symbol,Int>(INT-MAX)
  for item in filter(completed?,items(m)) do :
    update(completed-productions, min{_, parent(item)}, production(g,item))

  ;Compute productions and upcoming
  val productions = HashSet<Symbol>()
  val upcoming-tokens = HashSet<GToken>()
  for item in items(m) do :
    val production = production(g,item)    
    val include? = match(upcoming(g,item)) :
      (t:GTerminal) :
        num-parsed(item) > 0 and
        completed-productions[production] > parent(item)
      (t:GProduction) :
        num-parsed(item) > 0 and 
        completed-productions[production] > parent(item)
      (t:False) :
        false
    if include? :
      add(productions, production)
      add(upcoming-tokens, upcoming(g, item) as GToken)

  ;Return error
  MissingInputError(input(m), info(m), to-tuple(productions), qsort(upcoming-tokens))

public defn to-exception (g:Grammar, input-ms:Collection<MissingInput>) :  
  val ms = to-tuple(input-ms)
  defn first-in-chain? (i:Int) : i == 0 or set-index(ms[i - 1]) < set-index(ms[i]) - 1
  ;val es = seq(to-exception{g, ms[_]}, filter(first-in-chain?, 0 to length(ms)))
  val es = seq(to-exception{g, ms[_]}, 0 to length(ms))
  ParsingErrors $ to-tuple $ es

defmethod print (o:OutputStream, e:MissingInputError) :
  val info-str = "" when info(e) is False else "%_: " % [info(e)]
  val input-str = match(input(e)) :
    (x:EndOfInput) : "end of input"
    (x:SExpForm) :
      match(unwrap-token(form(x))) :
        (f:Symbol) : "symbol '%~'" % [f]
        (f:List) : "list"
        (f) : "input '%~'" % [f]
    (x:SExpListEnd) : "end of list"
  defn token-str (t:GToken) :
    match(t) :
      (t:GProduction) : "a '%~' production" % [name(t)]
      (t:GKeyword) : "'%~'" % [item(t)]
      (t:GListStart) : "a list"
      (t:GListEnd) : "the end of the list"
      (t:GAny) : "a form"
      (t) : t
  defn tokens-str (ts:Tuple<GToken>) :
    if length(ts) == 1 :
      token-str(ts[0])
    else :
      val but-last-t = ts[0 to length(ts) - 1]
      val last-t = ts[length(ts) - 1]
      "either %,, or %_" % [seq(token-str,but-last-t), token-str(last-t)]
  defn productions-str (names:Tuple<Symbol>) :
    tokens-str(map(GProduction,names))
  print(o, "%_Unexpected %_." % [info-str, input-str])
  if not empty?(productions(e)) :
    print(o, " Current parsing %_ and %_ is expected next." % [
      productions-str(productions(e)), tokens-str(upcoming(e))])

defmethod print (o:OutputStream, e:ParsingErrors) :
  print(o, "Could not parse the given input:")
  val o2 = IndentedStream(o)
  do(lnprint{o2, _}, errors(e))

;============================================================
;====================== Debugging ===========================
;============================================================

public defn format (grammar:Grammar, r:ParsedRange) :
  "(rule %_) [%_ to %_] %_" % [rule(r), start(r), end(r), grammar[rule(r)]]

public defn format (grammar:Grammar, node:ParseNode) :
  within o = Printable() :
    print(o, format(grammar, range(node)))
    val o2 = IndentedStream(o)
    do(lnprint{o2, format(grammar,_)}, filter-by<ParseNode>(children(node)))

defn Printable (f:OutputStream -> ?) :
  new Printable :
    defmethod print (o:OutputStream, this) :
      f(o)

;============================================================
;================== New Parse Forest ========================
;============================================================

defstruct PartialRule <: Hashable&Equalable :
  rule: Int
  num-parsed: Int
  start: Int
  end: Int
with:
  printer => true

defn parts (r:PartialRule) : [rule(r), num-parsed(r), start(r), end(r)]
defmethod equal? (a:PartialRule, b:PartialRule) : parts(a) == parts(b)
defmethod hash (r:PartialRule) : hash(parts(r))

;- setlist is the setlist from the backwards parse.
public defn NewParseForest (grammar:Grammar, setlist:ESetList) :
  ;Convert the set index from the backwards parse to the
  ;position in the input stream.
  defn set-index-to-position (index:Int) -> Int :
    length(setlist) - 1 - index
  defn position-to-set-index (position:Int) -> Int :
    length(setlist) - 1 - position
    
  ;Compute partial rules:
  ;Each item PartialRule(rule, num-parsed, start, end) means:
  ;  The input from start (inclusive) to end (exclusive) can successfully
  ;  be parsed as the tokens at index 'num-parsed' and after in rule 'rule'.
  val partial-rules = HashSet<PartialRule>()
  defn init-partial-rules () :
    for eset in sets(setlist) do :
      for item in items(setlist,eset) do :
        val start = set-index-to-position(index(eset))
        val end = set-index-to-position(parent(item))
        add(partial-rules, PartialRule(rule(item), num-parsed(item), start, end))

  ;Compute production parses:
  ;Each entry ProdPos(prod, position) => (R1, R2, ...) means:
  ;  The production 'prod' starting from position 'position' can be
  ;  parsed in the ways given by R1, R2, ....
  ;To be consistent, the start position in each R1, R2 is equal to
  ;'position'.
  val prod-parses = HashTable<ProdPos, List<ParsedRange>>(List())
  defn add-production-range (set-index:Int, item:EItem) :
    fatal("Illegal item") when num-parsed(item) > 0
    val prodpos = ProdPos(production(grammar,item),
                          set-index-to-position(set-index))
    val range = ParsedRange(rule(item),
                            set-index-to-position(set-index),
                            set-index-to-position(parent(item)))
    update(prod-parses, cons{range, _}, prodpos)
  defn init-prod-parses () :
    for eset in sets(setlist) do :
      for item in items(setlist, eset) do :
        if num-parsed(item) == 0 :
          add-production-range(index(eset), item)

  ;Expand all completed items with completion roots for the given
  ;set. For any additional completed items, add them as production-ranges.
  val added-completed-parses = IntSet()
  defn create-completion-production-parses (set-index:Int) -> False :
    if add(added-completed-parses, set-index) :
      ;Gather set of existing completed items.
      val completion-set = HashSet<EItemCore>()
      for item in items(setlist, setlist[set-index]) do :
        if num-parsed(item) == 0 :
          add(completion-set, core(item))
      ;Expand all completed items with completion roots.
      ;Add their production ranges if they did not exist in the
      ;set before.
      for item in items(setlist, setlist[set-index]) do :
        if num-parsed(item) == 0 and completion-root(item) is-not False :
          within x = expand-completion-item(item) :
            if add(completion-set, core(x)) :
              add-production-range(set-index, x)  
  ;Given the completed item with completion root,
  ;Return the entire chain of expanding the items not including the
  ;final root.
  defn expand-completion-item (return:EItem -> ?, item:EItem) :
    val root-core = core(item)
    let loop (x:EItem = completion-root(item) as EItem) :
      if core(x) != root-core :
        return(x)
        val x* = first-item(setlist, parent(x), production(grammar,x))
        loop(dec-num-parsed(x* as EItem, false))

  ;Given the ParsedRange 'range', return all of the subparses of production
  ;at index 'index' starting from 'start-position'. 
  defn child-ranges (range:ParsedRange, index:Int, start-position:Int) -> Seqable<ParsedRange> :
    create-completion-production-parses(position-to-set-index(start-position))
    val token = tokens!(grammar[rule(range)])[index]
    val production = name(token as GProduction)
    val candidates = prod-parses[ProdPos(production, start-position)]
;    println("Candidates:")
;    within indented() :
;      do(println, candidates)
    for r in candidates filter :
;      println("Filter using %_" % [PartialRule(rule(range), index + 1, end(r), end(range))])
      partial-rules[PartialRule(rule(range), index + 1, end(r), end(range))]

  ;Create ParseForest
  init-partial-rules()
  init-prod-parses()
;  println("Prod Table:")
;  within indented() :
;    do(println, prod-parses)
;  println("Partial Rules:")
;  within indented() :
;    do(println, partial-rules)
  new ParseForest :
    defmethod get (this, r:ParsedRange, index:Int, position:Int) :
      child-ranges(r, index, position)
    defmethod start (this) :
      ParsedRange(0, 0, length(setlist) - 1)

;============================================================
;================ Construct Parse Forest ====================
;============================================================

public deftype ParseForest
public defmulti get (f:ParseForest, r:ParsedRange, index:Int, position:Int) -> Seqable<ParsedRange>
public defmulti start (f:ParseForest) -> ParsedRange

defstruct RulePos <: Hashable&Equalable :
  rule: Int
  num-parsed: Int
  rule-start: Int
  position: Int
with:
  printer => true

defstruct ProdPos <: Hashable&Equalable :
  production: Symbol
  position: Int
with:
  printer => true

defstruct EItemCore <: Hashable&Equalable :
  rule: Int
  num-parsed: Int
  parent: Int

public defn core (item:EItem) :
  EItemCore(rule(item), num-parsed(item), parent(item))

defn parts (k:EItemCore) : [rule(k), num-parsed(k), parent(k)]
defmethod equal? (a:EItemCore, b:EItemCore) : parts(a) == parts(b)
defmethod hash (k:EItemCore) : hash(parts(k))

val hash-timer = MillisecondTimer("Hash RulePos")
defn parts (k:RulePos) : [rule(k), num-parsed(k), rule-start(k), position(k)]
defmethod equal? (a:RulePos, b:RulePos) : parts(a) == parts(b)
defmethod hash (k:RulePos) :
  start(hash-timer)
  val result = hash(parts(k))
  stop(hash-timer)
  result

defn parts (k:ProdPos) : [production(k), position(k)]
defmethod equal? (a:ProdPos, b:ProdPos) : parts(a) == parts(b)
defmethod hash (k:ProdPos) : hash(parts(k))

public defn ParseForest (grammar:Grammar, setlist:ESetList) :
  ;Construct tables
  val rule-positions = HashSet<RulePos>()
  defn fill-rule-positions () :
    for eset in sets(setlist) do :
      for item in items(setlist,eset) do :
        add(rule-positions, RulePos(rule(item), num-parsed(item), parent(item), index(eset)))
  println(hash-timer)      

  ;Compute right recursion chains
  val completion-chains = HashTable<EItemCore, List<EItem>>()
  val completion-chain-productions-table = HashTable<EItemCore,List<Symbol>>()
  defn completion-parent? (item:EItem) -> Maybe<EItem> :
    fatal("Illegal argument.") when upcoming(grammar,item) is-not False
    val parent = first-item(setlist, parent(item), production(grammar,item)) as EItem
    val root = completion-root(parent) as EItem
    if core(parent) == core(root) : None()
    else : One(inc-num-parsed(parent, false))
    
  defn completion-chain (item:EItem) :
    set?(completion-chains, core(item), fn () :
      val p = completion-parent?(item)
      val rest = List() when empty?(p) else completion-chain(value!(p))
      cons(item, rest))

  defn completion-chain-productions (item:EItem) :
    set?(completion-chain-productions-table, core(item), fn () :
      val p = completion-parent?(item)
      val rest = List() when empty?(p) else completion-chain-productions(value!(p))
      val prod = production(grammar,item)
      rest when contains?(rest,prod) else cons(prod,rest))    

  ;Collect completion chains
  val pending-completion-chains = Vector<List<EItem>>()
  val pending-completions = HashTable<ProdPos,Int>()
  defn add-pending-completion-chain (set-index:Int, root:EItem) :
    val chain = completion-chain(root)
    val chain-index = length(pending-completion-chains)
    add(pending-completion-chains, chain)    
    for prod in completion-chain-productions(root) do :
      val prodpos = ProdPos(prod, set-index)
      pending-completions[prodpos] = chain-index
  defn pending-chains (return:EItem -> ?, prodpos:ProdPos) -> False :
    val index = get?(pending-completions, prodpos)
    match(index:Int) : 
      if not empty?(pending-completion-chains[index]) :
        within with-timer("Compute pending completion chain") :
          do(return, pending-completion-chains[index])
      pending-completion-chains[index] = List()
      remove(pending-completions, prodpos)
      false
  defn collect-pending-completion-chains () :
    for eset in sets(setlist) do :
      for item in items(setlist, eset) do :
        if upcoming(grammar,item) is False :
          val root = completion-root(item)
          match(root:EItem) :
            println("Add completion chain for %_ with root %_" % [format(grammar,item), format(grammar,root)])
            add-pending-completion-chain(index(eset), root)

  ;Construct production tables
  val production-ranges = HashTable<ProdPos, List<ParsedRange>>(List())
  defn add-production-range (set-index:Int, item:EItem) :
    val prodpos = ProdPos(production(grammar,item), set-index)
    val range = ParsedRange(rule(item), parent(item), set-index)
    add(production-ranges, prodpos, range)
  defn fill-production-table () :
    for eset in sets(setlist) do :
      for item in items(setlist, eset) do :
        if upcoming(grammar,item) is False :
          add-production-range(index(eset), item)
  defn get-production-ranges (prodpos:ProdPos) :
    within item = pending-chains(prodpos) :
      println("Fill in right-recursion rule: %_ => %_" % [position(prodpos), format(grammar,item)])
      add-production-range(position(prodpos), item)
    production-ranges[prodpos]

  ;Retrieve child ranges
  val child-range-timer = MillisecondTimer("Child Range Timer")
  defn child-ranges (range:ParsedRange, index:Int, end-position:Int) :
    start(child-range-timer)
    val token = tokens!(grammar[rule(range)])[index]
    val production = name(token as GProduction)
    val result = to-tuple $ for child in get-production-ranges(ProdPos(production, end-position)) filter :
      rule-positions[RulePos(rule(range), index, start(range), start(child))]
    stop(child-range-timer)
    println(child-range-timer)
    result

  ;Fill tables
  within with-timer("fill rule positions") :
    fill-rule-positions()
  within with-timer("collect pending completion chains") :
    collect-pending-completion-chains()
  within with-timer("fill production table") :
    fill-production-table()

  ;defn test-children (range:ParsedRange, index:Int, end-position:Int) :
  ;  println("Children of %_ (index %_) (ending at %_):" % [format(grammar,range), index, end-position])
  ;  within indented() :
  ;    for child in child-ranges(range, index, end-position) do :
  ;      println(format(grammar,child))
  ;
  ;;TEST
  ;let :
  ;  val end = length(setlist) - 1
  ;  test-children(ParsedRange(0, 0, end), 3, end)
  ;  test-children(ParsedRange(1, 3, 20), 2, 20)
  ;  test-children(ParsedRange(1, 3, 20), 1, 5)
  ;  test-children(ParsedRange(1, 3, 20), 0, 4)
  ;  test-children(ParsedRange(2, 5, 20), 2, 20)
  ;  test-children(ParsedRange(2, 5, 20), 1, 7)
  ;  test-children(ParsedRange(2, 5, 20), 0, 6)
          
  new ParseForest :
    defmethod get (this, range:ParsedRange, index:Int, end-position:Int) :
      child-ranges(range, index, end-position)
    defmethod start (this) :
      ParsedRange(0, 0, length(setlist) - 1)      

public defn with-timer<?T> (f:() -> ?T, name:String) :
  val timer = MillisecondTimer(name)
  start(timer)
  val result = f()
  stop(timer)
  println(timer)
  result

;============================================================
;================ Selecting the Parse Tree ==================
;============================================================

public defn new-select-tree (grammar:Grammar, forest:ParseForest) -> ParseNode :
  val node-table = HashTable<ParsedRange,ParseNode>()

  defn select (range:ParsedRange) -> ParseNode :
    set?(node-table, range, fn () :
      val grule = grammar[rule(range)] as GMatcherRule|GTokenRule
      val children = Vector<ParseNode|False>()
      val num-tokens = length(tokens(grule))
      let loop (index:Int = 0, position:Int = start(range)) :
        if index < num-tokens :
          match(tokens(grule)[index]) :
            (t:GTerminal) :
              add(children, false)
              loop(index + 1, position + 1)
            (t:GProduction) :
              val child-ranges = to-tuple $ forest[range, index, position]
              ;println("Lookup %_ at index %_, position %_" % [format(grammar,range), index, position])
              ;for r in child-ranges do :
              ;  println("  %_" % [format(grammar,r)])
              val child-range = minimum(child-ranges, {compare-specificity-2(grammar, rule(range), _, _) < 0})
              val child = select(child-range)
              add(children, child)
              loop(index + 1, end(/range(child)))
      ParseNode(range, to-tuple(children)))

  ;Launch!
  select(start(forest))

;Return -1 if a should take priority over b during a left-to-right disambiguation sweep of the parse forest.
defn compare-specificity-2 (grammar:Grammar, parent-rule-index:Int, a:ParsedRange, b:ParsedRange) -> Int :
  val parent-rule = grammar[parent-rule-index] as GMatcherRule|GTokenRule
  val rule-a = grammar[rule(a)] as GMatcherRule|GTokenRule
  val rule-b = grammar[rule(b)] as GMatcherRule|GTokenRule
  defn compare-associativity () :
    switch(associativity(parent-rule)) :
      LeftAssociative : compare(length(b), length(a))
      RightAssociative : compare(length(a), length(b))
  defn compare-priority () :
    compare(priority(rule-b), priority(rule-a))
  defn compare-order () :
    compare(rule(a), rule(b))
  val c1 = compare-associativity()
  if c1 == 0 :
    val c2 = compare-priority()
    if c2 == 0 : compare-order()
    else : c2
  else : c1  
  
;============================================================
;================ Selecting the Parse Tree ==================
;============================================================

public defn select-tree (grammar:Grammar, forest:ParseForest) -> ParseNode :
  val node-table = HashTable<ParsedRange,ParseNode>()

  defn select (range:ParsedRange) -> ParseNode :
    set?(node-table, range, fn () :
      val grule = grammar[rule(range)] as GMatcherRule|GTokenRule
      val children = Vector<ParseNode|False>()
      val num-tokens = length(tokens(grule))
      let loop (index:Int = num-tokens - 1, position:Int = end(range)) :
        if index >= 0 :
          match(tokens(grule)[index]) :
            (t:GTerminal) :
              add(children, false)
              loop(index - 1, position - 1)
            (t:GProduction) :
              val child-ranges = forest[range, index, position]
              val child-range = minimum(child-ranges, {compare-specificity(grammar, rule(range), _, _) < 0})
              val child = select(child-range)
              add(children, child)
              loop(index - 1, start(/range(child)))
      reverse!(children)        
      ParseNode(range, to-tuple(children)))

  ;Launch!
  select(start(forest))

;Return -1 if a should take priority over b during a right-to-left disambiguation sweep of the parse forest.
defn compare-specificity (grammar:Grammar, parent-rule-index:Int, a:ParsedRange, b:ParsedRange) :
  val parent-rule = grammar[parent-rule-index] as GMatcherRule|GTokenRule
  val rule-a = grammar[rule(a)] as GMatcherRule|GTokenRule
  val rule-b = grammar[rule(b)] as GMatcherRule|GTokenRule
  defn compare-associativity () :
    switch(associativity(parent-rule)) :
      LeftAssociative : compare(length(a), length(b))
      RightAssociative : compare(length(b), length(a))
  defn compare-priority () :
    compare(priority(rule-b), priority(rule-a))
  defn compare-order () :
    compare(rule(a), rule(b))
  val c1 = compare-associativity()
  if c1 == 0 :
    val c2 = compare-priority()
    if c2 == 0 : compare-order()
    else : c2
  else : c1  

;============================================================
;================= Evaluate the Parse Tree ==================
;============================================================

defn evaluate-parse-tree (parse-result:ParseResult) :
  ;Pull out fields
  val grammar = grammar(parse-result)
  val inputlist = inputlist(parse-result)
  val infolist = infolist(parse-result)
  
  ;Accumulated errors                        
  val errors = Vector<Exception>()

  ;Attempt evaluation of a given ParseNode
  defn evaluate (tree:ParseNode) -> Maybe :
    ;Retrieve rule
    val rule = grammar[rule(range(tree))] as GMatcherRule|GTokenRule
    defn evaluate-child (i:Int) -> Maybe :
      match(children(tree)[i]) :
        (child:ParseNode) :
          evaluate(child)
        (f:False) :
          val token = tokens(rule)[i]
          val input = inputlist[start(range(tree)) + i]
          match(token, input) :
            (token:GListRest, input:SExpForm|SExpListEnd) : One(list(input))
            (token:GListEnd, input:SExpListEnd) : One(false)
            (token, input:SExpForm) : One(form(input))
            
    ;Lazy evaluation
    defn lazy-evaluation () :
      val result = new ParsedResult :
        defmethod get (this, i:Int) :
          val v = evaluate-child(i)
          throw(ChildNotEvaluated()) when empty?(v)
          value!(v)
        defmethod info (this) : infolist[start(range(tree))]
        defmethod form (this) : list(inputlist[start(range(tree))] as SExpForm|SExpListEnd)
      try :
        One(action(rule)(result))
      catch (e:ChildNotEvaluated) :
        None()
      catch (e:Exception) :
        add(errors, e)
        None()
        
    ;Eager evaluation
    defn eager-evaluation () :
      val results = to-tuple $
        seq(evaluate-child, 0 to length(tokens(rule)))
      if none?(empty?, results) :
        val result = new ParsedResult :
          defmethod get (this, i:Int) : value!(results[i])
          defmethod info (this) : infolist[start(range(tree))]
          defmethod form (this) : list(inputlist[start(range(tree))] as SExpForm|SExpListEnd)
        try :
          One(action(rule)(result))
        catch (e:Exception) :
          add(errors, e)
          None()
      else :
        None()

    ;Launch!
    if lazy-action?(rule) : lazy-evaluation()
    else : eager-evaluation()

  ;Launch!
  val v = evaluate(node(parse-result))
  if empty?(v) : throw(ParsingErrors(to-tuple(errors)))
  else : value!(v)

defstruct ChildNotEvaluated <: Exception

;============================================================
;==================== Overall Launcher ======================
;============================================================

defn parse (grammar:Grammar, input:List) :
  match(parse-result(grammar, input)) :
    (r:ParseResult) : evaluate-parse-tree(r)
    (e:ParsingErrors) : throw(e)  

;============================================================
;======================= Test Case ==========================
;============================================================

defn test-parse (rules:Tuple<GRule>, input:List) :
  val g = Grammar(rules)
  match(parse-result(g, input)) :
    (n:ParseResult) : println(format(g,node(n)))
    (e:ParsingErrors) : println(e)

defn test-parse-action (rules:Tuple<GRule>, input:List) :
  println(parse(Grammar(rules), input))

defn example-grammar () :
  val E = GProduction(`E)
  val N = GKeyword(`N)
  val PLUS = GKeyword(`+)
  val TIMES = GKeyword(`x)
  val LPAREN = GKeyword(`L)
  val RPAREN = GKeyword(`R)
  [GTokenRule(`S, [GListStart(), E, GListEnd()])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])]

deftest print-grammar :
  val g = example-grammar()
  do(println, g)

deftest parse :
  test-parse(example-grammar(), `(N x N x L N + N R x N x N + N x N x N))

defn example-grammar-2 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val B = GKeyword(`B)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [E E X])
   GTokenRule(`S, [F F Y])
   GTokenRule(`E, [A A B])
   GTokenRule(`F, [A A B])]

deftest parse-2 :
  val g = example-grammar-2()
  test-parse(g, `(A A B A A B Y))

defn example-grammar-3 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [E F X])
   GTokenRule(`S, [F E X])
   GTokenRule(`S, [F F F Y])
   GTokenRule(`E, [A A])
   GTokenRule(`F, [A])]

deftest parse-3 :
  val g = example-grammar-3()
  test-parse(g, `(A A A X))

defn example-grammar-10 () :
  val S = GProduction(`S)
  val W = GProduction(`W)
  val X = GProduction(`X)
  val Y = GProduction(`Y)
  val Z = GProduction(`Z)
  val A = GKeyword(`A)
  val B = GKeyword(`B)
  val C = GKeyword(`C)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [X Y Z])
   GTokenRule(`S, [W X Y])
   GTokenRule(`W, [A])
   GTokenRule(`X, [A A])
   GTokenRule(`Y, [B B])
   GTokenRule(`Z, [C C])]

deftest parse-10 :
  val g = example-grammar-10()
  test-parse(g, `(Y A A A B B A X))

defn example-grammar-4 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [E E X])
   GTokenRule(`E, [A])
   GTokenRule(`E, [A A])]

deftest parse-4 :
  val g = example-grammar-4()
  test-parse(g, `(A A A A X))

defn example-grammar-5 () :
  #for E in [ES, E, IF-E, SCLAUSES, SCLAUSE, ECLAUSE] :
    val E = GProduction(`E)
  #for (X in [PLUS, TIMES, LPAREN, RPAREN, N, EQ, LET, IN, IF, COLON, ELSE, SWITCH],
        x in [+, x, L, R, N, =, let, in, if, :, else, switch]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])
   GTokenRule(`E, [E EQ E])
   GTokenRule(`E, [LET E EQ E IN E])
   GTokenRule(`E, [IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE COLON E])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES ECLAUSE RPAREN])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES RPAREN])
   GTokenRule(`SCLAUSES, [SCLAUSE SCLAUSES])
   GTokenRule(`SCLAUSES, [])
   GTokenRule(`SCLAUSE, [E COLON E])
   GTokenRule(`ECLAUSE, [ELSE COLON E])]

deftest grammar-calc :
  Grammar(example-grammar-5())

deftest parse-5 :
  val g = example-grammar-5()
  test-parse(g, `(
    switch L
      N : N x N
      N x N : N
      N + N : N + N 
      else : N x N
    R))

deftest parse-5-2 :
  val g = example-grammar-5()
  test-parse(g, `(N + N x N + N))

deftest parse-6 :
  test-parse(example-grammar-5(), reader/read-file("test.txt"))

defn example-grammar-6 () :
  #for E in [ES, E] :
    val E = GProduction(`E)
  #for (X in [A B C],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() ES GListEnd()])
   GTokenRule(`ES, [E, ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [A])
   GTokenRule(`E, [B C])]

deftest parse-7 :
  val g = example-grammar-6()
  test-parse(g, `(a a b c a a b c b c a a a b c a a a a a a a a a a a a a a))

defn example-grammar-8 () :
  #for E in [AS, BS] :
    val E = GProduction(`E)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() AS GListEnd()])
   GTokenRule(`AS, [A, BS])
   GTokenRule(`BS, [A, AS])
   GTokenRule(`BS, [A])]

deftest parse-simple-mutual-right-recursive :
  val g = example-grammar-8()
  test-parse(g, `(a a a a a a a a a a a a a a a a a a a a a a a a a a))

defn example-grammar-9 () :
  #for E in [AS, BS] :
    val E = GProduction(`E)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() AS GListEnd()])
   GTokenRule(`AS, [BS, A])
   GTokenRule(`BS, [AS, A])
   GTokenRule(`BS, [A])]

deftest parse-simple-mutual-left-recursive :
  val g = example-grammar-9()
  test-parse(g, `(a a a a a a a a a a a a a a a a a a a a a a a a a a))
  
deftest parse-mutually-right-recursive :
  #for E in [AS BS CS A B C X] :
    val E = GProduction(`E)
  #for (X in [x a b c],
        x in [x a b c]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [GListStart() X X X AS GListEnd()])
    GTokenRule(`AS, [A, X, BS])
    GTokenRule(`BS, [B, X, CS])
    GTokenRule(`CS, [X])
    GTokenRule(`CS, [C, X, AS])
    GTokenRule(`X, [x])
    GTokenRule(`A, [a])
    GTokenRule(`B, [b])
    GTokenRule(`C, [c])]
  test-parse(rules, `(x x x a x b x c x a x b x c x a x b x x))

deftest right-recursive-priority :
  #for E in [E A BS] :
    val E = GProduction(`E)
  #for (X in [a],
        x in [a]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [GListStart() E GListEnd()])
    GTokenRule(`E, [A BS])
    GTokenRule(`E, [A A A A], 200)
    GTokenRule(`BS, [A BS])
    GTokenRule(`BS, [])
    GTokenRule(`A, [a])]
  test-parse(rules, `(a a a a))

defn example-null-grammar () :
  #for X in [S Ap E] :
    val X = GProduction(`X)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [Ap Ap Ap Ap])
   GTokenRule(`Ap, [A])
   GTokenRule(`Ap, [E])
   GTokenRule(`E, [])]

deftest parse-null :
  val g = example-null-grammar()
  test-parse(g, `(a a a))

defn example-tricky-null-grammar () :
  #for E in [S, A, B] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [w A d])
   GTokenRule(`S, [A d])
   GTokenRule(`S, [w B A A A d])
   GTokenRule(`A, [x])
   GTokenRule(`A, [])
   GTokenRule(`B, [x])]

deftest parse-tricky-null :
  val g = example-tricky-null-grammar()
  test-parse(g, `(w x x d))

defn example-tricky-null-grammar-2 () :
  #for E in [B S A] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() B GListEnd()])
   GTokenRule(`B, [S])
   GTokenRule(`B, [A])
   GTokenRule(`S, [w x A A A A d], 100, LeftAssociative)
   GTokenRule(`A, [w x])
   GTokenRule(`A, [])]

deftest parse-tricky-null-2 :
  val g = example-tricky-null-grammar-2()
  test-parse(g, `(w x w x w x w x d))

defn list-grammar () :
  #for E in [S, A, B, C, D, L, R, CD, CDs] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [A B CDs L CDs R CDs])
   GTokenRule(`S, [A B C])
   GTokenRule(`CDs, [CD, CDs])
   GTokenRule(`CDs, [])
   GTokenRule(`CD, [L C D R])
   GTokenRule(`A, [a])
   GTokenRule(`B, [b])
   GTokenRule(`C, [c])
   GTokenRule(`D, [d])
   GTokenRule(`L, [GListStart()])
   GTokenRule(`R, [GListEnd()])]

deftest parse-list :
  val g = list-grammar()
  test-parse(g, `(a b (c d) (c d) ((c d) (c d) (c d)) (c d)))

defn any-vs-list-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [done],
        x in [done]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [GAny() done])
   GTokenRule(`S, [GListStart() done GListEnd() done])]

deftest parse-any-vs-list :
  val g = any-vs-list-grammar()
  test-parse(g, `((done) done))

defn any-as-list-grammar () :
  #for E in [S A As Xs] :
    val E = GProduction(`E)
;  #for (X in [],
;        x in [a b c d]) :
;    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [Xs Xs])
   GTokenRule(`S, [A A])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [GListStart(true) As GListEnd()])
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`Xs, [GListStart() GKeyword(`x) GListEnd()])]

deftest parse-any-as-list :
  val g = any-as-list-grammar()
  test-parse(g, `((x) (x y z)))

defn list-recovery-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [a GListStart() b GListEnd() c])]

deftest parse-list-recovery :
  val g = list-recovery-grammar()
  test-parse(g, `(a b c))

defn rest-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [GListStart() a b c GListEnd()])
   GTokenRule(`S, [GListStart() a b GListRest() GListEnd()])]

deftest parse-rest :
  val g = rest-grammar()
  test-parse(g, `((a b d e f)))

defn full-any-grammar () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [LP a b LP c d R RP RP])   
   GTokenRule(`S, [LP a b LP c RP RP])   
   
   GTokenRule(`S, [A])
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]  

deftest parse-full-any-grammar :
  val g = full-any-grammar()
  test-parse(g, `((a b (c d))))

defn full-any-grammar-2 () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
  [GTokenRule(`Start, [GListStart() S GListEnd()])
   GTokenRule(`S, [A a b c]) 
   GTokenRule(`S, [R])   
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]  

deftest parse-full-any-grammar-2 :
  val g = full-any-grammar-2()
  test-parse(g, `((x y z) a b c))

defn amb-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [LP S RP])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])]    

deftest parse-amb-grammar :
  val g = amb-grammar()
  test-parse(g, `(red red dog dog red dog dog dog))

defn amb-grammar-2 () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [LP S RP])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])
   GTokenRule(`E, [red dog])]    

deftest parse-amb-grammar-2 :
  val g = amb-grammar-2()
  test-parse(g, `(red dog dog dog dog red red dog dog red red dog dog dog red dog dog red dog dog))

defn if-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [IF THEN ELSE N],
        x in [if then else N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [LP S RP])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [LP E RP])   
   GTokenRule(`E, [IF E THEN E], 100, LeftAssociative)      
   GTokenRule(`E, [IF E THEN E ELSE E], 100, LeftAssociative)
   GTokenRule(`E, [N])]    

deftest parse-if-grammar :
  val g = if-grammar()
  test-parse(g, `(if N then if N then N else N))

defn matcher-grammar () :
  #for E in [ES E Id BId RId] :
    val E = GProduction(`E)
  #for (X in [VAR EQ N DOT],
        x in [var = N .]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn prefix-symbol? (form, prefix:String) :
    match(unwrap-token(form)) :
      (f:Symbol) : prefix?(name(f), prefix)
      (f) : false
  [GTokenRule(`Start, [LP ES RP])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [VAR Id EQ E])
   GTokenRule(`E, [N])
   GTokenRule(`Id, [BId DOT RId])
   GMatcherRule(`BId, [GAny()], prefix-symbol?{_, "B"})
   GMatcherRule(`RId, [GAny()], prefix-symbol?{_, "R"})]

deftest parse-matcher-grammar :
  val g = matcher-grammar()
  test-parse(g, `(var B10.R18 = N N))

deftest parse-matcher-grammar-error :
  val g = matcher-grammar()
  test-parse(g, `("hello world"))

defn core-form-grammar () :
  #for E in [ES E A R] :
    val E = GProduction(`E)
  #for (X in [CORE],
        x in [$core]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn core-form? (form) :
    match(unwrap-token(form)) :
      (f:List) : not empty?(f) and unwrap-token(head(f)) == `$core
      (f) : false
      
  [GTokenRule(`Start, [LP ES RP])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [CORE])
   GTokenRule(`E, [LP ES RP])   
   GMatcherRule(`E, [GAny(Atomic)], core-form?)

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP R RP])
   GTokenRule(`R, [GAny() R])
   GTokenRule(`R, [LP R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]

deftest parse-core-form-grammar :
  val g = core-form-grammar()
  test-parse(g, `($core ($core a b c d) $core))

defn exp-grammar () :
  #for E in [ES E ID A R] :
    val E = GProduction(`E)
  #for (X in [VAR VAL FOR LET IN EQ COLON PLUS TIMES N DO],
        x in [var val for let in = : + * N @do]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
      
  [GTokenRule(`Start, [LP ES RP], fn (result) :
     result[0])
  
   GTokenRule(`keywords, [VAR])     
   GTokenRule(`keywords, [VAL])     
   GTokenRule(`keywords, [FOR])     
   GTokenRule(`keywords, [LET])     
   GTokenRule(`keywords, [IN])
   GTokenRule(`keywords, [EQ])
   GTokenRule(`keywords, [COLON])
   GTokenRule(`keywords, [DO])

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])

   GTokenRule(`ID, [A], fn (result) :
     result[0])
   ;GNegationRule(`ID, GProduction(`keywords))
   
   GTokenRule(`ES, [E ES], 100, LeftAssociative, fn (result) :
     cons(result[0], result[1]))
   GTokenRule(`ES, [], fn (result) :
     List())
   
   GTokenRule(`E, [VAR ID EQ E], fn (result) :
     qquote($var ~(result[1]) ~(result[3])))
   GTokenRule(`E, [VAL ID EQ E], fn (result) :
     qquote($val ~(result[1]) ~(result[3])))
   GTokenRule(`E, [FOR ID IN E COLON E], fn (result) :
       qquote($for ~(result[1]) ~(result[3]) ~(result[5])))
   GTokenRule(`E, [LET ID EQ E COLON E], fn (result) :
     qquote($let ~(result[1]) ~(result[3]) ~(result[5])))     
   GTokenRule(`E, [E LP DO ES RP], 70, LeftAssociative, fn (result) :
     qquote($call ~(result[0]) ~@(result[3])))
   GTokenRule(`E, [LP E RP], fn (result) :
     result[1])
   GTokenRule(`E, [LP ES RP], fn (result) :
     qquote($begin ~@(result[1])))
   GTokenRule(`E, [N], fn (result) :
     result[0])
   GTokenRule(`E, [GIntToken()], fn (result) :
     result[0])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative, fn (result) :
     qquote($plus ~(result[0]), ~(result[2])))
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative, fn (result) :
     qquote($times ~(result[0]), ~(result[2])))]

let :;deftest parse-exp-grammar :
  test-parse(exp-grammar(), reader/read-file("exp-test.txt"))

deftest action-exp-grammar :
  test-parse-action(exp-grammar(), reader/read-file("exp-test.txt"))

defn rest-priority-grammar () :
  #for E in [ES E F A R] :
    val E = GProduction(`E)
  #for (X in [PLUS N],
        x in [+ N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
      
  [GTokenRule(`Start, [LP F RP])

   GTokenRule(`F, [E E], 100, LeftAssociative)
   
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   ;GTokenRule(`E, [N R], true)
   GTokenRule(`E, [N])

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]

deftest parse-rest-priority-grammar :
  val g = rest-priority-grammar()
  test-parse(g, `(N + N + N N + N))

deftest parse-blowup-grammar :
  #for E in [E] :
    val E = GProduction(`E)
  #for (X in [N],
        x in [N]) :
    val X = GKeyword(`x)
  val grammar = [
    GTokenRule(`Start, [GListStart() E GListEnd()])
    GTokenRule(`E, [E E E])
    GTokenRule(`E, [N])]  

;  test-parse(grammar, `(N N N N N N N N N N N N N N N N N
;                        N N N N N N N N N N N N N N N N N N))

  test-parse(grammar, `(N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N N))