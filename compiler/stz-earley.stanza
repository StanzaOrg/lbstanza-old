#use-added-syntax(tests)
defpackage stz/earley :
  import core
  import collections
  import stz/utils

;============================================================
;====================== Definitions =========================
;============================================================

deftype GRule
defmulti name (r:GRule) -> Symbol
defmulti sub-name (r:GRule, name:Symbol) -> GRule

defstruct GNegationRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  token: GToken

defstruct GMatcherRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  tokens: Tuple<GToken>
  matcher: ? -> True|False
  priority: Int with: (default => 100)
  action: ParsedResult -> ? with: (default => default-action)
  lazy-action?: True|False with: (default => false)

defstruct GTokenRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  tokens: Tuple<GToken>
  priority: Int with: (default => 100)
  associativity: Associativity with: (default => RightAssociative)
  action: ParsedResult -> ? with: (default => default-action)
  lazy-action?: True|False with: (default => false)

defn GMatcherRule (name:Symbol, tokens:Tuple<GToken>, matcher:? -> True|False,
                   action:ParsedResult -> ?, lazy-action?:True|False) :
  GMatcherRule(name, tokens, matcher, 100, action, lazy-action?)

defn GMatcherRule (name:Symbol, tokens:Tuple<GToken>, matcher:? -> True|False,
                   action:ParsedResult -> ?) :
  GMatcherRule(name, tokens, matcher, action, false)

defn GTokenRule (name:Symbol,
                 tokens:Tuple<GToken>,
                 action:ParsedResult -> ?,
                 lazy-action?:True|False) :
  GTokenRule(name, tokens, 100, RightAssociative, action, lazy-action?)

defn GTokenRule (name:Symbol,
                 tokens:Tuple<GToken>,
                 action:ParsedResult -> ?) :
  GTokenRule(name, tokens, action, false)

defenum Associativity :
  LeftAssociative
  RightAssociative

deftype GToken <: Equalable & Hashable & Comparable<GToken>
defstruct GProduction <: GToken :
  name: Symbol
deftype GTerminal <: GToken
defstruct GKeyword <: GTerminal :
  item: Symbol
defstruct GCharToken <: GTerminal
defstruct GByteToken <: GTerminal
defstruct GIntToken <: GTerminal
defstruct GLongToken <: GTerminal
defstruct GFloatToken <: GTerminal
defstruct GDoubleToken <: GTerminal
defstruct GStringToken <: GTerminal
defstruct GSymbolToken <: GTerminal
defstruct GTrueToken <: GTerminal
defstruct GFalseToken <: GTerminal
  
defstruct GListStart <: GTerminal :
  reluctant?: True|False with: (default => false)
defstruct GListEnd <: GTerminal
defstruct GAny <: GTerminal :
  type: AnyType with: (default => Standard)
defstruct GListRest <: GTerminal

defenum AnyType :
  Atomic
  Reluctant
  Standard

defstruct EItem :
  rule:Int
  num-parsed:Int
  parent:Int
  passed-guard?:True|False with: (default => true, updater => sub-passed-guard?)
  completion-root:EItem|False with: (init => false, updater => sub-completion-root)  

defstruct ParseNode :
  rule: Int
  start: Int
  end: Int
  children: Tuple<ParseNode|False>

deftype ParsedResult
defmulti get (r:ParsedResult, i:Int) -> ?
defmulti info (r:ParsedResult) -> FileInfo|False
defmulti form (r:ParsedResult) -> List
defn default-action (r:ParsedResult) : false

;============================================================
;======================== Equalable =========================
;============================================================

defmethod equal? (a:GToken, b:GToken) :
  match(a, b) :
    (a:GKeyword, b:GKeyword) : item(a) == item(b)
    (a:GCharToken, b:GCharToken) : true
    (a:GByteToken, b:GByteToken) : true
    (a:GIntToken, b:GIntToken) : true
    (a:GLongToken, b:GLongToken) : true
    (a:GFloatToken, b:GFloatToken) : true
    (a:GDoubleToken, b:GDoubleToken) : true
    (a:GStringToken, b:GStringToken) : true
    (a:GSymbolToken, b:GSymbolToken) : true
    (a:GTrueToken, b:GTrueToken) : true
    (a:GFalseToken, b:GFalseToken) : true
    (a:GProduction, b:GProduction) : name(a) == name(b)
    (a:GListStart, b:GListStart) : true
    (a:GListEnd, b:GListEnd) : true
    (a:GAny, b:GAny) : type(a) == type(b)
    (a:GListRest, b:GListRest) : true
    (a, b) : false

defmethod hash (t:GToken) :
  match(t) :
    (t:GKeyword) : 1 + hash(item(t))
    (t:GProduction) : 2 + hash(name(t))
    (t:GListStart) : 3
    (t:GListEnd) : 4
    (t:GAny) : 5 + hash(to-int(type(t)))
    (t:GListRest) : 6
    (t:GCharToken) : 7
    (t:GByteToken) : 8
    (t:GIntToken) : 9
    (t:GLongToken) : 10
    (t:GFloatToken) : 11
    (t:GDoubleToken) : 12
    (t:GStringToken) : 13
    (t:GSymbolToken) : 14
    (t:GTrueToken) : 15
    (t:GFalseToken) : 16

defmethod compare (a:GToken, b:GToken) :
  defn rank (t:GToken) :
    match(t) :
      (t:GKeyword) : 0
      (t:GProduction) : 1
      (t:GListStart) : 2
      (t:GListEnd) : 3
      (t:GAny) : 4
      (t:GListRest) : 5
      (t:GCharToken) : 6
      (t:GByteToken) : 7
      (t:GIntToken) : 8
      (t:GLongToken) : 9
      (t:GFloatToken) : 10
      (t:GDoubleToken) : 11
      (t:GStringToken) : 12
      (t:GSymbolToken) : 13
      (t:GTrueToken) : 14
      (t:GFalseToken) : 15
  defn compare-token (a:GToken, b:GToken) :
    match(a, b) :
      (a:GProduction, b:GProduction) : compare(name(a), name(b))
      (a:GKeyword, b:GKeyword) : compare(item(a), item(b))
      (a:GAny, b:GAny) : compare(to-int(type(a)), to-int(type(b)))
      (a, b) : 0
  val c = compare(rank(a), rank(b))
  if c == 0 : compare-token(a,b)
  else : c

;============================================================
;======================= Printers ===========================
;============================================================

defmethod print (o:OutputStream, t:GToken) :
  print{o, _} $ match(t) :
    (t:GProduction) : name(t)
    (t:GKeyword) : item(t)
    (t:GCharToken) : "Char"
    (t:GByteToken) : "Byte"
    (t:GIntToken) : "Int"
    (t:GLongToken) : "Long"
    (t:GFloatToken) : "Float"
    (t:GDoubleToken) : "Double"
    (t:GStringToken) : "String"
    (t:GSymbolToken) : "Symbol"
    (t:GTrueToken) : "True"
    (t:GFalseToken) : "False"
    (t:GListStart) : "("
    (t:GListEnd) : ")"
    (t:GAny) : "_"
    (t:GListRest) : "_ ..."

defmethod print (o:OutputStream, r:GRule) :
  print{o, _} $ match(r) :
    (r:GTokenRule) : "%_ = %s" % [name(r), tokens(r)]
    (r:GMatcherRule) : "%_ = custom matcher" % [name(r)]
    (r:GNegationRule) : "%_ != %_" % [name(r), token(r)]

;============================================================
;======================== Utilities =========================
;============================================================

defn add-all<?T> (q:Queue<?T>, xs:Seqable<T>) :
  do(add{q, _}, xs)

defn add<?K,?V> (table:Table<?K,List<?V>>, k:K, v:V) :
  update(table, cons{v, _,}, k)

defn wrap (token, info:FileInfo|False) :
  match(info:FileInfo) : Token(token, info)
  else : token

defn inc-num-parsed (x:EItem) :
  EItem(rule(x), num-parsed(x) + 1, parent(x))

defn upcoming (grammar:Grammar, item:EItem) -> GToken|False :
  val ts = tokens!(grammar[rule(item)])
  val i = num-parsed(item)
  ts[i] when i < length(ts)

defn previous (grammar:Grammar, item:EItem) -> GToken|False :
  val ts = tokens!(grammar[rule(item)])
  val i = num-parsed(item)
  ts[i - 1] when i > 0
  
defn production (grammar:Grammar, item:EItem) -> Symbol :
  name(grammar[rule(item)])

defn tokens! (rule:GRule) :
  tokens(rule as GMatcherRule|GTokenRule)

defn associativity (rule:GMatcherRule) :
  RightAssociative

;============================================================
;==================== Grammar Analysis ======================
;============================================================

deftype Grammar
defmulti get (g:Grammar, i:Int) -> GRule
defmulti nullable? (g:Grammar, production:Symbol) -> True|False
defmulti rules (g:Grammar, production:Symbol, next-input:SExpToken) -> Seqable<Int>
defmulti rules (g:Grammar, production:Symbol) -> Seqable<Int>

defn Grammar (input-rules:Tuple<GRule>) :
  val rules = convert-negation-rules(input-rules)
  val grammar-properties = analyze-grammar-properties(rules)
  val null-prods = nullable-productions(grammar-properties)
  val dispatch-sets = analyze-dispatch-sets(rules, grammar-properties)
  new Grammar :
    defmethod get (this, i:Int) :
      rules[i]
    defmethod nullable? (this, production:Symbol) :
      null-prods[production]
    defmethod rules (this, production:Symbol) :
      all-rules(dispatch-sets)[production]
    defmethod rules (this, production:Symbol, next-input:SExpToken) :
      match(next-input) :
        (input:SExpWildcard) :
          all-rules(dispatch-sets)[production]
        (input:SExpForm) :
          val x = unwrap-token(form(input))
          val obj-rules = match(x) :
            (x:Symbol) : keyword-rules(dispatch-sets)[[production, x]]
            (x) : List()
          val type-rules = match(x) :
            (x:Char) : char-rules(dispatch-sets)[production]
            (x:Byte) : byte-rules(dispatch-sets)[production]
            (x:Int) : int-rules(dispatch-sets)[production]
            (x:Long) : long-rules(dispatch-sets)[production]
            (x:Float) : float-rules(dispatch-sets)[production]
            (x:Double) : double-rules(dispatch-sets)[production]
            (x:String) : string-rules(dispatch-sets)[production]
            (x:True) : true-rules(dispatch-sets)[production]
            (x:False) : false-rules(dispatch-sets)[production]
            (x:Symbol) : symbol-rules(dispatch-sets)[production]
            (x:List) : list-rules(dispatch-sets)[production]
            (x) : List()
          cat-all $ [
            obj-rules,
            type-rules,
            any-rules(dispatch-sets)[production]
            null-rules(dispatch-sets)[production]]              
        (input:SExpListEnd) :
          cat(
            list-end-rules(dispatch-sets)[production]
            null-rules(dispatch-sets)[production])

;------------------------------------------------------------
;------------------ Grammar Properties ----------------------
;------------------------------------------------------------

defstruct GrammarProperties:
  nullable-productions: HashSet<Symbol>
  nullable-rules: IntSet
  first-sets: Tuple<Tuple<GTerminal>>

defn analyze-grammar-properties (grammar:Tuple<GMatcherRule|GTokenRule>) :
  ;Compute parent rules that contain each production.
  val parent-table:HashTable<Symbol,List<Int>> = group-by{key, value, _} $
    for (rule in grammar, rule-index in 0 to false) seq-cat :
      for prod in filter-by<GProduction>(tokens(rule)) seq :
        name(prod) => rule-index

  ;Production worklist algorithm
  defn worklist (f:(Int, GMatcherRule|GTokenRule, () -> False) -> ?) :
    val queue = Queue<Int>()
    add-all(queue, 0 to length(grammar))
    while not empty?(queue) :
      val rule-index = pop(queue)
      val rule = grammar[rule-index]
      var progress?:True|False = false
      defn progress () : progress? = true
      f(rule-index, rule, progress)
      if progress? :
        add-all(queue, parent-table[name(rule)])

  ;Compute nullable productions and rules
  val null-prods = HashSet<Symbol>()
  val null-rules = IntSet()
  defn nullable? (t:GToken) :
    match(t:GProduction) :
      null-prods[name(t)]
  defn nullable? (rule:GMatcherRule|GTokenRule) :
    all?(nullable?, tokens(rule))
  within (rule-index, rule, progress) = worklist() :
    if nullable?(rule) :
      add(null-rules, rule-index)
      progress() when add(null-prods, name(rule))

  ;Compute firstsets
  val first-set-entries = HashSet<KeyValue<Symbol,GTerminal>>()
  val first-set-table = HashTable<Symbol,List<GTerminal>>(List())  
  defn first-set (t:GToken) :
    match(t) :
      (t:GTerminal) : [t]
      (t:GProduction) : first-set-table[name(t)]
  defn first-set (rule:GMatcherRule|GTokenRule) :
    generate<GTerminal> :
      let loop (i:Int = 0) :
        if i < length(tokens(rule)) :
          val t = tokens(rule)[i]
          do(yield, first-set(t))
          loop(i + 1) when nullable?(t)
  within (rule-index, rule, progress) = worklist() :
    for t in first-set(rule) do :
      if add(first-set-entries, name(rule) => t) :
        add(first-set-table, name(rule), t)
        progress()
  val first-sets = for rule in grammar map :
    to-tuple $ unique $ first-set(rule)

  ;Return all properties
  GrammarProperties(
    null-prods,
    null-rules,
    first-sets)

;------------------------------------------------------------
;------------------ Dispatch Sets ---------------------------
;------------------------------------------------------------

defstruct DispatchSet :
  all-rules:HashTable<Symbol,List<Int>>
  null-rules:HashTable<Symbol,List<Int>>
  any-rules:HashTable<Symbol,List<Int>>
  list-end-rules:HashTable<Symbol,List<Int>>
  char-rules:HashTable<Symbol,List<Int>>
  byte-rules:HashTable<Symbol,List<Int>>
  int-rules:HashTable<Symbol,List<Int>>
  long-rules:HashTable<Symbol,List<Int>>
  float-rules:HashTable<Symbol,List<Int>>
  double-rules:HashTable<Symbol,List<Int>>
  string-rules:HashTable<Symbol,List<Int>>
  true-rules:HashTable<Symbol,List<Int>>
  false-rules:HashTable<Symbol,List<Int>>
  symbol-rules:HashTable<Symbol,List<Int>>
  list-rules:HashTable<Symbol,List<Int>>
  keyword-rules:HashTable<[Symbol,Symbol],List<Int>>

defn analyze-dispatch-sets (grammar:Tuple<GRule>, props:GrammarProperties) :
  ;Create rule sets
  val all-rules = HashTable<Symbol,List<Int>>(List())
  val null-rules = HashTable<Symbol,List<Int>>(List())
  val any-rules = HashTable<Symbol,List<Int>>(List())
  val list-end-rules = HashTable<Symbol,List<Int>>(List())
  val char-rules = HashTable<Symbol,List<Int>>(List())
  val byte-rules = HashTable<Symbol,List<Int>>(List())
  val int-rules = HashTable<Symbol,List<Int>>(List())
  val long-rules = HashTable<Symbol,List<Int>>(List())
  val float-rules = HashTable<Symbol,List<Int>>(List())
  val double-rules = HashTable<Symbol,List<Int>>(List())
  val string-rules = HashTable<Symbol,List<Int>>(List())
  val true-rules = HashTable<Symbol,List<Int>>(List())
  val false-rules = HashTable<Symbol,List<Int>>(List())
  val symbol-rules = HashTable<Symbol,List<Int>>(List())
  val list-rules = HashTable<Symbol,List<Int>>(List())
  val keyword-rules = HashTable<[Symbol,Symbol],List<Int>>(List())

  ;Add to rule sets
  for (rule in grammar, rule-index in 0 to false, fset in first-sets(props)) do :
    defn add-to-set (table:HashTable<Symbol,List<Int>>) :
      add(table, name(rule), rule-index)
    add-to-set(all-rules)
    if nullable-rules(props)[rule-index] :
      add-to-set(null-rules)
    for token in fset do :
      match(token) :
        (token:GAny|GListRest) : add-to-set(any-rules)
        (token:GListEnd) : add-to-set(list-end-rules)
        (token:GCharToken) : add-to-set(char-rules)
        (token:GByteToken) : add-to-set(byte-rules)
        (token:GIntToken) : add-to-set(int-rules)
        (token:GLongToken) : add-to-set(long-rules)
        (token:GFloatToken) : add-to-set(float-rules)
        (token:GDoubleToken) : add-to-set(double-rules)
        (token:GStringToken) : add-to-set(string-rules)
        (token:GTrueToken) : add-to-set(true-rules)
        (token:GFalseToken) : add-to-set(false-rules)
        (token:GSymbolToken) : add-to-set(symbol-rules)
        (token:GListStart) : add-to-set(list-rules)
        (token:GKeyword) : add(keyword-rules, [name(rule), item(token)], rule-index)

  ;Ensure subtraction relationships of sets
  val set-buffer = IntSet()
  defn minus (a:Seqable<Int>, b:Seqable<Int>) :
    add-all(set-buffer, b)
    val result = to-list $ filter({not set-buffer[_]}, a)
    clear(set-buffer)
    result
  defn subtract-map! (atable:HashTable<Symbol,List<Int>>,
                      btables:Collection<HashTable<Symbol,List<Int>>>) :
    for entry in atable map! :
      val prod = key(entry)
      val bset = seq-cat({_[prod]}, btables)
      value(entry) - bset
  defn subtract-map! (atable:HashTable<[Symbol,Symbol],List<Int>>,
                      btables:Collection<HashTable<Symbol,List<Int>>>) :
    for entry in atable map! :
      val [prod, _] = key(entry)
      val bset = seq-cat({_[prod]}, btables)
      value(entry) - bset  
  subtract-map!(keyword-rules, [symbol-rules, any-rules, null-rules])
  subtract-map!(char-rules, [any-rules, null-rules])
  subtract-map!(byte-rules, [any-rules, null-rules])
  subtract-map!(int-rules, [any-rules, null-rules])
  subtract-map!(long-rules, [any-rules, null-rules])
  subtract-map!(float-rules, [any-rules, null-rules])
  subtract-map!(double-rules, [any-rules, null-rules])
  subtract-map!(string-rules, [any-rules, null-rules])
  subtract-map!(true-rules, [any-rules, null-rules])
  subtract-map!(false-rules, [any-rules, null-rules])
  subtract-map!(symbol-rules, [any-rules, null-rules])
  subtract-map!(list-rules, [any-rules, null-rules])
  subtract-map!(list-end-rules, [null-rules])
  subtract-map!(any-rules, [null-rules])
  
  ;Return computed dispatch sets
  DispatchSet(
    all-rules
    null-rules
    any-rules
    list-end-rules
    char-rules
    byte-rules
    int-rules
    long-rules
    float-rules
    double-rules
    string-rules
    true-rules
    false-rules
    symbol-rules
    list-rules
    keyword-rules)

;------------------------------------------------------------
;----------------- Negation Set Analysis --------------------
;------------------------------------------------------------

deftype KSet
defstruct KeywordSet <: KSet :
  keywords: Tuple<Symbol>
with:
  printer => true
  
defstruct ProdSet <: KSet :
  name: Symbol
with:
  printer => true
  
defstruct UnionSet <: KSet :
  sets: Tuple<KSet>
with:
  printer => true
  
defstruct MinusSet <: KSet :
  a: KSet
  b: KSet
with:
  printer => true

defn convert-negation-rules (rules:Tuple<GRule>) -> Tuple<GMatcherRule|GTokenRule> :
  ;Gather positive and negative tokens
  val negative-table = HashTable<Symbol,List<GToken>>(List())
  val positive-table = HashTable<Symbol,List<GToken>>(List())
  for rule in rules do :
    match(rule) :
      (rule:GNegationRule) :
        add(negative-table, name(rule), token(rule))
      (rule:GTokenRule) :
        if length(tokens(rule)) == 1 :
          val t = tokens(rule)[0]
          add(positive-table, name(rule), t)
      (rule:GMatcherRule) :
        false
        
  ;Create initial kset table
  val kset-table = HashTable<Symbol,KSet>()
  defn to-kset (name:Symbol) :
    set?(kset-table, name, fn () :
      val psets = to-tuple $ seq(to-kset, positive-table[name])
      val nsets = to-tuple $ seq(to-kset, negative-table[name])
      MinusSet(UnionSet(psets), UnionSet(nsets)))
  defn to-kset (t:GToken) :
    match(t) :
      (t:GProduction) : to-kset(name(t))
      (t:GKeyword) : KeywordSet([item(t)])
      
  ;Simplify kset
  val simplified-kset-table = HashTable<Symbol,KeywordSet>()
  defn simplify (name:Symbol) :
    set?(simplified-kset-table, name, fn () :
      simplify(to-kset(name)))
  defn simplify (kset:KSet) -> KeywordSet :
    match(kset) :
      (kset:UnionSet) :
        val keywords = seq-cat(keywords{simplify(_)}, sets(kset))
        KeywordSet $ to-tuple $ to-hashset<Symbol>(keywords)
      (kset:MinusSet) :
        val symbols = to-hashset<Symbol>(keywords(simplify(a(kset))))
        do(remove{symbols, _}, keywords(simplify(b(kset))))
        KeywordSet $ to-tuple $ symbols
      (kset:KeywordSet) :
        kset
      (kset:ProdSet) :
        simplify(name(kset))

  ;Create matcher rule
  defn to-matcher-rules (prod:Symbol) :
    val neg-tokens = negative-table[prod]
    val keywords = seq-cat(keywords{simplify(to-kset(_))}, neg-tokens)
    val keyword-set = to-hashset<Symbol>(keywords)
    defn match? (form) :
      match(unwrap-token(form)) :
        (s:Symbol) : not keyword-set[s]
        (s) : true
    val new-rules = Vector<GRule>()
    val old-prod = gensym(prod)
    add(new-rules, GMatcherRule(prod, [GProduction(old-prod)], match?, fn (result) : result[0]))
    for r in rules do :
      if name(r) == prod and r is-not GNegationRule :
        add(new-rules, sub-name(r, old-prod))
    new-rules

  ;Create matcher rules  
  val matcher-rules = seq-cat(to-matcher-rules, keys(negative-table))
  defn standard-rule? (r:GRule) : not key?(negative-table, name(r))
  val remaining-rules = filter(standard-rule?, rules[1 to false])
  val new-rules = to-tuple $ cat-all $ [
    [rules[0]]
     matcher-rules
     remaining-rules]
  new-rules as Tuple<GMatcherRule|GTokenRule>

;============================================================
;======================== ESetList ==========================
;============================================================

deftype ESetList
defmulti add (l:ESetList, items:Seqable<EItem>) -> False
defmulti clear-markers (l:ESetList) -> False
defmulti items (return:EItem -> ?, l:ESetList, index:Int, production:Symbol, mark?:True|False) -> False
defmulti first-item (l:ESetList, index:Int, production:Symbol) -> EItem|False
defmulti sets (l:ESetList) -> Seqable<Seqable<EItem>>
defmulti length (l:ESetList) -> Int

defstruct EItemSet :
  start: Int
  length: Int

defn ESetList (grammar:Grammar) :
  val items = Vector<EItem>()
  val markers = Vector<Int>()
  val sets = Vector<EItemSet>()
  val buffer = Vector<EItem>()
  var current-marker:Int = 1

  defn production! (item:EItem) :
    name(upcoming(grammar,item) as GProduction)

  defn productions (return:EItem -> ?, start:Int, end:Int, production:Symbol) :
    let loop (i:Int = start) :
      if i < end :
        val item = items[i]
        if production!(item) == production :
          return(item)
          loop(i + 1)

  new ESetList :
    defmethod length (this) :
      length(sets)
    defmethod add (this, new-items:Seqable<EItem>) :
      add-all(buffer, new-items)
      qsort!(production!, buffer)
      add(sets, EItemSet(length(items), length(buffer)))
      add-all(items, buffer)
      lengthen(markers, length(items), 0)
      clear(buffer)
    defmethod items (return:EItem -> ?, this, index:Int, production:Symbol, mark?:True|False) :
      val eset = sets[index]
      val i = bsearch(production!, items, start(eset), start(eset) + length(eset), production)
      match(i:Int) :
        if mark? :
          if markers[i] != current-marker :
            productions(return, i, start(eset) + length(eset), production)
            markers[i] = current-marker
        else :
          productions(return, i, start(eset) + length(eset), production)
    defmethod first-item (this, index:Int, production:Symbol) :
      val eset = sets[index]
      val i = bsearch(production!, items, start(eset), start(eset) + length(eset), production)
      match(i:Int) : items[i]
    defmethod clear-markers (this) :
      current-marker = current-marker + 1
    defmethod sets (this) :
      for eset in sets seq :
        for i in 0 to length(eset) seq :
          items[start(eset) + i]

;Binary search:
;It returns i such that all items at index < i satisfy key(xs[i]) < v.
defn bsearch<?T> (key:T -> Comparable, xs:Vector<?T>, start:Int, end:Int, v:Comparable) -> Int|False :
  bsearch(xs, start, end, compare{key(_), v})

defn bsearch<?T> (xs:Vector<?T>, start:Int, end:Int, compare:T -> Int) -> Int|False :
  ;All items with index less than i are known to return -1 for compare.
  ;All items with index greater than j are known to return 0/1 for compare.
  let loop (i:Int = start, j:Int = end) :
    if i == j :
      i when i < end and compare(xs[i]) == 0
    else :
      val m = (i + j) / 2
      if compare(xs[m]) < 0 : loop(m + 1, j)
      else : loop(i, m)

defn bsearch<?T> (xs:Vector<?T>, compare:T -> Int) -> Int|False :
  bsearch(xs, 0, length(xs), compare)

;============================================================
;==================== Error Handling ========================
;============================================================

defstruct MissingInput :
  input
  set-index: Int
  info: FileInfo|False
  items: Tuple<EItem>

defstruct MissingInputError <: Exception :
  input
  info: FileInfo|False
  productions: Tuple<Symbol>
  upcoming: Tuple<GToken>

defstruct ParsingErrors <: Exception :
  errors: Tuple<Exception>

defn to-exception (g:Grammar, m:MissingInput) :
  ;Compute earliest completed productions
  defn completed? (item:EItem) :
    val tokens = tokens!(g[rule(item)])
    num-parsed(item) == length(tokens)
  val completed-productions = HashTable<Symbol,Int>(INT-MAX)
  for item in filter(completed?,items(m)) do :
    update(completed-productions, min{_, parent(item)}, production(g,item))

  ;Compute productions and upcoming
  val productions = HashSet<Symbol>()
  val upcoming-tokens = HashSet<GToken>()
  for item in items(m) do :
    if passed-guard?(item) :
      val production = production(g,item)    
      val include? = match(upcoming(g,item)) :
        (t:GTerminal) :
          num-parsed(item) > 0 and
          completed-productions[production] > parent(item)
        (t:GProduction) :
          completed-productions[production] > parent(item)
        (t:False) :
          false
      if include? :
        add(productions, production)
        add(upcoming-tokens, upcoming(g, item) as GToken)

  ;Return error
  MissingInputError(input(m), info(m), to-tuple(productions), qsort(upcoming-tokens))

defn to-exception (g:Grammar, input-ms:Collection<MissingInput>) :  
  val ms = to-tuple(input-ms)
  defn first-in-chain? (i:Int) : i == 0 or set-index(ms[i - 1]) < set-index(ms[i]) - 1
  val es = seq(to-exception{g, ms[_]}, filter(first-in-chain?, 0 to length(ms)))
  ParsingErrors $ to-tuple $ es

defmethod print (o:OutputStream, e:MissingInputError) :
  val info-str = "" when info(e) is False else "%_: " % [info(e)]
  val input-str = match(input(e)) :
    (x:EndOfInput) : "end of input"
    (x:SExpForm) :
      match(unwrap-token(form(x))) :
        (f:Symbol) : "symbol '%~'" % [f]
        (f:List) : "list"
        (f) : "input '%~'" % [f]
    (x:SExpListEnd) : "end of list"
  defn token-str (t:GToken) :
    match(t) :
      (t:GProduction) : "a '%~' production" % [name(t)]
      (t:GKeyword) : "'%~'" % [item(t)]
      (t:GListStart) : "a list"
      (t:GListEnd) : "the end of the list"
      (t:GAny) : "a form"
      (t) : t
  defn tokens-str (ts:Tuple<GToken>) :
    if length(ts) == 1 :
      token-str(ts[0])
    else :
      val but-last-t = ts[0 to length(ts) - 1]
      val last-t = ts[length(ts) - 1]
      "either %,, or %_" % [seq(token-str,but-last-t), token-str(last-t)]
  defn productions-str (names:Tuple<Symbol>) :
    tokens-str(map(GProduction,names))
  print(o, "%_Unexpected %_." % [info-str, input-str])
  if not empty?(productions(e)) :
    print(o, " Current parsing %_ and %_ is expected next." % [
      productions-str(productions(e)), tokens-str(upcoming(e))])

defmethod print (o:OutputStream, e:ParsingErrors) :
  print(o, "Could not parse the given input:")
  val o2 = IndentedStream(o)
  do(lnprint{o2, _}, errors(e))

;============================================================
;============== ProductionTable/ProductionSet ===============
;============================================================

deftype ProductionTable<T>
defmulti get<?T> (t:ProductionTable<?T>, key:Symbol) -> T
defmulti set<?T> (t:ProductionTable<?T>, key:Symbol, v:T) -> False
defmulti clear (t:ProductionTable) -> False

defn ProductionTable<T> (default:T) :
  val table = HashTable<Symbol,T>(default)
  new ProductionTable<T> :
    defmethod get (this, key:Symbol) : table[key]
    defmethod set (this, key:Symbol, v:T) : table[key] = v
    defmethod clear (this) : clear(table)

deftype ProductionSet
defmulti get (t:ProductionSet, key:Symbol) -> True|False
defmulti add (t:ProductionSet, key:Symbol) -> True|False
defmulti clear (t:ProductionSet) -> False

defn ProductionSet () :
  val keys = HashSet<Symbol>()
  new ProductionSet :
    defmethod get (this, key:Symbol) : keys[key]
    defmethod add (this, key:Symbol) : add(keys,key)
    defmethod clear (this) : clear(keys)

deftype CompletionSet
defmulti add (s:CompletionSet, item:EItem) -> True|False
defmulti get (s:CompletionSet, item:EItem) -> True|False
defmulti clear (s:CompletionSet) -> False

defn CompletionSet () :
  val keys = HashSet<[Int,Int,Int]>()
  new CompletionSet :
    defmethod add (this, item:EItem) :
      add(keys, [rule(item), num-parsed(item), parent(item)])
    defmethod get (this, item:EItem) :
      keys[[rule(item), num-parsed(item), parent(item)]]
    defmethod clear (this) :
      clear(keys)

;============================================================
;====================== Debugging ===========================
;============================================================

defn printable-stream (return:OutputStream -> ?) :
  new Printable :
    defmethod print (o:OutputStream, this) :
      return(o)

defn print-current-set (grammar:Grammar, set-index:Int, current-set:ESet) :
  println("Set %_" % [set-index])
  within indented() :
    do(println{format(grammar,_)}, current-set)

defn format (grammar:Grammar, e:EItem) :
  within o = printable-stream() :
    val r = grammar[rule(e)]
    print(o, "(rule %_) [%_ =" % [rule(e), name(r)])
    for (t in tokens!(r), i in 0 to false) do :
      val prefix = " • " when num-parsed(e) == i else " "
      print-all(o, [prefix, t])
    if num-parsed(e) == length(tokens!(r)) :
      print(o, " •")
    print(o, ", S%_]" % [parent(e)])
    if r is GMatcherRule :
      print(o, " (custom matcher)")
    if not passed-guard?(e) :
      print(o, " (unmatched)")
    if completion-root(e) is EItem :
      val msg = format(grammar, completion-root(e) as EItem)
      print(o, " (complete as %_)" % [msg])

defn format (grammar:Grammar, setlist:ESetList) :
  within o = printable-stream() :
    val o2 = IndentedStream(o)
    for (eset in sets(setlist), i in 0 to false) do :
      print(o, "\n") when i > 0
      print(o, "Set %_:" % [i])
      do(lnprint{o2, format(grammar,_)}, eset)

defn format (grammar:Grammar, eset:Vector<EItem>) :
  within o = printable-stream() :
    val o2 = IndentedStream(o)
    print(o, "ESet :")
    do(lnprint{o2, format(grammar,_)}, eset)

defn format (grammar:Grammar, r:ParsedRange) :
  "(rule %_) [%_ to %_] %_" % [rule(r), start(r), end(r), grammar[rule(r)]]

defn format (grammar:Grammar, node:ParseNode) :
  within o = printable-stream() :
    val rule = grammar[rule(node)]
    print(o, "[%_ to %_] %_" % [start(node), end(node), rule])
    val o2 = IndentedStream(o)
    do(lnprint{o2, format(grammar,_)}, filter-by<ParseNode>(children(node)))

defn format (grammar:Grammar, p:EParent) :
  val parent-rule = grammar[rule(p)]
  val direct-str = " (direct)" when direct?(p) else ""
  "(rule %_) [%_ to ?] %_ (index %_) => %_%_" % [
    rule(p), start(p), parent-rule, index(p), format(grammar,child(p)), direct-str]

;============================================================
;=================== SExpression Stream =====================
;============================================================

deftype SExpStream
defmulti peek (s:SExpStream) -> SExpToken
defmulti advance (s:SExpStream, expand-list?:True|False) -> False
defmulti advance-rest (s:SExpStream) -> False
defmulti insert-wildcard (s:SExpStream) -> False
defmulti insert-list (s:SExpStream) -> False
defmulti info (s:SExpStream) -> FileInfo|False

deftype SExpToken
defstruct SExpForm <: SExpToken :
  form
  list:List
with:
  printer => true
defstruct SExpWildcard <: SExpToken
defstruct SExpListEnd <: SExpToken
defstruct EndOfInput <: SExpToken

defn list (t:SExpListEnd) :
  List()

defn SExpStream (input:List) :
  val stack = Vector<List>()
  var current:List|False = input
  var info:FileInfo|False = false

  defn update-info () :
    match(current:List) :
      if not empty?(current) :
        val t = head(current)
        match(t:Token) :
          info = /info(t)

  defn peek-stream () :
    match(current:List) :
      if empty?(current) : SExpListEnd()
      else :
        match(head(current)) :
          (t:SExpWildcard) : t
          (t) : SExpForm(t, current)
    else : EndOfInput()

  defn advance-stream (expand-list?:True|False) :
    fatal("No more tokens.") when current is False
    val curr = current as List
    if empty?(curr) :
      current = pop(stack) when not empty?(stack)
    else :
      val expand? = expand-list? and
                    unwrap-token(head(curr)) is List
      if expand? :
        add(stack, tail(curr))
        current = unwrap-token(head(curr)) as List
      else :
        current = tail(curr)
    update-info()

  update-info()
  new SExpStream :
    defmethod info (this) :
      info
    defmethod peek (this) :
      peek-stream()
    defmethod advance (this, expand-list?:True|False) :
      advance-stream(expand-list?)
    defmethod advance-rest (this) :
      current = List()
    defmethod insert-wildcard (this) :
      current = cons(SExpWildcard(), current as List)
    defmethod insert-list (this) :
      current = cons(List(), current as List)

;============================================================
;====================== RangeTable ==========================
;============================================================

deftype RangeTable
defmulti add (t:RangeTable, p:EParent) -> False
defmulti add (t:RangeTable, p:ECondParent) -> False
defmulti children (t:RangeTable, rule:Int, start:Int, index:Int, end:Int) -> List<EParent>
defmulti indirect-children (t:RangeTable, rule:Int, start:Int, index:Int, end:Int) -> List<EParent>
defmulti parent? (t:RangeTable, start:Int, production:Symbol) -> ECondParent|False
defmulti parents (t:RangeTable) -> Collection<EParent>
defmulti condparents (t:RangeTable) -> Collection<ECondParent>

defstruct EParent :
  rule: Int
  start: Int
  index: Int
  child: ParsedRange
  direct?: True|False
with:
  printer => true

defstruct ECondParent :
  rule: Int
  start: Int
  child-start: Int
  production: Symbol
with:
  printer => true

defstruct ParsedRange <: Equalable&Hashable :
  rule: Int
  start: Int
  end: Int
with:
  printer => true

defn RangeTable () :
  val children-table = HashTable<[Int, Int, Int, Int],List<EParent>>(List())
  val indirect-children-table = HashTable<[Int, Int, Int, Int],List<EParent>>(List())
  val parent-table = HashTable<[Int,Symbol],ECondParent>()
  new RangeTable :
    defmethod add (this, p:EParent) :
      val key = [rule(p), start(p), index(p), end(child(p))]
      val table = children-table when direct?(p) else indirect-children-table
      update(table, cons{p, _}, key)
      false
    defmethod add (this, p:ECondParent) :
      val key = [child-start(p), production(p)]
      fatal("Entry already exists.") when key?(parent-table, key)
      parent-table[key] = p
    defmethod children (this, rule:Int, start:Int, index:Int, end:Int) :
      children-table[[rule, start, index, end]]
    defmethod indirect-children (this, rule:Int, start:Int, index:Int, end:Int) :
      indirect-children-table[[rule, start, index, end]]
    defmethod parent? (this, start:Int, production:Symbol) :
      get?(parent-table, [start, production])
    defmethod parents (this) :
      within to-collection() :
        cat-all(values(children-table))
    defmethod condparents (this) :
      within to-collection() :
        to-seq(values(parent-table))

defmethod equal? (a:ParsedRange, b:ParsedRange) :
  rule(a) == rule(b) and
  start(a) == start(b) and
  end(a) == end(b)

defmethod hash (a:ParsedRange) :
  hash $ [rule(a), start(a), end(a)]

defn length (r:ParsedRange) :
  end(r) - start(r)

;============================================================
;======================= ESet ===============================
;============================================================

deftype ESet <: Collection<EItem>
defmulti start-completed? (s:ESet) -> True|False
defmulti scanned-any? (s:ESet) -> True|False
defmulti scanned-atomic-any? (s:ESet) -> True|False
defmulti scanned-non-reluctant? (s:ESet) -> True|False
defmulti scanned-non-reluctant-list-start? (s:ESet) -> True|False
defmulti scanned-rest? (s:ESet) -> True|False
defmulti wildcard-expected? (s:ESet) -> True|False
defmulti list-expected? (s:ESet) -> True|False
defmulti list-end-expected? (s:ESet) -> True|False
defmulti add (s:ESet, item:EItem) -> False
defmulti clear (s:ESet, length:Int) -> False
defmulti length (s:ESet) -> Int
defmulti get (s:ESet, i:Int) -> EItem
defmulti map! (f:EItem -> EItem, s:ESet) -> False
defmulti remove! (f:EItem -> True|False, s:ESet) -> False

defn ESet (grammar:Grammar) :
  ;Accumulate items
  val items = Vector<EItem>()

  ;Track flags
  var start-completed?:True|False
  var scanned-any?:True|False
  var scanned-atomic-any?:True|False
  var scanned-non-reluctant?:True|False
  var scanned-non-reluctant-list-start?:True|False
  var scanned-rest?:True|False
  var wildcard-expected?: True|False
  var list-expected?: True|False
  var list-end-expected?: True|False
  
  defn recompute-flags () :
    start-completed? = false
    scanned-any? = false
    scanned-atomic-any? = false
    scanned-non-reluctant? = false
    scanned-non-reluctant-list-start? = false
    scanned-rest? = false
    wildcard-expected? = false
    list-expected? = false
    list-end-expected? = false
    do(process-flags, items)

  defn process-flags (item:EItem) :
    ;Set flags for what was scanned.
    val prev-item = previous(grammar,item)
    match(prev-item) :
      (t:GAny) :
        scanned-any? = true
        if type(t) is Atomic : scanned-atomic-any? = true
      (t:GListStart) :
        if not reluctant?(t) :
          scanned-non-reluctant-list-start? = true
      (t:GListRest) :
        scanned-rest? = true      
      (t) :
        false

    ;Process scanned non-reluctant flag
    if non-reluctant-terminal?(prev-item) :
      scanned-non-reluctant? = true
        
    ;Set flags for what is upcoming
    match(upcoming(grammar,item)) :
      (t:GListStart) :
        list-expected? = true
      (t:GListEnd) :
        list-end-expected? = true
      (t:GTerminal) :
        wildcard-expected? = true
      (t:False) :        
        if rule(item) == 0 : start-completed? = true
      (t) :
        false

  recompute-flags()
  new ESet :
    defmethod clear (this, l:Int) :
      shorten(items, l)
      recompute-flags()
    defmethod add (this, item:EItem) :
      add(items, item)
      process-flags(item)
    defmethod get (this, i:Int) : items[i]
    defmethod length (this) : length(items)
    defmethod to-seq (this) : to-seq(items)
    defmethod map! (f:EItem -> EItem, this) : map!(f, items)
    defmethod remove! (f:EItem -> True|False, this) :
      remove-when(f, items)
      recompute-flags()
    ;Flags
    defmethod start-completed? (this) : start-completed?
    defmethod scanned-any? (this) : scanned-any?
    defmethod scanned-atomic-any? (this) : scanned-atomic-any?
    defmethod scanned-non-reluctant? (this) : scanned-non-reluctant?
    defmethod scanned-non-reluctant-list-start? (this) : scanned-non-reluctant-list-start?
    defmethod scanned-rest? (this) : scanned-rest?
    defmethod wildcard-expected? (this) : wildcard-expected?
    defmethod list-expected? (this) : list-expected?
    defmethod list-end-expected? (this) : list-end-expected?

defmethod do (f:EItem -> ?, eset:ESet) :
  val item-index = to-seq(0 to false)
  while peek(item-index) < length(eset) :
    f(eset[next(item-index)])

defn empty? (s:ESet) :
  length(s) == 0

;============================================================
;================= Matching Predicates ======================
;============================================================

;Returns true if the given token is a non-reluctant terminal.
defn non-reluctant-terminal? (t:GToken|False) :
  match(t) :
    (t:GProduction) : false
    (t:False) : false
    (t:GListRest) : false
    (t:GAny) : type(t) is-not Reluctant
    (t:GListStart) : not reluctant?(t)
    (t) : true

;Returns true if the given terminal matches against the given input.
defn matches-input? (t:GTerminal, input:SExpToken) :
  match(t, input) :
    ;Wildcard matching
    (t:GListStart|GListEnd, input:SExpWildcard) : false
    (t, input:SExpWildcard) : true
    ;Form matching
    (t:GKeyword, input:SExpForm) : unwrap-token(form(input)) == item(t)
    (t:GCharToken, input:SExpForm) : unwrap-token(form(input)) is Char
    (t:GByteToken, input:SExpForm) : unwrap-token(form(input)) is Byte
    (t:GIntToken, input:SExpForm) : unwrap-token(form(input)) is Int
    (t:GLongToken, input:SExpForm) : unwrap-token(form(input)) is Long
    (t:GFloatToken, input:SExpForm) : unwrap-token(form(input)) is Float
    (t:GDoubleToken, input:SExpForm) : unwrap-token(form(input)) is Double
    (t:GStringToken, input:SExpForm) : unwrap-token(form(input)) is String
    (t:GSymbolToken, input:SExpForm) : unwrap-token(form(input)) is Symbol
    (t:GTrueToken, input:SExpForm) : unwrap-token(form(input)) is True
    (t:GFalseToken, input:SExpForm) : unwrap-token(form(input)) is False
    (t:GListStart, input:SExpForm) : unwrap-token(form(input)) is List
    (t:GAny, input:SExpForm) : true
    (t:GListRest, input:SExpForm) : true
    (t, input:SExpForm) : false
    ;List end matching
    (t:GListEnd, input:SExpListEnd) : true
    (t, input:SExpListEnd) : false

;Returns true if the upcoming input satisfies the matcher of the given rule.
defn matches-input? (rule:GMatcherRule, input:SExpToken) :
  match(input) :
    (input:SExpWildcard) : true
    (input:SExpForm) : matcher(rule)(form(input))
    (input) : false

;============================================================
;====================== Algorithm ===========================
;============================================================

defstruct ParseResult :
  node: ParseNode
  grammar: Grammar
  inputlist: Vector<SExpToken>
  infolist: Vector<FileInfo|False>

defn parse-result (grammar:Grammar, input:List) -> ParseResult|ParsingErrors :
  val setlist = ESetList(grammar)
  val prediction-set = ProductionSet()
  val completion-set = CompletionSet()
  val production-count = ProductionTable<Int>(0)
  val ranges = RangeTable()
  val inputlist = Vector<SExpToken>()
  val infolist = Vector<FileInfo|False>()
  val missing = Vector<MissingInput>()

  ;Returns true if the starting rule has been completed
  defn process-set (set-index:Int,
                    current-set:ESet,
                    next-set:ESet,
                    next-input:SExpToken,
                    include-all-rules?:True|False) -> True|False :                    
    ;Clear state
    clear-markers(setlist)
    clear(prediction-set)
    clear(completion-set)

    ;Iterate through each item
    for item in current-set do :
      dispatch(item) where :
        defn* dispatch (item:EItem) :
          if passed-guard?(item) :
            ;Dispatch
            match(upcoming(grammar,item)) :
              (t:GTerminal) : upcoming-terminal(item, t)
              (p:GProduction) : upcoming-production(item, p)
              (f:False) : end-of-rule(item)
          else :
            test-guard(item)
        defn test-guard (item:EItem) :
          val rule = grammar[rule(item)] as GMatcherRule
          if matches-input?(rule, next-input) :
            add(current-set, sub-passed-guard?(item, true))
        defn add-completion (item:EItem) :
          add(current-set, item) when add(completion-set, item)
        defn upcoming-terminal (item:EItem, t:GTerminal) :
          if matches-input?(t, next-input) :
            add(next-set, inc-num-parsed(item))
        defn upcoming-production (item:EItem, t:GProduction) :
          if nullable?(grammar, name(t)) :
            add-completion(inc-num-parsed(item))          
          if add(prediction-set, name(t)) :
            val rules = rules(grammar, name(t)) when include-all-rules?
                   else rules(grammar, name(t), next-input)
            for rule in rules do :
              val passed-guard? = grammar[rule] is-not GMatcherRule
              add(current-set, EItem(rule, 0, set-index, passed-guard?))
        defn end-of-rule (completed-item:EItem) :
          val prod = production(grammar,completed-item)
          if parent(completed-item) < set-index :
            within item = items(setlist, parent(completed-item), prod, true) :
              val root = match(completion-root(item)) :
                (root:EItem) : root
                (f:False) : item
              add-completion(inc-num-parsed(root))

  defn prune-conditional-matches (eset:ESet, input:SExpToken) -> True|False :
    ;Remove all items whose previous token satisfies f.
    defn remove-previous (f:GToken|False -> True|False) :
      remove!(f{previous(grammar, _)}, eset)

    ;Is the input a list?
    val input-is-list? = match(input:SExpForm) :
      unwrap-token(form(input)) is List

    ;Determine whether we have made any progress?
    if scanned-non-reluctant?(eset) :
      ;Determine whether we have conditional matches to take care of. This
      ;occurs if the input is a list and an ANY has been scanned.
      if input-is-list? and scanned-any?(eset) :
        ;If an atomic any has been scanned, then we do not want the
        ;list to be expanded, and all matches with LIST-START should
        ;be removed.
        if scanned-atomic-any?(eset) :
          remove-previous({_ is GListStart|GListRest})
          false
        ;If a non-reluctant list start has been scanned, then we do want
        ;the list to be expanded, and all matches with ANY should
        ;be removed.
        else if scanned-non-reluctant-list-start?(eset) :
          remove-previous({_ is GAny|GListRest})
          true
        ;Otherwise, we do not need the list to be expanded, and all
        ;matches with LIST-START should be removed.
        else :
          remove-previous({_ is GListStart|GListRest})
          false
      ;If we scanned a rest production, then we need to remove it, since
      ;we know that we have successfully scanned a non-reluctant terminal.
      else if scanned-rest?(eset) :
        remove-previous({_ is GListRest})
        true
      ;By default, we expand the list.
      else :
        true
    ;Otherwise, we have scanned only reluctant items, and
    ;they should all should be removed, except for rest.
    else :
      remove-previous({_ is-not GListRest})
      false

  defn compute-completion-root (set-index:Int, current-set:ESet) :
    ;Compute count table
    clear(production-count)
    for item in current-set do :
      val t = upcoming(grammar,item)
      match(t:GProduction) :
        production-count[name(t)] = production-count[name(t)] + 1
    ;Determine whether deterministic reduction
    defn deterministic-reduction? (item:EItem) :
      val num-tokens = length(tokens!(grammar[rule(item)]))
      if num-parsed(item) == num-tokens - 1 :
        val t = upcoming(grammar,item)
        match(t:GProduction) : production-count[name(t)] == 1
    ;Compute completion
    defn complete (item:EItem) :
      if parent(item) < set-index :
        val pitem = first-item(setlist, parent(item), production(grammar,item))
        match(pitem:EItem) : completion-root(pitem)
    ;Compute completions of all deterministic reductions.
    for item in current-set map! :
      if deterministic-reduction?(item) :
        match(complete(item)) :
          (c:EItem) : sub-completion-root(item, c)
          (f:False) : sub-completion-root(item, item)
      else : item

  defn add-to-setlist (current-set:ESet) :
    defn prod? (e:EItem) : passed-guard?(e) and upcoming(grammar,e) is GProduction
    add(setlist, filter(prod?, current-set))

  defn record-completions (set-index:Int, current-set:ESet) :
    defn complete? (item:EItem) : upcoming(grammar,item) is False
    for item in current-set do :
      if complete?(item) :
        val range = ParsedRange(rule(item), parent(item), set-index)
        within pitem = items(setlist, parent(item), production(grammar, item), false) :
          add(ranges, EParent(rule(pitem), parent(pitem), num-parsed(pitem), range, true))
          if completion-root(pitem) is-not False :
            val pitem = completion-root(pitem) as EItem
            add(ranges, EParent(rule(pitem), parent(pitem), num-parsed(pitem), range, false))
      else if completion-root(item) is-not False :
        val production = name(upcoming(grammar,item) as GProduction)
        add(ranges, ECondParent(rule(item), parent(item), set-index, production))

  defn record-missing-input (next-input, index:Int, info:FileInfo|False, eset:ESet) :
    add(missing, MissingInput(next-input, index, info, to-tuple(eset)))
      
  defn process-all-sets () :
    ;Initialize current-set and next-set.
    val current-set = ESet(grammar)
    val next-set = ESet(grammar)
    add(current-set, EItem(0, 0, 0))
    
    ;Initialize input stream
    val input-stream = SExpStream(input)
    
    ;Process sets until finished.
    let loop (set-index:Int = 0,
              current-set:ESet = current-set,
              next-set:ESet = next-set) :
      val next-input = peek(input-stream)
      val num-scanned = length(current-set)      
      process-set(set-index, current-set, next-set, next-input, false)
      val expand-list? = prune-conditional-matches(next-set, next-input)

      ;Utilities
      defn* record-current-set () :
        ;Add matched input
        add(inputlist, next-input)
        add(infolist, info(input-stream))
        ;Debug
        ;print-current-set(grammar, set-index, current-set)
        ;Compute the completion root and add to the setlist
        compute-completion-root(set-index, current-set)
        add-to-setlist(current-set)
        ;Record all completed productions
        record-completions(set-index, current-set)
      defn* scan-next-set () :
        clear(current-set, 0)
        loop(set-index + 1, next-set, current-set)
      defn* scan-current-set-again () :
        clear(current-set, num-scanned)
        loop(set-index, current-set, next-set)
      defn* compute-complete-current-set () :
        clear(current-set, num-scanned)
        process-set(set-index, current-set, next-set, next-input, true)

      ;Dispatch to different cases
      defn* dispatch () :
        if empty?(next-set) :
          if start-completed?(current-set) : finished-parse()
          else : unexpected-input()
        else if scanned-rest?(next-set) : advance-to-list-end()
        else : advance-one()
      defn* finished-parse () :
        record-current-set()
      defn* advance-to-list-end () :
        record-current-set()
        advance-rest(input-stream)
        scan-next-set()
      defn* advance-one () :
        record-current-set()
        advance(input-stream, expand-list?)
        scan-next-set()
      defn* unexpected-input () :
        compute-complete-current-set()
        record-missing-input(next-input, set-index, info(input-stream), current-set)
        if list-end-expected?(current-set) : advance(input-stream, false)          
        else if wildcard-expected?(current-set) : insert-wildcard(input-stream)
        else if list-expected?(current-set) : insert-list(input-stream)
        else : fatal("Unrecoverable")
        scan-current-set-again()

      ;Launch
      dispatch()

  ;Launch!
  defn main () :
    val process-set-timer = MillisecondTimer("Process Set")
    start(process-set-timer)
    process-all-sets()
    stop(process-set-timer)
    println(process-set-timer)
    
    if empty?(missing) :
      val tree-timer = MillisecondTimer("Tree")
      start(tree-timer)
      val node = select-tree(grammar, ranges, length(setlist) - 1)
      stop(tree-timer)
      println(tree-timer)
      ParseResult(node, grammar, inputlist, infolist)
    else :
      to-exception(grammar, missing)

  main()  

;============================================================
;================ Selecting the Parse Tree ==================
;============================================================

defn select-tree (grammar:Grammar, ranges:RangeTable, ending-set:Int) -> ParseNode :
  ;Complete right recursive chains 
  val completed-right-recursive-chains = HashSet<ParsedRange>()
  defn complete-right-recursive-chain (r:ParsedRange) :
    if add(completed-right-recursive-chains, r) :
      val production = name(grammar[rule(r)])
      val parent = parent?(ranges, start(r), production)
      match(parent:ECondParent) :
        val last-index = length(tokens!(grammar[rule(parent)])) - 1
        add(ranges, EParent(rule(parent), start(parent), last-index, r, true))
        complete-right-recursive-chain(ParsedRange(rule(parent), start(parent), end(r)))

  defn lookup-child (rule:Int, start:Int, index:Int, end:Int, rightmost-child?:True|False) :
    ;Complete any outstanding right recursive chains
    if rightmost-child? :
      for c in indirect-children(ranges, rule, start, index, end) do :
        complete-right-recursive-chain(child(c))
    ;Find most specific child
    val cs = children(ranges, rule, start, index, end)
    if empty?(tail(cs)) : head(cs)
    else : minimum(cs, {compare-specificity(grammar, _, _) < 0})

  defn select-tokens (rule:Int,
                      start-position:Int,
                      end-position:Int) -> Tuple<ParseNode|False> :
    val grule = grammar[rule] as GMatcherRule|GTokenRule
    val children = Vector<ParseNode|False>()
    val last-index = length(tokens(grule)) - 1
    let loop (index:Int = last-index, end-position:Int = end-position) :
      if index >= 0 :
        match(tokens(grule)[index]) :
          (t:GTerminal) :
            add(children, false)
            loop(index - 1, end-position - 1)
          (t:GProduction) :              
            val child-edge = lookup-child(rule, start-position, index, end-position, index == last-index)
            add(children, select(child(child-edge)))
            loop(index - 1, start(child(child-edge)))
    reverse!(children)
    to-tuple(children)

  defn select (range:ParsedRange) -> ParseNode :
    val children = select-tokens(rule(range), start(range), end(range))
    ParseNode(rule(range), start(range), end(range), children)      

  ;Launch
  select(ParsedRange(0, 0, ending-set))  

;Return -1 if a should take priority over b during
;a right-to-left disambiguation sweep of the parse forest.
defn compare-specificity (grammar:Grammar, a:EParent, b:EParent) :
  val parent-rule = grammar[rule(a)] as GMatcherRule|GTokenRule
  val rule-a = grammar[rule(child(a))] as GMatcherRule|GTokenRule
  val rule-b = grammar[rule(child(b))] as GMatcherRule|GTokenRule
  defn compare-associativity () :
    switch(associativity(parent-rule)) :
      RightAssociative : compare(length(child(b)), length(child(a)))
      LeftAssociative : compare(length(child(a)), length(child(b)))
  defn compare-priority () :
    compare(priority(rule-b), priority(rule-a))
  defn compare-order () :
    compare(rule(child(a)), rule(child(b)))
    
  val c1 = compare-associativity()
  if c1 == 0 :
    val c2 = compare-priority()
    if c2 == 0 : compare-order()
    else : c2
  else : c1  

;============================================================
;================= Evaluate the Parse Tree ==================
;============================================================

defn evaluate-parse-tree (parse-result:ParseResult) :
  ;Pull out fields
  val grammar = grammar(parse-result)
  val inputlist = inputlist(parse-result)
  val infolist = infolist(parse-result)
  
  ;Accumulated errors                        
  val errors = Vector<Exception>()

  ;Attempt evaluation of a given ParseNode
  defn evaluate (tree:ParseNode) -> Maybe :
    ;Retrieve rule
    val rule = grammar[rule(tree)] as GMatcherRule|GTokenRule
    defn evaluate-child (i:Int) -> Maybe :
      match(children(tree)[i]) :
        (child:ParseNode) :
          evaluate(child)
        (f:False) :
          val token = tokens(rule)[i]
          val input = inputlist[start(tree) + i]
          match(token, input) :
            (token:GListRest, input:SExpForm|SExpListEnd) : One(list(input))
            (token:GListEnd, input:SExpListEnd) : One(false)
            (token, input:SExpForm) : One(form(input))
            
    ;Lazy evaluation
    defn lazy-evaluation () :
      val result = new ParsedResult :
        defmethod get (this, i:Int) :
          val v = evaluate-child(i)
          throw(ChildNotEvaluated()) when empty?(v)
          value!(v)
        defmethod info (this) : infolist[start(tree)]
        defmethod form (this) : list(inputlist[start(tree)] as SExpForm|SExpListEnd)
      try :
        One(action(rule)(result))
      catch (e:ChildNotEvaluated) :
        None()
      catch (e:Exception) :
        add(errors, e)
        None()
        
    ;Eager evaluation
    defn eager-evaluation () :
      val results = to-tuple $
        seq(evaluate-child, 0 to length(tokens(rule)))
      if none?(empty?, results) :
        val result = new ParsedResult :
          defmethod get (this, i:Int) : value!(results[i])
          defmethod info (this) : infolist[start(tree)]
          defmethod form (this) : list(inputlist[start(tree)] as SExpForm|SExpListEnd)
        try :
          One(action(rule)(result))
        catch (e:Exception) :
          add(errors, e)
          None()
      else :
        None()

    ;Launch!
    if lazy-action?(rule) : lazy-evaluation()
    else : eager-evaluation()

  ;Launch!
  val evaluate-timer = MillisecondTimer("Evaluation Timer")
  start(evaluate-timer)
  val v = evaluate(node(parse-result))
  stop(evaluate-timer)
  println(evaluate-timer)
  if empty?(v) : throw(ParsingErrors(to-tuple(errors)))
  else : value!(v)

defstruct ChildNotEvaluated <: Exception

;============================================================
;==================== Overall Launcher ======================
;============================================================

defn parse (grammar:Grammar, input:List) :
  match(parse-result(grammar, input)) :
    (r:ParseResult) : evaluate-parse-tree(r)
    (e:ParsingErrors) : throw(e)  

;============================================================
;======================= Test Case ==========================
;============================================================

defn test-parse (rules:Tuple<GRule>, input:List) :
  val g = Grammar(rules)
  match(parse-result(g, input)) :
    (n:ParseResult) : println(format(g,node(n)))
    (e:ParsingErrors) : println(e)

defn test-parse-action (rules:Tuple<GRule>, input:List) :
  println(parse(Grammar(rules), input))

defn example-grammar () :
  val E = GProduction(`E)
  val N = GKeyword(`N)
  val PLUS = GKeyword(`+)
  val TIMES = GKeyword(`x)
  val LPAREN = GKeyword(`L)
  val RPAREN = GKeyword(`R)
  [GTokenRule(`S, [E])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])]

deftest print-grammar :
  val g = example-grammar()
  do(println, g)

deftest parse :
  test-parse(example-grammar(), `(N x N x L N + N R x N x N + N x N x N))

defn example-grammar-2 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val B = GKeyword(`B)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [E E X])
   GTokenRule(`S, [F F Y])
   GTokenRule(`E, [A A B])
   GTokenRule(`F, [A A B])]

deftest parse-2 :
  val g = example-grammar-2()
  test-parse(g, `(A A B A A B Y))

defn example-grammar-3 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [E F X])
   GTokenRule(`S, [F E X])
   GTokenRule(`S, [F F F Y])
   GTokenRule(`E, [A A])
   GTokenRule(`F, [A])]

deftest parse-3 :
  val g = example-grammar-3()
  test-parse(g, `(A A A X))

defn example-grammar-4 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [E E X])
   GTokenRule(`E, [A])
   GTokenRule(`E, [A A])]

deftest parse-4 :
  val g = example-grammar-4()
  test-parse(g, `(A A A A X))

defn example-grammar-5 () :
  #for E in [ES, E, IF-E, SCLAUSES, SCLAUSE, ECLAUSE] :
    val E = GProduction(`E)
  #for (X in [PLUS, TIMES, LPAREN, RPAREN, N, EQ, LET, IN, IF, COLON, ELSE, SWITCH],
        x in [+, x, L, R, N, =, let, in, if, :, else, switch]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])
   GTokenRule(`E, [E EQ E])
   GTokenRule(`E, [LET E EQ E IN E])
   GTokenRule(`E, [IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE COLON E])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES ECLAUSE RPAREN])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES RPAREN])
   GTokenRule(`SCLAUSES, [SCLAUSE SCLAUSES])
   GTokenRule(`SCLAUSES, [])
   GTokenRule(`SCLAUSE, [E COLON E])
   GTokenRule(`ECLAUSE, [ELSE COLON E])]

deftest grammar-calc :
  Grammar(example-grammar-5())

deftest parse-5 :
  val g = example-grammar-5()
  test-parse(g, `(
    switch L
      N : N x N else
      N x N : N
      N + N : N + N +
      else : N x N
    R))

deftest parse-6 :
  test-parse(example-grammar-5(), reader/read-file("test.txt"))

defn example-grammar-6 () :
  #for E in [ES, E] :
    val E = GProduction(`E)
  #for (X in [A B C],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [ES])
   GTokenRule(`ES, [E, ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [A])
   GTokenRule(`E, [B C])]

deftest parse-7 :
  val g = example-grammar-6()
  test-parse(g, `(a a b c a a b c b c a a a a a a a a a a a a a a a a))

deftest parse-mutually-right-recursive :
  #for E in [AS BS CS A B C X] :
    val E = GProduction(`E)
  #for (X in [x a b c],
        x in [x a b c]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [X X X AS])
    GTokenRule(`AS, [A, X, BS])
    GTokenRule(`BS, [B, X, CS])
    GTokenRule(`CS, [X])
    GTokenRule(`CS, [C, X, AS])
    GTokenRule(`X, [x])
    GTokenRule(`A, [a])
    GTokenRule(`B, [b])
    GTokenRule(`C, [c])]
  test-parse(rules, `(x x x a x b x c x a x b x c x a x b x x))

deftest right-recursive-priority :
  #for E in [E A BS] :
    val E = GProduction(`E)
  #for (X in [a],
        x in [a]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [E])
    GTokenRule(`E, [A BS])
    GTokenRule(`E, [A A A A], 200)
    GTokenRule(`BS, [A BS])
    GTokenRule(`BS, [])
    GTokenRule(`A, [a])]
  test-parse(rules, `(a a a a))

defn example-null-grammar () :
  #for X in [S Ap E] :
    val X = GProduction(`X)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [Ap Ap Ap Ap])
   GTokenRule(`Ap, [A])
   GTokenRule(`Ap, [E])
   GTokenRule(`E, [])]

deftest parse-null :
  val g = example-null-grammar()
  test-parse(g, `(a a a))

defn example-tricky-null-grammar () :
  #for E in [S, A, B] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [w A d])
   GTokenRule(`S, [A d])
   GTokenRule(`S, [w B A A A d])
   GTokenRule(`A, [x])
   GTokenRule(`A, [])
   GTokenRule(`B, [x])]

deftest parse-tricky-null :
  val g = example-tricky-null-grammar()
  test-parse(g, `(w x x d))

defn example-tricky-null-grammar-2 () :
  #for E in [B S A] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [B])
   GTokenRule(`B, [S])
   GTokenRule(`B, [A])
   GTokenRule(`S, [w x A A A A d], 100, LeftAssociative)
   GTokenRule(`A, [w x])
   GTokenRule(`A, [])]

deftest parse-tricky-null-2 :
  val g = example-tricky-null-grammar-2()
  test-parse(g, `(w x w x d))

defn list-grammar () :
  #for E in [S, A, B, C, D, L, R, CD, CDs] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [A B CDs L CDs R CDs])
   GTokenRule(`S, [A B C])
   GTokenRule(`CDs, [CD, CDs])
   GTokenRule(`CDs, [])
   GTokenRule(`CD, [L C D R])
   GTokenRule(`A, [a])
   GTokenRule(`B, [b])
   GTokenRule(`C, [c])
   GTokenRule(`D, [d])
   GTokenRule(`L, [GListStart()])
   GTokenRule(`R, [GListEnd()])]

deftest parse-list :
  val g = list-grammar()
  test-parse(g, `(a b (c d) (c d) ((c d) (c d) (c d)) (c d)))

defn any-vs-list-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [done],
        x in [done]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [GAny() done])
   GTokenRule(`S, [GListStart() done GListEnd() done])]

deftest parse-any-vs-list :
  val g = any-vs-list-grammar()
  test-parse(g, `((done) done))

defn any-as-list-grammar () :
  #for E in [S A As Xs] :
    val E = GProduction(`E)
;  #for (X in [],
;        x in [a b c d]) :
;    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [Xs Xs])
   GTokenRule(`S, [A A])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [GListStart(true) As GListEnd()])
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`Xs, [GListStart() GKeyword(`x) GListEnd()])]

deftest parse-any-as-list :
  val g = any-as-list-grammar()
  test-parse(g, `((x) (x y z)))

defn list-recovery-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [a GListStart() b GListEnd() c])]

deftest parse-list-recovery :
  val g = list-recovery-grammar()
  test-parse(g, `(a b c))

defn rest-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [GListStart() a b c GListEnd()])
   GTokenRule(`S, [GListStart() a b GListRest() GListEnd()])]

deftest parse-rest :
  val g = rest-grammar()
  test-parse(g, `((a b d e f)))

defn full-any-grammar () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [LP a b LP c d As d RP RP])   
   GTokenRule(`S, [LP a b LP c d R RP RP])   
   GTokenRule(`S, [A])
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]  

deftest parse-full-any-grammar :
  val g = full-any-grammar()
  test-parse(g, `((a b (c d x y z d g d))))

defn full-any-grammar-2 () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [A a b c]) 
   GTokenRule(`S, [R])   
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]  

deftest parse-full-any-grammar-2 :
  val g = full-any-grammar-2()
  test-parse(g, `((x y z) a b c))

defn amb-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])]    

deftest parse-amb-grammar :
  val g = amb-grammar()
  test-parse(g, `(red red dog dog red dog dog dog))

defn amb-grammar-2 () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])]    

deftest parse-amb-grammar-2 :
  val g = amb-grammar-2()
  test-parse(g, `(red dog dog red dog dog red dog dog red dog dog red dog dog))

defn if-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [IF THEN ELSE N],
        x in [if then else N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [LP E RP])   
   GTokenRule(`E, [IF E THEN E], 100, LeftAssociative)      
   GTokenRule(`E, [IF E THEN E ELSE E], 100, LeftAssociative)
   GTokenRule(`E, [N])]    

deftest parse-if-grammar :
  val g = if-grammar()
  test-parse(g, `(if N then if N then N else N))

defn matcher-grammar () :
  #for E in [ES E Id BId RId] :
    val E = GProduction(`E)
  #for (X in [VAR EQ N DOT],
        x in [var = N .]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn prefix-symbol? (form, prefix:String) :
    match(unwrap-token(form)) :
      (f:Symbol) : prefix?(name(f), prefix)
      (f) : false
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [VAR Id EQ E])
   GTokenRule(`E, [N])
   GTokenRule(`Id, [BId DOT RId])
   GMatcherRule(`BId, [GAny()], prefix-symbol?{_, "B"})
   GMatcherRule(`RId, [GAny()], prefix-symbol?{_, "R"})]

deftest parse-matcher-grammar :
  val g = matcher-grammar()
  test-parse(g, `(var B10.R18 = N N))

deftest parse-matcher-grammar-error :
  val g = matcher-grammar()
  test-parse(g, `("hello world"))

defn core-form-grammar () :
  #for E in [ES E A R] :
    val E = GProduction(`E)
  #for (X in [CORE],
        x in [$core]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn core-form? (form) :
    match(unwrap-token(form)) :
      (f:List) : not empty?(f) and unwrap-token(head(f)) == `$core
      (f) : false
      
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [CORE])
   GTokenRule(`E, [LP ES RP])   
   GMatcherRule(`E, [GAny(Atomic)], core-form?)

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP R RP])
   GTokenRule(`R, [GAny() R])
   GTokenRule(`R, [LP R RP R])
   GTokenRule(`R, [GListRest()])]

deftest parse-core-form-grammar :
  val g = core-form-grammar()
  test-parse(g, `($core ($core a b c d) $core))

defn exp-grammar () :
  #for E in [ES E ID] :
    val E = GProduction(`E)
  #for (X in [VAR VAL FOR LET IN EQ COLON PLUS TIMES N DO],
        x in [var val for let in = : + * N @do]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
      
  [GTokenRule(`Start, [ES GListEnd()], fn (result) :
     result[0])
  
   GTokenRule(`keywords, [VAR])     
   GTokenRule(`keywords, [VAL])     
   GTokenRule(`keywords, [FOR])     
   GTokenRule(`keywords, [LET])     
   GTokenRule(`keywords, [IN])
   GTokenRule(`keywords, [EQ])
   GTokenRule(`keywords, [COLON])
   GTokenRule(`keywords, [DO])

   GTokenRule(`ID, [GAny()], fn (result) :
     result[0])
   GNegationRule(`ID, GProduction(`keywords))
   
   GTokenRule(`ES, [E ES], fn (result) :
     cons(result[0], result[1]))
   GTokenRule(`ES, [], fn (result) :
     List())
   
   GTokenRule(`E, [VAR ID EQ E], fn (result) :
     qquote($var ~(result[1]) ~(result[3])))
   GTokenRule(`E, [VAL ID EQ E], fn (result) :
     qquote($val ~(result[1]) ~(result[3])))
   GTokenRule(`E, [FOR ID IN E COLON E], fn (result) :
       qquote($for ~(result[1]) ~(result[3]) ~(result[5])))
   GTokenRule(`E, [LET ID EQ E COLON E], fn (result) :
     qquote($let ~(result[1]) ~(result[3]) ~(result[5])))
   GTokenRule(`E, [E LP DO ES RP], 70, LeftAssociative, fn (result) :
     qquote($call ~(result[0]) ~@(result[3])))
   GTokenRule(`E, [LP E RP], fn (result) :
     result[1])
   GTokenRule(`E, [LP ES RP], fn (result) :
     qquote($begin ~@(result[1])))
   GTokenRule(`E, [N], fn (result) :
     result[0])
   GTokenRule(`E, [GIntToken()], fn (result) :
     result[0])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative, fn (result) :
     qquote($plus ~(result[0]), ~(result[2])))
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative, fn (result) :
     qquote($times ~(result[0]), ~(result[2])))]  

deftest parse-exp-grammar :
  test-parse(exp-grammar(), reader/read-file("exp-test.txt"))

deftest action-exp-grammar :
  test-parse-action(exp-grammar(), reader/read-file("exp-test.txt"))

defn rest-priority-grammar () :
  #for E in [ES E F A R] :
    val E = GProduction(`E)
  #for (X in [PLUS N],
        x in [+ N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
      
  [GTokenRule(`Start, [F GListEnd()])

   GTokenRule(`F, [E E], 100, LeftAssociative)
   
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   GTokenRule(`E, [E R], 0)
   GTokenRule(`E, [N])

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]

deftest parse-rest-priority-grammar :
  val g = rest-priority-grammar()
  test-parse(g, `(N + N + N N + N))