#use-added-syntax(tests)
defpackage stz/earley :
  import core
  import collections
  import stz/utils

;============================================================
;====================== Definitions =========================
;============================================================

deftype GRule
defmulti name (r:GRule) -> Symbol
defmulti sub-name (r:GRule, name:Symbol) -> GRule

defstruct GNegationRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  token: GToken

defstruct GMatcherRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  tokens: Tuple<GToken>
  matcher: ? -> True|False
  priority: Int with: (default => 100)

defstruct GTokenRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  tokens: Tuple<GToken>
  priority: Int with: (default => 100)
  associativity: Associativity with: (default => RightAssociative)
  reluctant?: True|False with: (default => false)

defenum Associativity :
  LeftAssociative
  RightAssociative

deftype GToken <: Equalable & Hashable & Comparable<GToken>
defstruct GProduction <: GToken :
  name: Symbol
defstruct GKeyword <: GToken :
  item: Symbol
defstruct GListStart <: GToken
defstruct GListEnd <: GToken
defstruct GAny <: GToken :
  atomic?: True|False with: (default => false)
defstruct GListRest <: GToken

defstruct EItem :
  rule:Int
  num-parsed:Int
  parent:Int
  passed-guard?:True|False with: (default => true, updater => sub-passed-guard?)
  completion-root:EItem|False with: (init => false, updater => sub-completion-root)  

defstruct ParseNode :
  rule: Int
  start: Int
  end: Int
  children: Tuple<ParseNode>

;============================================================
;======================== Equalable =========================
;============================================================

defmethod equal? (a:GToken, b:GToken) :
  match(a, b) :
    (a:GKeyword, b:GKeyword) : item(a) == item(b)
    (a:GProduction, b:GProduction) : name(a) == name(b)
    (a:GListStart, b:GListStart) : true
    (a:GListEnd, b:GListEnd) : true
    (a:GAny, b:GAny) : atomic?(a) == atomic?(b)
    (a:GListRest, b:GListRest) : true
    (a, b) : false

defmethod hash (t:GToken) :
  match(t) :
    (t:GKeyword) : 1 + hash(item(t))
    (t:GProduction) : 2 + hash(name(t))
    (t:GListStart) : 3
    (t:GListEnd) : 4
    (t:GAny) : 5 + hash(atomic?(t))
    (t:GListRest) : 6

defmethod compare (a:GToken, b:GToken) :
  defn rank (t:GToken) :
    match(t) :
      (t:GKeyword) : 0
      (t:GProduction) : 1
      (t:GListStart) : 2
      (t:GListEnd) : 3
      (t:GAny) : 4
      (t:GListRest) : 5
  defn compare-token (a:GToken, b:GToken) :
    match(a, b) :
      (a:GProduction, b:GProduction) : compare(name(a), name(b))
      (a:GKeyword, b:GKeyword) : compare(item(a), item(b))
      (a:GAny, b:GAny) : compare(to-int(atomic?(a)), to-int(atomic?(b)))
      (a, b) : 0
  defn to-int (b:True|False) :
    1 when b else 0
  val c = compare(rank(a), rank(b))
  if c == 0 : compare-token(a,b)
  else : c

;============================================================
;======================= Printers ===========================
;============================================================

defmethod print (o:OutputStream, t:GToken) :
  print{o, _} $ match(t) :
    (t:GProduction) : name(t)
    (t:GKeyword) : item(t)
    (t:GListStart) : "("
    (t:GListEnd) : ")"
    (t:GAny) : "_"
    (t:GListRest) : "_ ..."

defmethod print (o:OutputStream, r:GRule) :
  print{o, _} $ match(r) :
    (r:GTokenRule) : "%_ = %s" % [name(r), tokens(r)]
    (r:GMatcherRule) : "%_ = custom matcher" % [name(r)]
    (r:GNegationRule) : "%_ != %_" % [name(r), token(r)]

;============================================================
;======================== Utilities =========================
;============================================================

defn add<?K,?V> (table:Table<?K,List<?V>>, k:K, v:V) :
  update(table, cons{v, _,}, k)

defn wrap (token, info:FileInfo|False) :
  match(info:FileInfo) : Token(token, info)
  else : token

defn inc-num-parsed (x:EItem) :
  EItem(rule(x), num-parsed(x) + 1, parent(x))

defn upcoming (grammar:Grammar, item:EItem) -> GToken|False :
  val ts = tokens!(grammar[rule(item)])
  val i = num-parsed(item)
  ts[i] when i < length(ts)

defn previous (grammar:Grammar, item:EItem) -> GToken|False :
  val ts = tokens!(grammar[rule(item)])
  val i = num-parsed(item)
  ts[i - 1] when i > 0
  
defn production (grammar:Grammar, item:EItem) -> Symbol :
  name(grammar[rule(item)])

defn tokens! (rule:GRule) :
  tokens(rule as GMatcherRule|GTokenRule)

defn associativity (rule:GMatcherRule) :
  RightAssociative

;============================================================
;==================== Grammar Analysis ======================
;============================================================

deftype Grammar
defmulti get (g:Grammar, i:Int) -> GRule
defmulti nullable? (g:Grammar, production:Symbol) -> True|False
defmulti rules (g:Grammar, production:Symbol, next-input:SExpToken) -> Seqable<Int>

defn Grammar (input-rules:Tuple<GRule>) :
  val rules = convert-negation-rules(input-rules)
  val [null-table, null-rules, rule-fsets] = nullables-and-firstsets(rules)
  val null-rules-table = nullables-to-rule-table(rules, null-rules)
  ;val input-rule-table = input-to-rule-table(rules, null-rules-table, rule-fsets)
  val prod-rules-table = group-by(name{rules[_]}, 0 to length(rules))
  new Grammar :
    defmethod get (this, i:Int) :
      rules[i]
    defmethod nullable? (this, production:Symbol) :
      null-table[production]
    defmethod rules (this, production:Symbol, next-input:SExpToken) :
      prod-rules-table[production]
      ;match(unwrap-token(next-input)) :
      ;  (t:Symbol) :
      ;    cat(null-rules-table[production],
      ;        input-rule-table[[production, t]])
      ;  (t:EndOfInput) :
      ;    null-rules-table[production]
      ;  (t:InsertedInput) :
      ;    prod-rules-table[production]

defn input-to-rule-table (rules:Tuple<GRule>,
                          null-rules-table:HashTable<Symbol,List<Int>>,
                          rule-fsets:Tuple<Tuple<Symbol>>) ->
                          HashTable<[Symbol, Symbol],List<Int>> :
  ;Utility to subtract one set from another.
  val buffer = IntSet()
  defn minus (a:Collection<Int>, b:Collection<Int>) :
    add-all(buffer, a)
    for x in b do : remove(buffer,x)
    val result = to-list(buffer)
    clear(buffer)
    result

  ;Compute [prod, input-terminal] => (rules ...) table.
  val table = group-by{key, value, _} $
    for (rule in rules, rule-index in 0 to false) seq-cat :
      for terminal in rule-fsets[rule-index] seq :
        [name(rule), terminal] => rule-index

  ;Remove all rules that are already accounted for by null table.
  for entry in table map! :
    val [prod, input] = key(entry)
    value(entry) - null-rules-table[prod]

  ;Return final table
  table

defn nullables-to-rule-table (rules:Tuple<GRule>, null-rules:Tuple<Int>) ->
                              HashTable<Symbol,List<Int>> :
  defn production (i:Int) : name(rules[i])
  group-by(production, null-rules)

defn nullables-and-firstsets (grammar:Tuple<GRule>) ->
                             [HashTable<Symbol,True|False>,
                              Tuple<Int>,
                              Tuple<Tuple<Symbol>>] :
  ;Compute parent rules that contain each production.
  val parent-table:HashTable<Symbol,List<Int>> = group-by{key, value, _} $
    for (rule in grammar, rule-index in 0 to false) seq-cat :
      match(rule:GMatcherRule|GTokenRule) :
        for prod in filter-by<GProduction>(tokens(rule)) seq :
          name(prod) => rule-index
      else :
        []

  ;Worklist algorithm
  defn worklist (f:(GRule, Symbol -> False) -> ?) :
    val queue = Queue<Int>()
    do(add{queue, _}, 0 to length(grammar))
    defn enqueue (prod:Symbol) :
      do(add{queue, _}, parent-table[prod])
    while not empty?(queue) :
      val rule = grammar[pop(queue)]
      f(rule, enqueue)

  ;Compute null table
  val null-table = HashTable<Symbol,True|False>(false)
  defn nullable? (t:GToken) :
    match(t) :
      (t:GProduction) : null-table[name(t)]
      (t:GListRest) : true
      (t) : false
  defn nullable? (rule:GRule) :
    match(rule:GMatcherRule|GTokenRule) :
      all?(nullable?, tokens(rule))
  within (rule, enqueue) = worklist() :
    if not null-table[name(rule)] and nullable?(rule) :
      null-table[name(rule)] = true
      enqueue(name(rule))

  ;;Compute first sets
  ;val fset-table = HashTable<Symbol,Tuple<Symbol>>([])
  ;defn first-sets (t:GToken) :
  ;  match(t) :
  ;    (t:GKeyword) : [item(t)]
  ;    (t:GProduction) : fset-table[name(t)]
  ;defn first-sets (rule:GRule) :
  ;  val terminals = Vector<Symbol>()
  ;  let loop (i:Int = 0) :
  ;    if i < length(tokens(rule)) :
  ;      val t = tokens(rule)[i]
  ;      add-all(terminals, first-sets(t))
  ;      loop(i + 1) when nullable?(t)
  ;  terminals
  ;within (rule, enqueue) = worklist() :
  ;  val fset = to-hashset<Symbol> $ fset-table[name(rule)]
  ;  val old-length = length(fset)
  ;  add-all(fset, first-sets(rule))
  ;  if length(fset) > old-length :
  ;    fset-table[name(rule)] = to-tuple(fset)
  ;    enqueue(name(rule))
  ;
  ;Compute null rules
  val null-rules = to-tuple $
    filter(nullable?{grammar[_]}, 0 to length(grammar))
  ;
  ;;Compute rule first sets
  ;val rule-fsets = for rule in grammar map :
  ;  to-tuple $ unique $ first-sets(rule)
  val rule-fsets = [[]]

  ;Return all tables
  [null-table, null-rules, rule-fsets]

defn nullable-productions (grammar:Tuple<GRule>) :
  val [null-table, null-rules, rule-fsets] = nullables-and-firstsets(grammar)
  to-hashset<Symbol> $ seq(key, filter(value, null-table))

;------------------------------------------------------------
;----------------- Negation Set Analysis --------------------
;------------------------------------------------------------

deftype KSet
defstruct KeywordSet <: KSet :
  keywords: Tuple<Symbol>
with:
  printer => true
  
defstruct ProdSet <: KSet :
  name: Symbol
with:
  printer => true
  
defstruct UnionSet <: KSet :
  sets: Tuple<KSet>
with:
  printer => true
  
defstruct MinusSet <: KSet :
  a: KSet
  b: KSet
with:
  printer => true

defn convert-negation-rules (rules:Tuple<GRule>) -> Tuple<GRule> :
  ;Gather positive and negative tokens
  val negative-table = HashTable<Symbol,List<GToken>>(List())
  val positive-table = HashTable<Symbol,List<GToken>>(List())
  for rule in rules do :
    match(rule) :
      (rule:GNegationRule) :
        add(negative-table, name(rule), token(rule))
      (rule:GTokenRule) :
        if length(tokens(rule)) == 1 :
          val t = tokens(rule)[0]
          match(t:GProduction|GKeyword) :
            add(positive-table, name(rule), t)
      (rule:GMatcherRule) :
        false
        
  ;Create initial kset table
  val kset-table = HashTable<Symbol,KSet>()
  defn to-kset (name:Symbol) :
    set?(kset-table, name, fn () :
      val psets = to-tuple $ seq(to-kset, positive-table[name])
      val nsets = to-tuple $ seq(to-kset, negative-table[name])
      MinusSet(UnionSet(psets), UnionSet(nsets)))
  defn to-kset (t:GToken) :
    match(t) :
      (t:GProduction) : to-kset(name(t))
      (t:GKeyword) : KeywordSet([item(t)])
      
  ;Simplify kset
  val simplified-kset-table = HashTable<Symbol,KeywordSet>()
  defn simplify (name:Symbol) :
    set?(simplified-kset-table, name, fn () :
      simplify(to-kset(name)))
  defn simplify (kset:KSet) -> KeywordSet :
    match(kset) :
      (kset:UnionSet) :
        val keywords = seq-cat(keywords{simplify(_)}, sets(kset))
        KeywordSet $ to-tuple $ to-hashset<Symbol>(keywords)
      (kset:MinusSet) :
        val symbols = to-hashset<Symbol>(keywords(simplify(a(kset))))
        do(remove{symbols, _}, keywords(simplify(b(kset))))
        KeywordSet $ to-tuple $ symbols
      (kset:KeywordSet) :
        kset
      (kset:ProdSet) :
        simplify(name(kset))

  ;Create matcher rule
  defn to-matcher-rules (prod:Symbol) :
    val neg-tokens = negative-table[prod]
    val keywords = seq-cat(keywords{simplify(to-kset(_))}, neg-tokens)
    val keyword-set = to-hashset<Symbol>(keywords)
    defn match? (form) :
      match(unwrap-token(form)) :
        (s:Symbol) : not keyword-set[s]
        (s) : true
    val new-rules = Vector<GRule>()
    val old-prod = gensym(prod)
    add(new-rules, GMatcherRule(prod, [GProduction(old-prod)], match?))
    for r in rules do :
      if name(r) == prod and r is-not GNegationRule :
        add(new-rules, sub-name(r, old-prod))
    new-rules

  ;Create matcher rules  
  val matcher-rules = seq-cat(to-matcher-rules, keys(negative-table))
  defn standard-rule? (r:GRule) : not key?(negative-table, name(r))
  val remaining-rules = filter(standard-rule?, rules[1 to false])
  to-tuple $ cat-all $ [
    [rules[0]]
     matcher-rules
     remaining-rules]

;============================================================
;======================== ESetList ==========================
;============================================================

deftype ESetList
defmulti add (l:ESetList, items:Seqable<EItem>) -> False
defmulti clear-markers (l:ESetList) -> False
defmulti items (return:EItem -> ?, l:ESetList, index:Int, production:Symbol, mark?:True|False) -> False
defmulti first-item (l:ESetList, index:Int, production:Symbol) -> EItem|False
defmulti sets (l:ESetList) -> Seqable<Seqable<EItem>>
defmulti length (l:ESetList) -> Int

defstruct EItemSet :
  start: Int
  length: Int

defn ESetList (grammar:Grammar) :
  val items = Vector<EItem>()
  val markers = Vector<Int>()
  val sets = Vector<EItemSet>()
  val buffer = Vector<EItem>()
  var current-marker:Int = 1

  defn production! (item:EItem) :
    name(upcoming(grammar,item) as GProduction)

  defn productions (return:EItem -> ?, start:Int, end:Int, production:Symbol) :
    let loop (i:Int = start) :
      if i < end :
        val item = items[i]
        if production!(item) == production :
          return(item)
          loop(i + 1)

  new ESetList :
    defmethod length (this) :
      length(sets)
    defmethod add (this, new-items:Seqable<EItem>) :
      add-all(buffer, new-items)
      qsort!(production!, buffer)
      add(sets, EItemSet(length(items), length(buffer)))
      add-all(items, buffer)
      lengthen(markers, length(items), 0)
      clear(buffer)
    defmethod items (return:EItem -> ?, this, index:Int, production:Symbol, mark?:True|False) :
      val eset = sets[index]
      val i = bsearch(production!, items, start(eset), start(eset) + length(eset), production)
      match(i:Int) :
        if mark? :
          if markers[i] != current-marker :
            productions(return, i, start(eset) + length(eset), production)
            markers[i] = current-marker
        else :
          productions(return, i, start(eset) + length(eset), production)
    defmethod first-item (this, index:Int, production:Symbol) :
      val eset = sets[index]
      val i = bsearch(production!, items, start(eset), start(eset) + length(eset), production)
      match(i:Int) : items[i]
    defmethod clear-markers (this) :
      current-marker = current-marker + 1
    defmethod sets (this) :
      for eset in sets seq :
        for i in 0 to length(eset) seq :
          items[start(eset) + i]

;Binary search:
;It returns i such that all items at index < i satisfy key(xs[i]) < v.
defn bsearch<?T> (key:T -> Comparable, xs:Vector<?T>, start:Int, end:Int, v:Comparable) -> Int|False :
  bsearch(xs, start, end, compare{key(_), v})

defn bsearch<?T> (xs:Vector<?T>, start:Int, end:Int, compare:T -> Int) -> Int|False :
  ;All items with index less than i are known to return -1 for compare.
  ;All items with index greater than j are known to return 0/1 for compare.
  let loop (i:Int = start, j:Int = end) :
    if i == j :
      i when i < end and compare(xs[i]) == 0
    else :
      val m = (i + j) / 2
      if compare(xs[m]) < 0 : loop(m + 1, j)
      else : loop(i, m)

defn bsearch<?T> (xs:Vector<?T>, compare:T -> Int) -> Int|False :
  bsearch(xs, 0, length(xs), compare)

;============================================================
;======================= ESet ===============================
;============================================================

deftype ESet <: Collection<EItem>
defmulti scanned-atomic? (s:ESet) -> True|False
defmulti all-reluctant? (s:ESet) -> True|False
defmulti any-expected? (s:ESet) -> True|False
defmulti wildcard-expected? (s:ESet) -> True|False
defmulti list-expected? (s:ESet) -> True|False
defmulti list-end-expected? (s:ESet) -> True|False
defmulti rest-expected? (s:ESet) -> True|False
defmulti add (s:ESet, item:EItem) -> False
defmulti clear (s:ESet, length:Int) -> False
defmulti length (s:ESet) -> Int
defmulti get (s:ESet, i:Int) -> EItem
defmulti map! (f:EItem -> EItem, s:ESet) -> False
defmulti remove! (f:EItem -> True|False, s:ESet) -> False

defn ESet (grammar:Grammar) :
  ;Accumulate items
  val items = Vector<EItem>()

  ;Track flags
  var wildcard-expected?: True|False = false
  var list-expected?: True|False = false
  var list-end-expected?: True|False = false
  var rest-expected?:True|False = false
  var any-expected?:True|False = false
  var all-reluctant?:True|False = true
  var scanned-atomic?:True|False = false
  defn process-flags (item:EItem) :
    val rule = grammar[rule(item)]
    val atomic-advance? = match(previous(grammar,item)) :
      (t:GAny) : atomic?(t)
      (t) : false      
    if atomic-advance? : scanned-atomic? = true      
    val reluctant-advance? = match(rule:GTokenRule) :
      num-parsed(item) == 1 and reluctant?(rule)
    if not reluctant-advance? : all-reluctant? = false
    if passed-guard?(item) :
      match(upcoming(grammar,item)) :
        (upcoming:GKeyword|GAny) :
          wildcard-expected? = true
          match(upcoming:GAny) :
            any-expected? = true
        (upcoming:GListStart) :
          list-expected? = true
        (upcoming:GListEnd) :
          list-end-expected? = true
        (upcoming:GListRest) :
          rest-expected? = true
        (upcoming) :
          false
    else :
      wildcard-expected? = true
      
  defn recompute-flags () :
    wildcard-expected? = false
    list-expected? = false
    list-end-expected? = false
    rest-expected? = false
    any-expected? = false
    all-reluctant? = true
    scanned-atomic? = false
    do(process-flags, items)

  ;Return set
  new ESet :
    defmethod get (this, i:Int) :
      items[i]
    defmethod scanned-atomic? (this) :
      scanned-atomic?
    defmethod all-reluctant? (this) :
      all-reluctant?
    defmethod any-expected? (this) :
      any-expected?
    defmethod wildcard-expected? (this) :
      wildcard-expected?
    defmethod list-expected? (this) :
      list-expected?
    defmethod list-end-expected? (this) :
      list-end-expected?
    defmethod rest-expected? (this) :
      rest-expected?
    defmethod clear (this, l:Int) :
      shorten(items, l)
      recompute-flags()
    defmethod add (this, item:EItem) :
      add(items, item)
      process-flags(item)
    defmethod length (this) :
      length(items)
    defmethod to-seq (this) :
      to-seq(items)
    defmethod map! (f:EItem -> EItem, this) :
      map!(f, items)
    defmethod remove! (f:EItem -> True|False, this) :
      remove-when(f, items)

defmethod do (f:EItem -> ?, eset:ESet) :
  val item-index = to-seq(0 to false)
  while peek(item-index) < length(eset) :
    f(eset[next(item-index)])

defn empty? (s:ESet) :
  length(s) == 0

;============================================================
;==================== Error Handling ========================
;============================================================

defstruct MissingInput :
  input
  set-index: Int
  info: FileInfo|False
  items: Tuple<EItem>

defstruct MissingInputError <: Exception :
  input
  info: FileInfo|False
  productions: Tuple<Symbol>
  upcoming: Tuple<GToken>

defstruct ParsingErrors <: Exception :
  errors: Tuple<Exception>

defn to-exception (g:Grammar, m:MissingInput) :
  ;Compute earliest completed productions
  defn completed? (item:EItem) :
    val tokens = tokens!(g[rule(item)])
    num-parsed(item) == length(tokens)
  val completed-productions = HashTable<Symbol,Int>(INT-MAX)
  for item in filter(completed?,items(m)) do :
    update(completed-productions, min{_, parent(item)}, production(g,item))

  ;Compute productions and upcoming
  val productions = HashSet<Symbol>()
  val upcoming-tokens = HashSet<GToken>()
  for item in items(m) do :
    if passed-guard?(item) :
      val production = production(g,item)    
      val include? = match(upcoming(g,item)) :
        (t:GKeyword|GAny|GListStart|GListEnd) :
          num-parsed(item) > 0 and
          completed-productions[production] > parent(item)
        (t:GProduction) :
          completed-productions[production] > parent(item)
        (t:False) :
          false
      if include? :
        add(productions, production)
        add(upcoming-tokens, upcoming(g, item) as GToken)

  ;Return error
  MissingInputError(input(m), info(m), to-tuple(productions), qsort(upcoming-tokens))

defn to-exception (g:Grammar, input-ms:Collection<MissingInput>) :  
  val ms = to-tuple(input-ms)
  defn first-in-chain? (i:Int) : i == 0 or set-index(ms[i - 1]) < set-index(ms[i]) - 1
  val es = seq(to-exception{g, ms[_]}, filter(first-in-chain?, 0 to length(ms)))
  ParsingErrors $ to-tuple $ es

defmethod print (o:OutputStream, e:MissingInputError) :
  val info-str = "" when info(e) is False else "%_: " % [info(e)]
  val input-str = match(input(e)) :
    (x:EndOfInput) : "end of input"
    (x:SExpForm) :
      match(unwrap-token(form(x))) :
        (f:Symbol) : "symbol '%~'" % [f]
        (f:List) : "list"
        (f) : "input '%~'" % [f]
    (x:SExpListEnd) : "end of list"
  defn token-str (t:GToken) :
    match(t) :
      (t:GProduction) : "a '%~' production" % [name(t)]
      (t:GKeyword) : "'%~'" % [item(t)]
      (t:GListStart) : "a list"
      (t:GListEnd) : "the end of the list"
      (t:GAny) : "a form"
  defn tokens-str (ts:Tuple<GToken>) :
    if length(ts) == 1 :
      token-str(ts[0])
    else :
      val but-last-t = ts[0 to length(ts) - 1]
      val last-t = ts[length(ts) - 1]
      "either %,, or %_" % [seq(token-str,but-last-t), token-str(last-t)]
  defn productions-str (names:Tuple<Symbol>) :
    tokens-str(map(GProduction,names))
  print(o, "%_Unexpected %_." % [info-str, input-str])
  if not empty?(productions(e)) :
    print(o, " Current parsing %_ and %_ is expected next." % [
      productions-str(productions(e)), tokens-str(upcoming(e))])

defmethod print (o:OutputStream, e:ParsingErrors) :
  print-all(o, join(errors(e), '\n'))

;============================================================
;============== ProductionTable/ProductionSet ===============
;============================================================

deftype ProductionTable<T>
defmulti get<?T> (t:ProductionTable<?T>, key:Symbol) -> T
defmulti set<?T> (t:ProductionTable<?T>, key:Symbol, v:T) -> False
defmulti clear (t:ProductionTable) -> False

defn ProductionTable<T> (default:T) :
  val table = HashTable<Symbol,T>(default)
  new ProductionTable<T> :
    defmethod get (this, key:Symbol) : table[key]
    defmethod set (this, key:Symbol, v:T) : table[key] = v
    defmethod clear (this) : clear(table)

deftype ProductionSet
defmulti get (t:ProductionSet, key:Symbol) -> True|False
defmulti add (t:ProductionSet, key:Symbol) -> True|False
defmulti clear (t:ProductionSet) -> False

defn ProductionSet () :
  val keys = HashSet<Symbol>()
  new ProductionSet :
    defmethod get (this, key:Symbol) : keys[key]
    defmethod add (this, key:Symbol) : add(keys,key)
    defmethod clear (this) : clear(keys)

deftype CompletionSet
defmulti add (s:CompletionSet, item:EItem) -> True|False
defmulti get (s:CompletionSet, item:EItem) -> True|False
defmulti clear (s:CompletionSet) -> False

defn CompletionSet () :
  val keys = HashSet<[Int,Int,Int]>()
  new CompletionSet :
    defmethod add (this, item:EItem) :
      add(keys, [rule(item), num-parsed(item), parent(item)])
    defmethod get (this, item:EItem) :
      keys[[rule(item), num-parsed(item), parent(item)]]
    defmethod clear (this) :
      clear(keys)

;============================================================
;====================== Debugging ===========================
;============================================================

defn printable-stream (return:OutputStream -> ?) :
  new Printable :
    defmethod print (o:OutputStream, this) :
      return(o)

defn print-current-set (grammar:Grammar, set-index:Int, current-set:ESet) :
  println("Set %_" % [set-index])
  within indented() :
    do(println{format(grammar,_)}, current-set)

defn format (grammar:Grammar, e:EItem) :
  within o = printable-stream() :
    val r = grammar[rule(e)]
    print(o, "(rule %_) [%_ =" % [rule(e), name(r)])
    for (t in tokens!(r), i in 0 to false) do :
      val prefix = " • " when num-parsed(e) == i else " "
      print-all(o, [prefix, t])
    if num-parsed(e) == length(tokens!(r)) :
      print(o, " •")
    print(o, ", S%_]" % [parent(e)])
    if r is GMatcherRule :
      print(o, " (custom matcher)")
    if not passed-guard?(e) :
      print(o, " (unmatched)")
    if completion-root(e) is EItem :
      val msg = format(grammar, completion-root(e) as EItem)
      print(o, " (complete as %_)" % [msg])

defn format (grammar:Grammar, setlist:ESetList) :
  within o = printable-stream() :
    val o2 = IndentedStream(o)
    for (eset in sets(setlist), i in 0 to false) do :
      print(o, "\n") when i > 0
      print(o, "Set %_:" % [i])
      do(lnprint{o2, format(grammar,_)}, eset)

defn format (grammar:Grammar, eset:Vector<EItem>) :
  within o = printable-stream() :
    val o2 = IndentedStream(o)
    print(o, "ESet :")
    do(lnprint{o2, format(grammar,_)}, eset)

defn format (grammar:Grammar, r:ParsedRange) :
  "(rule %_) [%_ to %_] %_" % [rule(r), start(r), end(r), grammar[rule(r)]]

defn format (grammar:Grammar, node:ParseNode) :
  within o = printable-stream() :
    val rule = grammar[rule(node)]
    print(o, "[%_ to %_] %_" % [start(node), end(node), rule])
    val o2 = IndentedStream(o)
    do(lnprint{o2, format(grammar,_)}, children(node))

defn format (grammar:Grammar, p:EParent) :
  val parent-rule = grammar[rule(p)]
  val direct-str = " (direct)" when direct?(p) else ""
  "(rule %_) [%_ to ?] %_ (index %_) => %_%_" % [
    rule(p), start(p), parent-rule, index(p), format(grammar,child(p)), direct-str]

;============================================================
;=================== SExpression Stream =====================
;============================================================

deftype SExpStream
defmulti peek (s:SExpStream) -> SExpToken
defmulti advance (s:SExpStream, expand-list?:True|False) -> False
defmulti advance-rest (s:SExpStream) -> SExpTail
defmulti insert-wildcard (s:SExpStream) -> False
defmulti insert-list (s:SExpStream) -> False
defmulti info (s:SExpStream) -> FileInfo|False

deftype SExpToken
defstruct SExpForm <: SExpToken :
  form
  list:List
with:
  printer => true
defstruct SExpWildcard <: SExpToken
defstruct SExpListEnd <: SExpToken
defstruct EndOfInput <: SExpToken
defstruct SExpTail <: SExpToken :
  list
with:
  printer => true

defn SExpStream (input:List) :
  val stack = Vector<List>()
  var current:List|False = input
  var info:FileInfo|False = false

  defn update-info () :
    match(current:List) :
      if not empty?(current) :
        val t = head(current)
        match(t:Token) :
          info = /info(t)

  defn peek-stream () :
    match(current:List) :
      if empty?(current) : SExpListEnd()
      else :
        match(head(current)) :
          (t:SExpWildcard) : t
          (t) : SExpForm(t, current)
    else : EndOfInput()

  defn advance-stream (expand-list?:True|False) :
    fatal("No more tokens.") when current is False
    val curr = current as List
    if empty?(curr) :
      current = pop(stack) when not empty?(stack)
    else :
      val expand? = expand-list? and
                    unwrap-token(head(curr)) is List
      if expand? :
        add(stack, tail(curr))
        current = unwrap-token(head(curr)) as List
      else :
        current = tail(curr)
    update-info()

  update-info()
  new SExpStream :
    defmethod info (this) :
      info
    defmethod peek (this) :
      peek-stream()
    defmethod advance (this, expand-list?:True|False) :
      advance-stream(expand-list?)
    defmethod advance-rest (this) :
      val ret = SExpTail(current as List)
      current = List()
      ret
    defmethod insert-wildcard (this) :
      current = cons(SExpWildcard(), current as List)
    defmethod insert-list (this) :
      current = cons(List(), current as List)

;============================================================
;====================== RangeTable ==========================
;============================================================

deftype RangeTable
defmulti add (t:RangeTable, p:EParent) -> False
defmulti add (t:RangeTable, p:ECondParent) -> False
defmulti children (t:RangeTable, rule:Int, start:Int, index:Int, end:Int) -> List<EParent>
defmulti indirect-children (t:RangeTable, rule:Int, start:Int, index:Int, end:Int) -> List<EParent>
defmulti parent? (t:RangeTable, start:Int, production:Symbol) -> ECondParent|False
defmulti parents (t:RangeTable) -> Collection<EParent>
defmulti condparents (t:RangeTable) -> Collection<ECondParent>

defstruct EParent :
  rule: Int
  start: Int
  index: Int
  child: ParsedRange
  direct?: True|False
with:
  printer => true

defstruct ECondParent :
  rule: Int
  start: Int
  child-start: Int
  production: Symbol
with:
  printer => true

defstruct ParsedRange <: Equalable&Hashable :
  rule: Int
  start: Int
  end: Int
with:
  printer => true

defn RangeTable () :
  val children-table = HashTable<[Int, Int, Int, Int],List<EParent>>(List())
  val indirect-children-table = HashTable<[Int, Int, Int, Int],List<EParent>>(List())
  val parent-table = HashTable<[Int,Symbol],ECondParent>()
  new RangeTable :
    defmethod add (this, p:EParent) :
      val key = [rule(p), start(p), index(p), end(child(p))]
      val table = children-table when direct?(p) else indirect-children-table
      update(table, cons{p, _}, key)
      false
    defmethod add (this, p:ECondParent) :
      val key = [child-start(p), production(p)]
      fatal("Entry already exists.") when key?(parent-table, key)
      parent-table[key] = p
    defmethod children (this, rule:Int, start:Int, index:Int, end:Int) :
      children-table[[rule, start, index, end]]
    defmethod indirect-children (this, rule:Int, start:Int, index:Int, end:Int) :
      indirect-children-table[[rule, start, index, end]]
    defmethod parent? (this, start:Int, production:Symbol) :
      get?(parent-table, [start, production])
    defmethod parents (this) :
      within to-collection() :
        cat-all(values(children-table))
    defmethod condparents (this) :
      within to-collection() :
        to-seq(values(parent-table))

defmethod equal? (a:ParsedRange, b:ParsedRange) :
  rule(a) == rule(b) and
  start(a) == start(b) and
  end(a) == end(b)

defmethod hash (a:ParsedRange) :
  hash $ [rule(a), start(a), end(a)]

defn length (r:ParsedRange) :
  end(r) - start(r)

;============================================================
;====================== Algorithm ===========================
;============================================================

defn parse (grammar:Grammar, input:List) -> ParseNode|ParsingErrors :
  val setlist = ESetList(grammar)
  val prediction-set = ProductionSet()
  val completion-set = CompletionSet()
  val production-count = ProductionTable<Int>(0)
  val ranges = RangeTable()
  val inputlist = Vector<SExpToken>()
  val infolist = Vector<FileInfo|False>()
  val missing = Vector<MissingInput>()

  ;Returns true if the given terminal matches against the given input.
  defn matches-input? (t:GToken, input:SExpToken) :
    match(t, input) :
      (t:GKeyword|GAny, input:SExpWildcard) : true
      (t, input:SExpWildcard) : false
      (t:GKeyword, input:SExpForm) : unwrap-token(form(input)) == item(t)
      (t:GKeyword, input) : false
      (t:GAny, input:SExpForm) : atomic?(t) or unwrap-token(form(input)) is-not List
      (t:GAny, input) : false
      (t:GListStart, input:SExpForm) : unwrap-token(form(input)) is List
      (t:GListStart, input) : false
      (t:GListEnd, input:SExpListEnd) : true
      (t:GListEnd, input) : false

  ;Returns true if the upcoming input satisfies the matcher of the given rule.
  defn matches-input? (rule:GMatcherRule, input:SExpToken) :
    match(input) :
      (input:SExpWildcard) : true
      (input:SExpForm) : matcher(rule)(form(input))
      (input) : false

  ;Returns true if the starting rule has been completed
  defn process-set (set-index:Int,
                    current-set:ESet,
                    next-set:ESet,
                    next-input:SExpToken) -> True|False :
    ;Clear state
    clear-markers(setlist)
    clear(prediction-set)
    clear(completion-set)

    ;Track whether starting rule has been completed
    var start-completed = false

    ;Iterate through each item
    for item in current-set do :
      dispatch(item) where :
        defn* dispatch (item:EItem) :
          if passed-guard?(item) :
            match(upcoming(grammar,item)) :
              (t:GKeyword|GListStart|GListEnd|GAny) : upcoming-terminal(item, t)
              (p:GProduction) : upcoming-production(item, p)
              (f:False) : end-of-rule(item)
              (t:GListRest) : false
          else :
            test-match(item)
        defn test-match (item:EItem) :
          val rule = grammar[rule(item)] as GMatcherRule
          if matches-input?(rule, next-input) :
            add(current-set, sub-passed-guard?(item, true))
        defn add-completion (item:EItem) :
          add(current-set, item) when add(completion-set, item)
        defn upcoming-terminal (item:EItem, t:GKeyword|GListStart|GListEnd|GAny|GListRest) :
          if matches-input?(t, next-input) :
            add(next-set, inc-num-parsed(item))
        defn upcoming-production (item:EItem, t:GProduction) :
          add-completion(inc-num-parsed(item)) when nullable?(grammar, name(t))
          if add(prediction-set, name(t)) :
            for rule in rules(grammar, name(t), next-input) do :
              val passed-guard? = grammar[rule] is-not GMatcherRule
              add(current-set, EItem(rule, 0, set-index, passed-guard?))
        defn end-of-rule (completed-item:EItem) :
          if rule(completed-item) == 0 : start-completed = true
          val prod = production(grammar,completed-item)
          if parent(completed-item) < set-index :
            within item = items(setlist, parent(completed-item), prod, true) :
              val root = match(completion-root(item)) :
                (root:EItem) : root
                (f:False) : item
              add-completion(inc-num-parsed(root))

    ;Return whether the starting production has been completed.
    start-completed

  defn compute-completion-root (set-index:Int, current-set:ESet) :
    ;Compute count table
    clear(production-count)
    for item in current-set do :
      val t = upcoming(grammar,item)
      match(t:GProduction) :
        production-count[name(t)] = production-count[name(t)] + 1
    ;Determine whether deterministic reduction
    defn deterministic-reduction? (item:EItem) :
      val num-tokens = length(tokens!(grammar[rule(item)]))
      if num-parsed(item) == num-tokens - 1 :
        val t = upcoming(grammar,item)
        match(t:GProduction) : production-count[name(t)] == 1
    ;Compute completion
    defn complete (item:EItem) :
      if parent(item) < set-index :
        val pitem = first-item(setlist, parent(item), production(grammar,item))
        match(pitem:EItem) : completion-root(pitem)
    ;Compute completions of all deterministic reductions.
    for item in current-set map! :
      if deterministic-reduction?(item) :
        match(complete(item)) :
          (c:EItem) : sub-completion-root(item,c)
          (f:False) : sub-completion-root(item, item)
      else : item

  defn add-to-setlist (current-set:ESet) :
    defn prod? (e:EItem) : passed-guard?(e) and upcoming(grammar,e) is GProduction
    add(setlist, filter(prod?, current-set))

  defn record-completions (set-index:Int, current-set:ESet) :
    defn complete? (item:EItem) : upcoming(grammar,item) is False|GListRest
    for item in current-set do :
      if complete?(item) :
        val range = ParsedRange(rule(item), parent(item), set-index)
        within pitem = items(setlist, parent(item), production(grammar, item), false) :
          add(ranges, EParent(rule(pitem), parent(pitem), num-parsed(pitem), range, true))
          if completion-root(pitem) is-not False :
            val pitem = completion-root(pitem) as EItem
            add(ranges, EParent(rule(pitem), parent(pitem), num-parsed(pitem), range, false))
      else if completion-root(item) is-not False :
        val production = name(upcoming(grammar,item) as GProduction)
        add(ranges, ECondParent(rule(item), parent(item), set-index, production))

  defn record-missing-input (next-input, index:Int, info:FileInfo|False, eset:ESet) :
    add(missing, MissingInput(next-input, index, info, to-tuple(eset)))
      
  defn process-all-sets () :
    ;Initialize current-set and next-set.
    val current-set = ESet(grammar)
    val next-set = ESet(grammar)
    add(current-set, EItem(0, 0, 0))
    ;Initialize input stream
    val input-stream = SExpStream(input)
    ;Process sets until finished.
    let loop (set-index:Int = 0,
              current-set:ESet = current-set,
              next-set:ESet = next-set) :
      val next-input = peek(input-stream)
      val num-scanned = length(current-set)
      val start-completed = process-set(set-index, current-set, next-set, next-input)

      ;Utilities
      defn* accept-input (t:SExpToken) :
        ;Add matched input
        add(inputlist, t)
        add(infolist, info(input-stream))
        ;Debug
        ;print-current-set(grammar, set-index, current-set)
        ;Compute the completion root and add to the setlist
        compute-completion-root(set-index, current-set)
        add-to-setlist(current-set)
        ;Record all completed productions
        record-completions(set-index, current-set)
      defn* scan-next-set () :
        clear(current-set, 0)
        loop(set-index + 1, next-set, current-set)
      defn* scan-current-set-again () :
        clear(current-set, num-scanned)
        loop(set-index, current-set, next-set)
      defn* inc-num-parsed-when (f:GToken|False -> True|False) :
        clear(next-set, 0)
        for item in current-set do :        
          if passed-guard?(item) and f(upcoming(grammar,item)) :
            add(next-set, inc-num-parsed(item))
      defn scanned-list-start? (item:EItem) :
        previous(grammar,item) is GListStart

      ;Dispatch to different cases
      defn* dispatch () :
        if all-reluctant?(next-set) :
          if rest-expected?(current-set) : advance-rest-terminals()
          else if any-expected?(current-set) : advance-any-terminals()
          else if start-completed : finished-parse()
          else : unexpected-input()
        else if scanned-atomic?(next-set) : advance-atomic()
        else : advance-standard-terminals()
      defn* advance-rest-terminals () :
        inc-num-parsed-when({_ is GListRest})
        accept-input(advance-rest(input-stream))
        scan-next-set()
      defn* advance-any-terminals () :
        inc-num-parsed-when({_ is GAny})          
        accept-input(next-input)
        advance(input-stream, false)
        scan-next-set()
      defn* finished-parse () :
        accept-input(next-input)
      defn* advance-standard-terminals () :
        accept-input(next-input)
        advance(input-stream, true)
        scan-next-set()
      defn* advance-atomic () :
        accept-input(next-input)
        advance(input-stream, false)
        remove!(scanned-list-start?, next-set)
        scan-next-set()
      defn* unexpected-input () :
        record-missing-input(next-input, set-index, info(input-stream), current-set)
        if list-end-expected?(current-set) : advance(input-stream, false)          
        else if wildcard-expected?(current-set) : insert-wildcard(input-stream)
        else if list-expected?(current-set) : insert-list(input-stream)
        else : fatal("Unrecoverable")
        scan-current-set-again()

      ;Launch
      dispatch()

  ;Launch!
  defn main () :
    process-all-sets()
    if empty?(missing) :
      select-tree(grammar, ranges, length(setlist) - 1)
    else :
      to-exception(grammar, missing)

  main()  

;============================================================
;================ Selecting the Parse Tree ==================
;============================================================

defn select-tree (grammar:Grammar, ranges:RangeTable, ending-set:Int) -> ParseNode :
  ;Complete right recursive chains 
  val completed-right-recursive-chains = HashSet<ParsedRange>()
  defn complete-right-recursive-chain (r:ParsedRange) :
    if add(completed-right-recursive-chains, r) :
      val production = name(grammar[rule(r)])
      val parent = parent?(ranges, start(r), production)
      match(parent:ECondParent) :
        val last-index = length(tokens!(grammar[rule(parent)])) - 1
        add(ranges, EParent(rule(parent), start(parent), last-index, r, true))
        complete-right-recursive-chain(ParsedRange(rule(parent), start(parent), end(r)))

  defn lookup-child (rule:Int, start:Int, index:Int, end:Int, rightmost-child?:True|False) :
    ;Complete any outstanding right recursive chains
    if rightmost-child? :
      for c in indirect-children(ranges, rule, start, index, end) do :
        complete-right-recursive-chain(child(c))
    ;Find most specific child
    val cs = children(ranges, rule, start, index, end)
    if empty?(tail(cs)) : head(cs)
    else : minimum(cs, {compare-specificity(grammar, _, _) < 0})

  defn select-tokens (rule:Int,
                      start-position:Int,
                      end-position:Int) -> Tuple<ParseNode> :
    val grule = grammar[rule] as GMatcherRule|GTokenRule
    val children = Vector<ParseNode>()
    val last-index = length(tokens(grule)) - 1
    let loop (index:Int = last-index, end-position:Int = end-position) :
      if index >= 0 :
        match(tokens(grule)[index]) :
          (t:GKeyword|GListStart|GListEnd|GAny|GListRest) :
            loop(index - 1, end-position - 1)
          (t:GProduction) :              
            val child-edge = lookup-child(rule, start-position, index, end-position, index == last-index)
            add(children, select(child(child-edge)))
            loop(index - 1, start(child(child-edge)))
    reverse!(children)
    to-tuple(children)

  defn select (range:ParsedRange) -> ParseNode :
    val children = select-tokens(rule(range), start(range), end(range))
    ParseNode(rule(range), start(range), end(range), children)      

  ;Launch
  select(ParsedRange(0, 0, ending-set))  

;Return -1 if a should take priority over b during
;a right-to-left disambiguation sweep of the parse forest.
defn compare-specificity (grammar:Grammar, a:EParent, b:EParent) :
  val parent-rule = grammar[rule(a)] as GMatcherRule|GTokenRule
  val rule-a = grammar[rule(child(a))] as GMatcherRule|GTokenRule
  val rule-b = grammar[rule(child(b))] as GMatcherRule|GTokenRule
  defn compare-associativity () :
    switch(associativity(parent-rule)) :
      RightAssociative : compare(length(child(b)), length(child(a)))
      LeftAssociative : compare(length(child(a)), length(child(b)))
  defn compare-priority () :
    compare(priority(rule-b), priority(rule-a))
  defn compare-order () :
    compare(rule(child(a)), rule(child(b)))
  val c1 = compare-associativity()
  if c1 == 0 :
    val c2 = compare-priority()
    if c2 == 0 : compare-order()
    else : c2
  else : c1  

;============================================================
;======================= Test Case ==========================
;============================================================

defn test-parse (rules:Tuple<GRule>, input:List) :
  val g = Grammar(rules)
  match(parse(g, input)) :
    (n:ParseNode) : println(format(g,n))
    (e:ParsingErrors) : println(e)

defn example-grammar () :
  val E = GProduction(`E)
  val N = GKeyword(`N)
  val PLUS = GKeyword(`+)
  val TIMES = GKeyword(`x)
  val LPAREN = GKeyword(`L)
  val RPAREN = GKeyword(`R)
  [GTokenRule(`S, [E])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])]

deftest print-grammar :
  val g = example-grammar()
  do(println, g)

deftest parse :
  test-parse(example-grammar(), `(N x N x L N + N R x N x N + N x N x N))

defn example-grammar-2 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val B = GKeyword(`B)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [E E X])
   GTokenRule(`S, [F F Y])
   GTokenRule(`E, [A A B])
   GTokenRule(`F, [A A B])]

deftest parse-2 :
  val g = example-grammar-2()
  test-parse(g, `(A A B A A B Y))

defn example-grammar-3 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [E F X])
   GTokenRule(`S, [F E X])
   GTokenRule(`S, [F F F Y])
   GTokenRule(`E, [A A])
   GTokenRule(`F, [A])]

deftest parse-3 :
  val g = example-grammar-3()
  test-parse(g, `(A A A X))

defn example-grammar-4 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [E E X])
   GTokenRule(`E, [A])
   GTokenRule(`E, [A A])]

deftest parse-4 :
  val g = example-grammar-4()
  test-parse(g, `(A A A A X))

defn example-grammar-5 () :
  #for E in [ES, E, IF-E, SCLAUSES, SCLAUSE, ECLAUSE] :
    val E = GProduction(`E)
  #for (X in [PLUS, TIMES, LPAREN, RPAREN, N, EQ, LET, IN, IF, COLON, ELSE, SWITCH],
        x in [+, x, L, R, N, =, let, in, if, :, else, switch]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])
   GTokenRule(`E, [E EQ E])
   GTokenRule(`E, [LET E EQ E IN E])
   GTokenRule(`E, [IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE COLON E])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES ECLAUSE RPAREN])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES RPAREN])
   GTokenRule(`SCLAUSES, [SCLAUSE SCLAUSES])
   GTokenRule(`SCLAUSES, [])
   GTokenRule(`SCLAUSE, [E COLON E])
   GTokenRule(`ECLAUSE, [ELSE COLON E])]

deftest grammar-calc :
  Grammar(example-grammar-5())

deftest parse-5 :
  val g = example-grammar-5()
  test-parse(g, `(
    switch L
      N : N x N else
      N x N : N
      N + N : N + N +
      else : N x N
    R))

deftest parse-6 :
  test-parse(example-grammar-5(), reader/read-file("test.txt"))

defn example-grammar-6 () :
  #for E in [ES, E] :
    val E = GProduction(`E)
  #for (X in [A B C],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [ES])
   GTokenRule(`ES, [E, ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [A])
   GTokenRule(`E, [B C])]

deftest parse-7 :
  val g = example-grammar-6()
  test-parse(g, `(a a b c a a b c b c a a a a a a a a a a a a a a a a))

deftest parse-mutually-right-recursive :
  #for E in [AS BS CS A B C X] :
    val E = GProduction(`E)
  #for (X in [x a b c],
        x in [x a b c]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [X X X AS])
    GTokenRule(`AS, [A, X, BS])
    GTokenRule(`BS, [B, X, CS])
    GTokenRule(`CS, [X])
    GTokenRule(`CS, [C, X, AS])
    GTokenRule(`X, [x])
    GTokenRule(`A, [a])
    GTokenRule(`B, [b])
    GTokenRule(`C, [c])]
  test-parse(rules, `(x x x a x b x c x a x b x c x a x b x x))

deftest right-recursive-priority :
  #for E in [E A BS] :
    val E = GProduction(`E)
  #for (X in [a],
        x in [a]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [E])
    GTokenRule(`E, [A BS])
    GTokenRule(`E, [A A A A], 200)
    GTokenRule(`BS, [A BS])
    GTokenRule(`BS, [])
    GTokenRule(`A, [a])]
  test-parse(rules, `(a a a a))

defn example-null-grammar () :
  #for X in [S Ap E] :
    val X = GProduction(`X)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [Ap Ap Ap Ap])
   GTokenRule(`Ap, [A])
   GTokenRule(`Ap, [E])
   GTokenRule(`E, [])]

deftest parse-null :
  val g = example-null-grammar()
  test-parse(g, `(a a a))

defn example-tricky-null-grammar () :
  #for E in [S, A, B] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [w A d])
   GTokenRule(`S, [A d])
   GTokenRule(`S, [w B A A A d])
   GTokenRule(`A, [x])
   GTokenRule(`A, [])
   GTokenRule(`B, [x])]

deftest parse-tricky-null :
  val g = example-tricky-null-grammar()
  test-parse(g, `(w x x d))

defn example-tricky-null-grammar-2 () :
  #for E in [B S A] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [B])
   GTokenRule(`B, [S])
   GTokenRule(`B, [A])
   GTokenRule(`S, [w x A A A A d], 100, LeftAssociative)
   GTokenRule(`A, [w x])
   GTokenRule(`A, [])]

deftest parse-tricky-null-2 :
  val g = example-tricky-null-grammar-2()
  test-parse(g, `(w x w x d))

defn list-grammar () :
  #for E in [S, A, B, C, D, L, R, CD, CDs] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [A B CDs L CDs R CDs])
   GTokenRule(`S, [A B C])
   GTokenRule(`CDs, [CD, CDs])
   GTokenRule(`CDs, [])
   GTokenRule(`CD, [L C D R])
   GTokenRule(`A, [a])
   GTokenRule(`B, [b])
   GTokenRule(`C, [c])
   GTokenRule(`D, [d])
   GTokenRule(`L, [GListStart()])
   GTokenRule(`R, [GListEnd()])]

deftest parse-list :
  val g = list-grammar()
  test-parse(g, `(a b (c d) (c d) ((c d) (c d) (c d)) (c d)))

defn any-vs-list-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [done],
        x in [done]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [GAny() done])
   GTokenRule(`S, [GListStart() done GListEnd() done])]

deftest parse-any-vs-list :
  val g = any-vs-list-grammar()
  test-parse(g, `((done) done))

defn any-as-list-grammar () :
  #for E in [S A As Xs] :
    val E = GProduction(`E)
;  #for (X in [],
;        x in [a b c d]) :
;    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [Xs Xs])
   GTokenRule(`S, [A A])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [GListStart() As GListEnd()], 100, RightAssociative, true)
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`Xs, [GListStart() GKeyword(`x) GListEnd()])]

deftest parse-any-as-list :
  val g = any-as-list-grammar()
  test-parse(g, `((x) (x y z)))

defn list-recovery-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [a GListStart() b GListEnd() c])]

deftest parse-list-recovery :
  val g = list-recovery-grammar()
  test-parse(g, `(a b c))

defn rest-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [GListStart() a b c GListEnd()])
   GTokenRule(`S, [GListStart() a b GListRest() GListEnd()])]

deftest parse-rest :
  val g = rest-grammar()
  test-parse(g, `((a b d e f)))

defn full-any-grammar () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [LP a b LP c d As d RP RP])   
   GTokenRule(`S, [LP a b LP c d R RP RP])   
   GTokenRule(`S, [A])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP R RP], 100, RightAssociative, true)
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`R, [GAny() R], 100, RightAssociative, true)
   GTokenRule(`R, [LP R RP R], 100, RightAssociative, true)
   GTokenRule(`R, [GListRest()])]  

deftest parse-full-any-grammar :
  val g = full-any-grammar()
  test-parse(g, `((a b (c d x y z d))))

defn amb-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])]    

deftest parse-amb-grammar :
  val g = amb-grammar()
  test-parse(g, `(red red dog dog red dog dog dog))

defn amb-grammar-2 () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])]    

deftest parse-amb-grammar-2 :
  val g = amb-grammar-2()
  test-parse(g, `(red dog dog red dog dog red dog dog red dog dog red dog dog))

defn if-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [IF THEN ELSE N],
        x in [if then else N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [LP E RP])   
   GTokenRule(`E, [IF E THEN E], 100, LeftAssociative)      
   GTokenRule(`E, [IF E THEN E ELSE E], 100, LeftAssociative)
   GTokenRule(`E, [N])]    

deftest parse-if-grammar :
  val g = if-grammar()
  test-parse(g, `(if N then (if N then N) else N))

defn matcher-grammar () :
  #for E in [ES E Id BId RId] :
    val E = GProduction(`E)
  #for (X in [VAR EQ N DOT],
        x in [var = N .]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn prefix-symbol? (form, prefix:String) :
    match(unwrap-token(form)) :
      (f:Symbol) : prefix?(name(f), prefix)
      (f) : false
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [VAR Id EQ E])
   GTokenRule(`E, [N])
   GTokenRule(`Id, [BId DOT RId])
   GMatcherRule(`BId, [GAny()], prefix-symbol?{_, "B"})
   GMatcherRule(`RId, [GAny()], prefix-symbol?{_, "R"})]

deftest parse-matcher-grammar :
  val g = matcher-grammar()
  test-parse(g, `(var B10.R18 = N N))

deftest parse-matcher-grammar-error :
  val g = matcher-grammar()
  test-parse(g, `("hello world"))

defn core-form-grammar () :
  #for E in [ES E A R] :
    val E = GProduction(`E)
  #for (X in [CORE],
        x in [$core]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn core-form? (form) :
    match(unwrap-token(form)) :
      (f:List) : not empty?(f) and unwrap-token(head(f)) == `$core
      (f) : false
      
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [CORE])
   GTokenRule(`E, [LP ES RP])   
   GMatcherRule(`E, [GAny(true)], core-form?)

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP R RP], 100, RightAssociative, true)
   GTokenRule(`R, [GAny() R], 100, RightAssociative, true)
   GTokenRule(`R, [LP R RP R], 100, RightAssociative, true)
   GTokenRule(`R, [GListRest()])]

deftest parse-core-form-grammar :
  val g = core-form-grammar()
  test-parse(g, `($core ($core a b c d) $core))

deftest keyword-analysis :
  val rules = [
    GNegationRule(`E, GProduction(`core-keywords))
    GTokenRule(`core-keywords, [GKeyword(`defstruct)])
    GTokenRule(`core-keywords, [GKeyword(`deftype)])
    GTokenRule(`core-keywords, [GKeyword(`defn)])
    GTokenRule(`core-keywords, [GKeyword(`defmulti)])
    GTokenRule(`core-keywords, [GKeyword(`let)])
    GTokenRule(`jitpcb-keywords, [GKeyword(`esir)])
    GTokenRule(`jitpcb-keywords, [GKeyword(`pcb-component)])
    GTokenRule(`jitpcb-keywords, [GKeyword(`pcb-module)])
    GTokenRule(`jitpcb-keywords, [GKeyword(`pcb-bundle)])
    GTokenRule(`jitpcb-keywords, [GKeyword(`pcb-rules)])
    GTokenRule(`jitpcb-keywords, [GKeyword(`pcb-keyword)])
    GTokenRule(`jitpcb-keywords, [GKeyword(`pcb-esir)])
    GNegationRule(`jitpcb-keywords, GKeyword(`pcb-esir))
    GTokenRule(`core-keywords, [GProduction(`jitpcb-keywords)])]
  do(println, negation-table(rules))

defn exp-grammar () :
  #for E in [ES E ID] :
    val E = GProduction(`E)
  #for (X in [VAR VAL FOR LET IN EQ COLON PLUS TIMES N DO],
        x in [var val for let in = : + * N @do]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
      
  [GTokenRule(`Start, [ES GListEnd()])
  
   GTokenRule(`keywords, [VAR])     
   GTokenRule(`keywords, [VAL])     
   GTokenRule(`keywords, [FOR])     
   GTokenRule(`keywords, [LET])     
   GTokenRule(`keywords, [IN])
   GTokenRule(`keywords, [EQ])
   GTokenRule(`keywords, [COLON])
   GTokenRule(`keywords, [DO])

   GTokenRule(`ID, [GAny()])
   GNegationRule(`ID, GProduction(`keywords))
   
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   
   GTokenRule(`E, [VAR ID EQ E])
   GTokenRule(`E, [VAL ID EQ E])
   GTokenRule(`E, [FOR ID IN E COLON E])
   GTokenRule(`E, [LET ID EQ E COLON E])
   GTokenRule(`E, [E LP DO ES RP], 70, LeftAssociative)
   GTokenRule(`E, [LP ES RP])
   GTokenRule(`E, [N])
   GTokenRule(`E, [E PLUS E], 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], 80, LeftAssociative)]  

deftest parse-exp-grammar :
  test-parse(exp-grammar(), reader/read-file("exp-test.txt"))