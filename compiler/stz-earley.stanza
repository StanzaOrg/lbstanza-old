#use-added-syntax(tests)
defpackage stz/earley :
  import core
  import collections
  import stz/utils

;<doc>=======================================================
;========================= Notes ============================
;============================================================

Example Parsing Tables:

  Set 0
    (rule 0) [Start = • X X X AS, S0]
    (rule 5) [X = • x, S0]
  Set 1
    (rule 5) [X = x •, S0]
    (rule 0) [Start = X • X X AS, S0]
    (rule 5) [X = • x, S1]
  Set 2
    (rule 5) [X = x •, S1]
    (rule 0) [Start = X X • X AS, S0]
    (rule 5) [X = • x, S2]
  Set 3
    (rule 5) [X = x •, S2]
    (rule 0) [Start = X X X • AS, S0] (complete as (rule 0) [Start = X X X • AS, S0])
    (rule 1) [AS = • A X BS, S3]
    (rule 6) [A = • a, S3]
  Set 4
    (rule 6) [A = a •, S3]
    (rule 1) [AS = A • X BS, S3]
    (rule 5) [X = • x, S4]
  Set 5
    (rule 5) [X = x •, S4]
    (rule 1) [AS = A X • BS, S3] (complete as (rule 0) [Start = X X X • AS, S0])
    (rule 2) [BS = • B X CS, S5]
    (rule 7) [B = • b, S5]
  Set 6
    (rule 7) [B = b •, S5]
    (rule 2) [BS = B • X CS, S5]
    (rule 5) [X = • x, S6]
  Set 7
    (rule 5) [X = x •, S6]
    (rule 2) [BS = B X • CS, S5] (complete as (rule 0) [Start = X X X • AS, S0])
    (rule 4) [CS = • C X AS, S7]
    (rule 8) [C = • c, S7]
  ...

Explanation of One Set:

  Set 7
    (rule 5) [X = x •, S6]
    (rule 2) [BS = B X • CS, S5] (complete as (rule 0) [Start = X X X • AS, S0])
    (rule 4) [CS = • C X AS, S7]
    (rule 8) [C = • c, S7]

- 'Set 7' indicates that 7 terminals have been parsed thus
far.

- (rule 5) [X = x •, S6] indicates the progress of parsing rule 5,
  which was first started on Set 6, after parsing 6 terminals. 'x' was
  the terminal just parsed, and this rule is now completed, as
  evidenced by the dot at the end.

- (rule 2) [BS = B X • CS, S5]
  (complete as (rule 0) [Start = X X X • AS, S0])  
  indicates the progress of parsing rule 3, which was first started on
  Set 5. The completion rule says that when the last production for
  this rule (CS) is parsed, and this rule is completed, it will
  immediately result in the completion of a chain of other rules,
  ending eventually with the completion of rule 0 started on Set 0.  


;============================================================
;=======================================================<doc>

;============================================================
;====================== Definitions =========================
;============================================================

deftype GRule
defmulti name (r:GRule) -> Symbol
defmulti sub-name (r:GRule, name:Symbol) -> GRule

defstruct GNegationRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  token: GToken

defstruct GMatcherRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  tokens: Tuple<GToken>
  matcher: ? -> True|False
  failure: True|False with: (default => false)
  priority: Int with: (default => 100)
  action: ParsedResult -> ? with: (default => default-action)
  lazy-action?: True|False with: (default => false)

defstruct GTokenRule <: GRule :
  name: Symbol with: (as-method => true, updater => sub-name)
  tokens: Tuple<GToken>
  failure: True|False with: (default => false)
  priority: Int with: (default => 100)
  associativity: Associativity with: (default => RightAssociative)
  action: ParsedResult -> ? with: (default => default-action)
  lazy-action?: True|False with: (default => false)

defn GMatcherRule (name:Symbol, tokens:Tuple<GToken>, matcher:? -> True|False,
                   action:ParsedResult -> ?, lazy-action?:True|False) :
  GMatcherRule(name, tokens, matcher, false, 100, action, lazy-action?)

defn GMatcherRule (name:Symbol, tokens:Tuple<GToken>, matcher:? -> True|False,
                   action:ParsedResult -> ?) :
  GMatcherRule(name, tokens, matcher, action, false)

defn GTokenRule (name:Symbol,
                 tokens:Tuple<GToken>,
                 action:ParsedResult -> ?,
                 lazy-action?:True|False) :
  GTokenRule(name, tokens, false, 100, RightAssociative, action, lazy-action?)

defn GTokenRule (name:Symbol,
                 tokens:Tuple<GToken>,
                 action:ParsedResult -> ?) :
  GTokenRule(name, tokens, action, false)

defenum Associativity :
  LeftAssociative
  RightAssociative

deftype GToken <: Equalable & Hashable & Comparable<GToken>
defstruct GProduction <: GToken :
  name: Symbol
deftype GTerminal <: GToken
defstruct GKeyword <: GTerminal :
  item: Symbol
defstruct GCharToken <: GTerminal
defstruct GByteToken <: GTerminal
defstruct GIntToken <: GTerminal
defstruct GLongToken <: GTerminal
defstruct GFloatToken <: GTerminal
defstruct GDoubleToken <: GTerminal
defstruct GStringToken <: GTerminal
defstruct GSymbolToken <: GTerminal
defstruct GTrueToken <: GTerminal
defstruct GFalseToken <: GTerminal
  
defstruct GListStart <: GTerminal :
  reluctant?: True|False with: (default => false)
defstruct GListEnd <: GTerminal
defstruct GAny <: GTerminal :
  type: AnyType with: (default => Standard)
defstruct GListRest <: GTerminal

defenum AnyType :
  Atomic
  Reluctant
  Standard

defstruct EItem :
  rule:Int
  num-parsed:Int
  parent:Int
  passed-guard?:True|False with: (default => true, updater => sub-passed-guard?)
  completion-root:EItem|False with: (init => false, updater => sub-completion-root)  

defstruct ParseNode :
  range: ParsedRange
  children: Tuple<ParseNode|False>

deftype ParsedResult
defmulti get (r:ParsedResult, i:Int) -> ?
defmulti info (r:ParsedResult) -> FileInfo|False
defmulti form (r:ParsedResult) -> List
defn default-action (r:ParsedResult) : false

;============================================================
;======================== Equalable =========================
;============================================================

defmethod equal? (a:GToken, b:GToken) :
  match(a, b) :
    (a:GKeyword, b:GKeyword) : item(a) == item(b)
    (a:GCharToken, b:GCharToken) : true
    (a:GByteToken, b:GByteToken) : true
    (a:GIntToken, b:GIntToken) : true
    (a:GLongToken, b:GLongToken) : true
    (a:GFloatToken, b:GFloatToken) : true
    (a:GDoubleToken, b:GDoubleToken) : true
    (a:GStringToken, b:GStringToken) : true
    (a:GSymbolToken, b:GSymbolToken) : true
    (a:GTrueToken, b:GTrueToken) : true
    (a:GFalseToken, b:GFalseToken) : true
    (a:GProduction, b:GProduction) : name(a) == name(b)
    (a:GListStart, b:GListStart) : true
    (a:GListEnd, b:GListEnd) : true
    (a:GAny, b:GAny) : type(a) == type(b)
    (a:GListRest, b:GListRest) : true
    (a, b) : false

defmethod hash (t:GToken) :
  match(t) :
    (t:GKeyword) : 1 + hash(item(t))
    (t:GProduction) : 2 + hash(name(t))
    (t:GListStart) : 3
    (t:GListEnd) : 4
    (t:GAny) : 5 + hash(to-int(type(t)))
    (t:GListRest) : 6
    (t:GCharToken) : 7
    (t:GByteToken) : 8
    (t:GIntToken) : 9
    (t:GLongToken) : 10
    (t:GFloatToken) : 11
    (t:GDoubleToken) : 12
    (t:GStringToken) : 13
    (t:GSymbolToken) : 14
    (t:GTrueToken) : 15
    (t:GFalseToken) : 16

defmethod compare (a:GToken, b:GToken) :
  defn rank (t:GToken) :
    match(t) :
      (t:GKeyword) : 0
      (t:GProduction) : 1
      (t:GListStart) : 2
      (t:GListEnd) : 3
      (t:GAny) : 4
      (t:GListRest) : 5
      (t:GCharToken) : 6
      (t:GByteToken) : 7
      (t:GIntToken) : 8
      (t:GLongToken) : 9
      (t:GFloatToken) : 10
      (t:GDoubleToken) : 11
      (t:GStringToken) : 12
      (t:GSymbolToken) : 13
      (t:GTrueToken) : 14
      (t:GFalseToken) : 15
  defn compare-token (a:GToken, b:GToken) :
    match(a, b) :
      (a:GProduction, b:GProduction) : compare(name(a), name(b))
      (a:GKeyword, b:GKeyword) : compare(item(a), item(b))
      (a:GAny, b:GAny) : compare(to-int(type(a)), to-int(type(b)))
      (a, b) : 0
  val c = compare(rank(a), rank(b))
  if c == 0 : compare-token(a,b)
  else : c

;============================================================
;======================= Printers ===========================
;============================================================

defmethod print (o:OutputStream, t:GToken) :
  print{o, _} $ match(t) :
    (t:GProduction) : name(t)
    (t:GKeyword) : item(t)
    (t:GCharToken) : "Char"
    (t:GByteToken) : "Byte"
    (t:GIntToken) : "Int"
    (t:GLongToken) : "Long"
    (t:GFloatToken) : "Float"
    (t:GDoubleToken) : "Double"
    (t:GStringToken) : "String"
    (t:GSymbolToken) : "Symbol"
    (t:GTrueToken) : "True"
    (t:GFalseToken) : "False"
    (t:GListStart) : "("
    (t:GListEnd) : ")"
    (t:GAny) : "_"
    (t:GListRest) : "_ ..."

defmethod print (o:OutputStream, r:GRule) :
  print{o, _} $ match(r) :
    (r:GTokenRule) : "%_ = %s" % [name(r), tokens(r)]
    (r:GMatcherRule) : "%_ = custom matcher" % [name(r)]
    (r:GNegationRule) : "%_ != %_" % [name(r), token(r)]

;============================================================
;======================== Utilities =========================
;============================================================

defn add-all<?T> (q:Queue<?T>, xs:Seqable<T>) :
  do(add{q, _}, xs)

defn add<?K,?V> (table:Table<?K,List<?V>>, k:K, v:V) :
  update(table, cons{v, _,}, k)

defn wrap (token, info:FileInfo|False) :
  match(info:FileInfo) : Token(token, info)
  else : token

defn inc-num-parsed (x:EItem) :
  EItem(rule(x), num-parsed(x) + 1, parent(x))

defn upcoming (grammar:Grammar, item:EItem) -> GToken|False :
  val ts = tokens!(grammar[rule(item)])
  val i = num-parsed(item)
  ts[i] when i < length(ts)

defn previous (grammar:Grammar, item:EItem) -> GToken|False :
  val ts = tokens!(grammar[rule(item)])
  val i = num-parsed(item)
  ts[i - 1] when i > 0
  
defn production (grammar:Grammar, item:EItem) -> Symbol :
  name(grammar[rule(item)])

defn tokens! (rule:GRule) :
  tokens(rule as GMatcherRule|GTokenRule)

defn associativity (rule:GMatcherRule) :
  RightAssociative

;============================================================
;==================== Grammar Analysis ======================
;============================================================

deftype Grammar
defmulti get (g:Grammar, i:Int) -> GRule
defmulti nullable? (g:Grammar, production:Symbol) -> True|False
defmulti rules (g:Grammar, production:Symbol, next-input:SExpToken) -> Seqable<Int>
defmulti rules (g:Grammar, production:Symbol) -> Seqable<Int>

defn Grammar (input-rules:Tuple<GRule>) :
  val rules = convert-negation-rules(input-rules)
  val grammar-properties = analyze-grammar-properties(rules)
  val null-prods = nullable-productions(grammar-properties)
  val dispatch-sets = analyze-dispatch-sets(rules, grammar-properties)
  new Grammar :
    defmethod get (this, i:Int) :
      rules[i]
    defmethod nullable? (this, production:Symbol) :
      null-prods[production]
    defmethod rules (this, production:Symbol) :
      all-rules(dispatch-sets)[production]
    defmethod rules (this, production:Symbol, next-input:SExpToken) :
      match(next-input) :
        (input:SExpWildcard) :
          all-rules(dispatch-sets)[production]
        (input:SExpForm) :
          val x = unwrap-token(form(input))
          val obj-rules = match(x) :
            (x:Symbol) : keyword-rules(dispatch-sets)[[production, x]]
            (x) : List()
          val type-rules = match(x) :
            (x:Char) : char-rules(dispatch-sets)[production]
            (x:Byte) : byte-rules(dispatch-sets)[production]
            (x:Int) : int-rules(dispatch-sets)[production]
            (x:Long) : long-rules(dispatch-sets)[production]
            (x:Float) : float-rules(dispatch-sets)[production]
            (x:Double) : double-rules(dispatch-sets)[production]
            (x:String) : string-rules(dispatch-sets)[production]
            (x:True) : true-rules(dispatch-sets)[production]
            (x:False) : false-rules(dispatch-sets)[production]
            (x:Symbol) : symbol-rules(dispatch-sets)[production]
            (x:List) : list-rules(dispatch-sets)[production]
            (x) : List()
          cat-all $ [
            obj-rules,
            type-rules,
            any-rules(dispatch-sets)[production]
            null-rules(dispatch-sets)[production]]              
        (input:SExpListEnd) :
          cat(
            list-end-rules(dispatch-sets)[production]
            null-rules(dispatch-sets)[production])

;------------------------------------------------------------
;------------------ Grammar Properties ----------------------
;------------------------------------------------------------

defstruct GrammarProperties:
  nullable-productions: HashSet<Symbol>
  nullable-rules: IntSet
  first-sets: Tuple<Tuple<GTerminal>>

defn analyze-grammar-properties (grammar:Tuple<GMatcherRule|GTokenRule>) :
  ;Compute parent rules that contain each production.
  val parent-table:HashTable<Symbol,List<Int>> = group-by{key, value, _} $
    for (rule in grammar, rule-index in 0 to false) seq-cat :
      for prod in filter-by<GProduction>(tokens(rule)) seq :
        name(prod) => rule-index

  ;Production worklist algorithm
  defn worklist (f:(Int, GMatcherRule|GTokenRule, () -> False) -> ?) :
    val queue = Queue<Int>()
    add-all(queue, 0 to length(grammar))
    while not empty?(queue) :
      val rule-index = pop(queue)
      val rule = grammar[rule-index]
      var progress?:True|False = false
      defn progress () : progress? = true
      f(rule-index, rule, progress)
      if progress? :
        add-all(queue, parent-table[name(rule)])

  ;Compute nullable productions and rules
  val null-prods = HashSet<Symbol>()
  val null-rules = IntSet()
  defn nullable? (t:GToken) :
    match(t:GProduction) :
      null-prods[name(t)]
  defn nullable? (rule:GMatcherRule|GTokenRule) :
    all?(nullable?, tokens(rule))
  within (rule-index, rule, progress) = worklist() :
    if nullable?(rule) :
      add(null-rules, rule-index)
      progress() when add(null-prods, name(rule))

  ;Compute firstsets
  val first-set-entries = HashSet<KeyValue<Symbol,GTerminal>>()
  val first-set-table = HashTable<Symbol,List<GTerminal>>(List())  
  defn first-set (t:GToken) :
    match(t) :
      (t:GTerminal) : [t]
      (t:GProduction) : first-set-table[name(t)]
  defn first-set (rule:GMatcherRule|GTokenRule) :
    generate<GTerminal> :
      let loop (i:Int = 0) :
        if i < length(tokens(rule)) :
          val t = tokens(rule)[i]
          do(yield, first-set(t))
          loop(i + 1) when nullable?(t)
  within (rule-index, rule, progress) = worklist() :
    for t in first-set(rule) do :
      if add(first-set-entries, name(rule) => t) :
        add(first-set-table, name(rule), t)
        progress()
  val first-sets = for rule in grammar map :
    to-tuple $ unique $ first-set(rule)

  ;Return all properties
  GrammarProperties(
    null-prods,
    null-rules,
    first-sets)

;------------------------------------------------------------
;------------------ Dispatch Sets ---------------------------
;------------------------------------------------------------

defstruct DispatchSet :
  all-rules:HashTable<Symbol,List<Int>>
  null-rules:HashTable<Symbol,List<Int>>
  any-rules:HashTable<Symbol,List<Int>>
  list-end-rules:HashTable<Symbol,List<Int>>
  char-rules:HashTable<Symbol,List<Int>>
  byte-rules:HashTable<Symbol,List<Int>>
  int-rules:HashTable<Symbol,List<Int>>
  long-rules:HashTable<Symbol,List<Int>>
  float-rules:HashTable<Symbol,List<Int>>
  double-rules:HashTable<Symbol,List<Int>>
  string-rules:HashTable<Symbol,List<Int>>
  true-rules:HashTable<Symbol,List<Int>>
  false-rules:HashTable<Symbol,List<Int>>
  symbol-rules:HashTable<Symbol,List<Int>>
  list-rules:HashTable<Symbol,List<Int>>
  keyword-rules:HashTable<[Symbol,Symbol],List<Int>>

defn analyze-dispatch-sets (grammar:Tuple<GRule>, props:GrammarProperties) :
  ;Create rule sets
  val all-rules = HashTable<Symbol,List<Int>>(List())
  val null-rules = HashTable<Symbol,List<Int>>(List())
  val any-rules = HashTable<Symbol,List<Int>>(List())
  val list-end-rules = HashTable<Symbol,List<Int>>(List())
  val char-rules = HashTable<Symbol,List<Int>>(List())
  val byte-rules = HashTable<Symbol,List<Int>>(List())
  val int-rules = HashTable<Symbol,List<Int>>(List())
  val long-rules = HashTable<Symbol,List<Int>>(List())
  val float-rules = HashTable<Symbol,List<Int>>(List())
  val double-rules = HashTable<Symbol,List<Int>>(List())
  val string-rules = HashTable<Symbol,List<Int>>(List())
  val true-rules = HashTable<Symbol,List<Int>>(List())
  val false-rules = HashTable<Symbol,List<Int>>(List())
  val symbol-rules = HashTable<Symbol,List<Int>>(List())
  val list-rules = HashTable<Symbol,List<Int>>(List())
  val keyword-rules = HashTable<[Symbol,Symbol],List<Int>>(List())

  ;Add to rule sets
  for (rule in grammar, rule-index in 0 to false, fset in first-sets(props)) do :
    defn add-to-set (table:HashTable<Symbol,List<Int>>) :
      add(table, name(rule), rule-index)
    add-to-set(all-rules)
    if nullable-rules(props)[rule-index] :
      add-to-set(null-rules)
    for token in fset do :
      match(token) :
        (token:GAny|GListRest) : add-to-set(any-rules)
        (token:GListEnd) : add-to-set(list-end-rules)
        (token:GCharToken) : add-to-set(char-rules)
        (token:GByteToken) : add-to-set(byte-rules)
        (token:GIntToken) : add-to-set(int-rules)
        (token:GLongToken) : add-to-set(long-rules)
        (token:GFloatToken) : add-to-set(float-rules)
        (token:GDoubleToken) : add-to-set(double-rules)
        (token:GStringToken) : add-to-set(string-rules)
        (token:GTrueToken) : add-to-set(true-rules)
        (token:GFalseToken) : add-to-set(false-rules)
        (token:GSymbolToken) : add-to-set(symbol-rules)
        (token:GListStart) : add-to-set(list-rules)
        (token:GKeyword) : add(keyword-rules, [name(rule), item(token)], rule-index)

  ;Ensure subtraction relationships of sets
  val set-buffer = IntSet()
  defn minus (a:Seqable<Int>, b:Seqable<Int>) :
    add-all(set-buffer, b)
    val result = to-list $ filter({not set-buffer[_]}, a)
    clear(set-buffer)
    result
  defn subtract-map! (atable:HashTable<Symbol,List<Int>>,
                      btables:Collection<HashTable<Symbol,List<Int>>>) :
    for entry in atable map! :
      val prod = key(entry)
      val bset = seq-cat({_[prod]}, btables)
      value(entry) - bset
  defn subtract-map! (atable:HashTable<[Symbol,Symbol],List<Int>>,
                      btables:Collection<HashTable<Symbol,List<Int>>>) :
    for entry in atable map! :
      val [prod, _] = key(entry)
      val bset = seq-cat({_[prod]}, btables)
      value(entry) - bset  
  subtract-map!(keyword-rules, [symbol-rules, any-rules, null-rules])
  subtract-map!(char-rules, [any-rules, null-rules])
  subtract-map!(byte-rules, [any-rules, null-rules])
  subtract-map!(int-rules, [any-rules, null-rules])
  subtract-map!(long-rules, [any-rules, null-rules])
  subtract-map!(float-rules, [any-rules, null-rules])
  subtract-map!(double-rules, [any-rules, null-rules])
  subtract-map!(string-rules, [any-rules, null-rules])
  subtract-map!(true-rules, [any-rules, null-rules])
  subtract-map!(false-rules, [any-rules, null-rules])
  subtract-map!(symbol-rules, [any-rules, null-rules])
  subtract-map!(list-rules, [any-rules, null-rules])
  subtract-map!(list-end-rules, [null-rules])
  subtract-map!(any-rules, [null-rules])
  
  ;Return computed dispatch sets
  DispatchSet(
    all-rules
    null-rules
    any-rules
    list-end-rules
    char-rules
    byte-rules
    int-rules
    long-rules
    float-rules
    double-rules
    string-rules
    true-rules
    false-rules
    symbol-rules
    list-rules
    keyword-rules)

;------------------------------------------------------------
;----------------- Negation Set Analysis --------------------
;------------------------------------------------------------

deftype KSet
defstruct KeywordSet <: KSet :
  keywords: Tuple<Symbol>
with:
  printer => true
  
defstruct ProdSet <: KSet :
  name: Symbol
with:
  printer => true
  
defstruct UnionSet <: KSet :
  sets: Tuple<KSet>
with:
  printer => true
  
defstruct MinusSet <: KSet :
  a: KSet
  b: KSet
with:
  printer => true

defn convert-negation-rules (rules:Tuple<GRule>) -> Tuple<GMatcherRule|GTokenRule> :
  ;Gather positive and negative tokens
  val negative-table = HashTable<Symbol,List<GToken>>(List())
  val positive-table = HashTable<Symbol,List<GToken>>(List())
  for rule in rules do :
    match(rule) :
      (rule:GNegationRule) :
        add(negative-table, name(rule), token(rule))
      (rule:GTokenRule) :
        if length(tokens(rule)) == 1 :
          val t = tokens(rule)[0]
          add(positive-table, name(rule), t)
      (rule:GMatcherRule) :
        false
        
  ;Create initial kset table
  val kset-table = HashTable<Symbol,KSet>()
  defn to-kset (name:Symbol) :
    set?(kset-table, name, fn () :
      val psets = to-tuple $ seq(to-kset, positive-table[name])
      val nsets = to-tuple $ seq(to-kset, negative-table[name])
      MinusSet(UnionSet(psets), UnionSet(nsets)))
  defn to-kset (t:GToken) :
    match(t) :
      (t:GProduction) : to-kset(name(t))
      (t:GKeyword) : KeywordSet([item(t)])
      
  ;Simplify kset
  val simplified-kset-table = HashTable<Symbol,KeywordSet>()
  defn simplify (name:Symbol) :
    set?(simplified-kset-table, name, fn () :
      simplify(to-kset(name)))
  defn simplify (kset:KSet) -> KeywordSet :
    match(kset) :
      (kset:UnionSet) :
        val keywords = seq-cat(keywords{simplify(_)}, sets(kset))
        KeywordSet $ to-tuple $ to-hashset<Symbol>(keywords)
      (kset:MinusSet) :
        val symbols = to-hashset<Symbol>(keywords(simplify(a(kset))))
        do(remove{symbols, _}, keywords(simplify(b(kset))))
        KeywordSet $ to-tuple $ symbols
      (kset:KeywordSet) :
        kset
      (kset:ProdSet) :
        simplify(name(kset))

  ;Create matcher rule
  defn to-matcher-rules (prod:Symbol) :
    val neg-tokens = negative-table[prod]
    val keywords = seq-cat(keywords{simplify(to-kset(_))}, neg-tokens)
    val keyword-set = to-hashset<Symbol>(keywords)
    defn match? (form) :
      match(unwrap-token(form)) :
        (s:Symbol) : not keyword-set[s]
        (s) : true
    val new-rules = Vector<GRule>()
    val old-prod = gensym(prod)
    add(new-rules, GMatcherRule(prod, [GProduction(old-prod)], match?, fn (result) : result[0]))
    for r in rules do :
      if name(r) == prod and r is-not GNegationRule :
        add(new-rules, sub-name(r, old-prod))
    new-rules

  ;Create matcher rules  
  val matcher-rules = seq-cat(to-matcher-rules, keys(negative-table))
  defn standard-rule? (r:GRule) : not key?(negative-table, name(r))
  val remaining-rules = filter(standard-rule?, rules[1 to false])
  val new-rules = to-tuple $ cat-all $ [
    [rules[0]]
     matcher-rules
     remaining-rules]
  new-rules as Tuple<GMatcherRule|GTokenRule>

;============================================================
;======================== ESetList ==========================
;============================================================

deftype ESetList
defmulti add (l:ESetList, items:Seqable<EItem>) -> False
defmulti clear-markers (l:ESetList) -> False
defmulti items (return:EItem -> ?, l:ESetList, index:Int, production:Symbol, mark?:True|False) -> False
defmulti first-item (l:ESetList, index:Int, production:Symbol) -> EItem|False
defmulti sets (l:ESetList) -> Collection<EItemSet>
defmulti get (l:ESetList, i:Int) -> EItemSet
defmulti items (l:ESetList, s:EItemSet) -> Collection<EItem>
defmulti length (l:ESetList) -> Int

defstruct EItemSet :
  index: Int
  start: Int
  length: Int

defn ESetList (grammar:Grammar) :
  val items = Vector<EItem>()
  val markers = Vector<Int>()
  val sets = Vector<EItemSet>()
  val buffer = Vector<EItem>()
  var current-marker:Int = 1

  defn upcoming? (item:EItem) :
    match(upcoming(grammar,item)) :
      (g:GToken) : One(g)
      (g:False) : None()

  defn productions (return:EItem -> ?, start:Int, end:Int, production:Symbol) :
    val prod = One(GProduction(production))
    let loop (i:Int = start) :
      if i < end :
        val item = items[i]
        if upcoming?(item) == prod :
          return(item)
          loop(i + 1)

  new ESetList :
    defmethod length (this) :
      length(sets)
    defmethod add (this, new-items:Seqable<EItem>) :
      add-all(buffer, new-items)
      qsort!({upcoming?(_) as Comparable}, buffer)
      add(sets, EItemSet(length(sets), length(items), length(buffer)))
      add-all(items, buffer)
      lengthen(markers, length(items), 0)
      clear(buffer)
    defmethod items (return:EItem -> ?, this, index:Int, production:Symbol, mark?:True|False) :
      val eset = sets[index]
      val i = bsearch(upcoming?, items, start(eset), start(eset) + length(eset), One(GProduction(production)))
      match(i:Int) :
        if mark? :
          if markers[i] != current-marker :
            productions(return, i, start(eset) + length(eset), production)
            markers[i] = current-marker
        else :
          productions(return, i, start(eset) + length(eset), production)
    defmethod first-item (this, index:Int, production:Symbol) :
      val eset = sets[index]
      val i = bsearch(upcoming?, items, start(eset), start(eset) + length(eset), One(GProduction(production)))
      match(i:Int) : items[i]
    defmethod clear-markers (this) :
      current-marker = current-marker + 1
    defmethod sets (this) :
      sets
    defmethod get (this, i:Int) :
      sets[i]
    defmethod items (this, eset:EItemSet) :
      within to-collection() :
        val s = start(eset)
        for i in 0 to length(eset) seq :
          items[s + i]

;Binary search:
;It returns i such that all items at index < i satisfy key(xs[i]) < v.
defn bsearch<?T> (key:T -> Comparable, xs:Vector<?T>, start:Int, end:Int, v:Comparable) -> Int|False :
  bsearch(xs, start, end, compare{key(_), v})

defn bsearch<?T> (xs:Vector<?T>, start:Int, end:Int, compare:T -> Int) -> Int|False :
  ;All items with index less than i are known to return -1 for compare.
  ;All items with index greater than j are known to return 0/1 for compare.
  let loop (i:Int = start, j:Int = end) :
    if i == j :
      i when i < end and compare(xs[i]) == 0
    else :
      val m = (i + j) / 2
      if compare(xs[m]) < 0 : loop(m + 1, j)
      else : loop(i, m)

defn bsearch<?T> (xs:Vector<?T>, compare:T -> Int) -> Int|False :
  bsearch(xs, 0, length(xs), compare)

;============================================================
;==================== Error Handling ========================
;============================================================

defstruct MissingInput :
  input
  set-index: Int
  info: FileInfo|False
  items: Tuple<EItem>

defstruct MissingInputError <: Exception :
  input
  info: FileInfo|False
  productions: Tuple<Symbol>
  upcoming: Tuple<GToken>

defstruct ParsingErrors <: Exception :
  errors: Tuple<Exception>

defn to-exception (g:Grammar, m:MissingInput) :
  ;Compute earliest completed productions
  defn completed? (item:EItem) :
    val tokens = tokens!(g[rule(item)])
    num-parsed(item) == length(tokens)
  val completed-productions = HashTable<Symbol,Int>(INT-MAX)
  for item in filter(completed?,items(m)) do :
    update(completed-productions, min{_, parent(item)}, production(g,item))

  ;Compute productions and upcoming
  val productions = HashSet<Symbol>()
  val upcoming-tokens = HashSet<GToken>()
  for item in items(m) do :
    if passed-guard?(item) :
      val production = production(g,item)    
      val include? = match(upcoming(g,item)) :
        (t:GTerminal) :
          num-parsed(item) > 0 and
          completed-productions[production] > parent(item)
        (t:GProduction) :
          completed-productions[production] > parent(item)
        (t:False) :
          false
      if include? :
        add(productions, production)
        add(upcoming-tokens, upcoming(g, item) as GToken)

  ;Return error
  MissingInputError(input(m), info(m), to-tuple(productions), qsort(upcoming-tokens))

defn to-exception (g:Grammar, input-ms:Collection<MissingInput>) :  
  val ms = to-tuple(input-ms)
  defn first-in-chain? (i:Int) : i == 0 or set-index(ms[i - 1]) < set-index(ms[i]) - 1
  val es = seq(to-exception{g, ms[_]}, filter(first-in-chain?, 0 to length(ms)))
  ParsingErrors $ to-tuple $ es

defmethod print (o:OutputStream, e:MissingInputError) :
  val info-str = "" when info(e) is False else "%_: " % [info(e)]
  val input-str = match(input(e)) :
    (x:EndOfInput) : "end of input"
    (x:SExpForm) :
      match(unwrap-token(form(x))) :
        (f:Symbol) : "symbol '%~'" % [f]
        (f:List) : "list"
        (f) : "input '%~'" % [f]
    (x:SExpListEnd) : "end of list"
  defn token-str (t:GToken) :
    match(t) :
      (t:GProduction) : "a '%~' production" % [name(t)]
      (t:GKeyword) : "'%~'" % [item(t)]
      (t:GListStart) : "a list"
      (t:GListEnd) : "the end of the list"
      (t:GAny) : "a form"
      (t) : t
  defn tokens-str (ts:Tuple<GToken>) :
    if length(ts) == 1 :
      token-str(ts[0])
    else :
      val but-last-t = ts[0 to length(ts) - 1]
      val last-t = ts[length(ts) - 1]
      "either %,, or %_" % [seq(token-str,but-last-t), token-str(last-t)]
  defn productions-str (names:Tuple<Symbol>) :
    tokens-str(map(GProduction,names))
  print(o, "%_Unexpected %_." % [info-str, input-str])
  if not empty?(productions(e)) :
    print(o, " Current parsing %_ and %_ is expected next." % [
      productions-str(productions(e)), tokens-str(upcoming(e))])

defmethod print (o:OutputStream, e:ParsingErrors) :
  print(o, "Could not parse the given input:")
  val o2 = IndentedStream(o)
  do(lnprint{o2, _}, errors(e))

;============================================================
;============== ProductionTable/ProductionSet ===============
;============================================================

deftype ProductionTable<T>
defmulti get<?T> (t:ProductionTable<?T>, key:Symbol) -> T
defmulti set<?T> (t:ProductionTable<?T>, key:Symbol, v:T) -> False
defmulti clear (t:ProductionTable) -> False

defn ProductionTable<T> (default:T) :
  val table = HashTable<Symbol,T>(default)
  new ProductionTable<T> :
    defmethod get (this, key:Symbol) : table[key]
    defmethod set (this, key:Symbol, v:T) : table[key] = v
    defmethod clear (this) : clear(table)

deftype ProductionSet
defmulti get (t:ProductionSet, key:Symbol) -> True|False
defmulti add (t:ProductionSet, key:Symbol) -> True|False
defmulti clear (t:ProductionSet) -> False

defn ProductionSet () :
  val keys = HashSet<Symbol>()
  new ProductionSet :
    defmethod get (this, key:Symbol) : keys[key]
    defmethod add (this, key:Symbol) : add(keys,key)
    defmethod clear (this) : clear(keys)

deftype CompletionSet
defmulti add (s:CompletionSet, item:EItem) -> True|False
defmulti get (s:CompletionSet, item:EItem) -> True|False
defmulti clear (s:CompletionSet) -> False

defn CompletionSet () :
  val keys = HashSet<[Int,Int,Int]>()
  new CompletionSet :
    defmethod add (this, item:EItem) :
      add(keys, [rule(item), num-parsed(item), parent(item)])
    defmethod get (this, item:EItem) :
      keys[[rule(item), num-parsed(item), parent(item)]]
    defmethod clear (this) :
      clear(keys)

;============================================================
;====================== Debugging ===========================
;============================================================

defn printable-stream (return:OutputStream -> ?) :
  new Printable :
    defmethod print (o:OutputStream, this) :
      return(o)

defn print-current-set (grammar:Grammar, set-index:Int, current-set:ESet) :
  println("Set %_" % [set-index])
  within indented() :
    do(println{format(grammar,_)}, current-set)

defn format (grammar:Grammar, e:EItem) :
  within o = printable-stream() :
    val r = grammar[rule(e)]
    print(o, "(rule %_) [%_ =" % [rule(e), name(r)])
    for (t in tokens!(r), i in 0 to false) do :
      val prefix = " • " when num-parsed(e) == i else " "
      print-all(o, [prefix, t])
    if num-parsed(e) == length(tokens!(r)) :
      print(o, " •")
    print(o, ", S%_]" % [parent(e)])
    if r is GMatcherRule :
      print(o, " (custom matcher)")
    if not passed-guard?(e) :
      print(o, " (unmatched)")
    if completion-root(e) is EItem :
      val msg = format(grammar, completion-root(e) as EItem)
      print(o, " (complete as %_)" % [msg])

defn format (grammar:Grammar, setlist:ESetList) :
  within o = printable-stream() :
    val o2 = IndentedStream(o)
    for eset in sets(setlist) do :
      print(o, "\n") when index(eset) > 0
      print(o, "Set %_:" % [index(eset)])
      do(lnprint{o2, format(grammar,_)}, items(setlist,eset))

defn format (grammar:Grammar, eset:Vector<EItem>) :
  within o = printable-stream() :
    val o2 = IndentedStream(o)
    print(o, "ESet :")
    do(lnprint{o2, format(grammar,_)}, eset)

defn format (grammar:Grammar, r:ParsedRange) :
  "(rule %_) [%_ to %_] %_" % [rule(r), start(r), end(r), grammar[rule(r)]]

defn format (grammar:Grammar, node:ParseNode) :
  within o = printable-stream() :
    print(o, format(grammar, range(node)))
    val o2 = IndentedStream(o)
    do(lnprint{o2, format(grammar,_)}, filter-by<ParseNode>(children(node)))

defn format (grammar:Grammar, p:EParent) :
  val parent-rule = grammar[rule(p)]
  val direct-str = " (direct)" when direct?(p) else ""
  "(rule %_) [%_ to ?] %_ (index %_) => %_%_" % [
    rule(p), start(p), parent-rule, index(p), format(grammar,child(p)), direct-str]

;============================================================
;=================== SExpression Stream =====================
;============================================================

deftype SExpStream
defmulti peek (s:SExpStream) -> SExpToken
defmulti advance (s:SExpStream, expand-list?:True|False) -> False
defmulti advance-rest (s:SExpStream) -> False
defmulti insert-wildcard (s:SExpStream) -> False
defmulti insert-list (s:SExpStream) -> False
defmulti info (s:SExpStream) -> FileInfo|False

deftype SExpToken
defstruct SExpForm <: SExpToken :
  form
  list:List
with:
  printer => true
defstruct SExpWildcard <: SExpToken
defstruct SExpListEnd <: SExpToken
defstruct EndOfInput <: SExpToken

defn list (t:SExpListEnd) :
  List()

defn SExpStream (input:List) :
  val stack = Vector<List>()
  var current:List|False = input
  var info:FileInfo|False = false

  defn update-info () :
    match(current:List) :
      if not empty?(current) :
        val t = head(current)
        match(t:Token) :
          info = /info(t)

  defn peek-stream () :
    match(current:List) :
      if empty?(current) : SExpListEnd()
      else :
        match(head(current)) :
          (t:SExpWildcard) : t
          (t) : SExpForm(t, current)
    else : EndOfInput()

  defn advance-stream (expand-list?:True|False) :
    fatal("No more tokens.") when current is False
    val curr = current as List
    if empty?(curr) :
      current = pop(stack) when not empty?(stack)
    else :
      val expand? = expand-list? and
                    unwrap-token(head(curr)) is List
      if expand? :
        add(stack, tail(curr))
        current = unwrap-token(head(curr)) as List
      else :
        current = tail(curr)
    update-info()

  update-info()
  new SExpStream :
    defmethod info (this) :
      info
    defmethod peek (this) :
      peek-stream()
    defmethod advance (this, expand-list?:True|False) :
      advance-stream(expand-list?)
    defmethod advance-rest (this) :
      current = List()
    defmethod insert-wildcard (this) :
      current = cons(SExpWildcard(), current as List)
    defmethod insert-list (this) :
      current = cons(List(), current as List)

;============================================================
;====================== RangeTable ==========================
;============================================================

deftype RangeTable
defmulti add (t:RangeTable, p:EParent) -> False
defmulti add (t:RangeTable, p:ECondParent) -> False
defmulti children (t:RangeTable, rule:Int, start:Int, index:Int, end:Int) -> List<EParent>
defmulti indirect-children (t:RangeTable, rule:Int, start:Int, index:Int, end:Int) -> List<EParent>
defmulti parent? (t:RangeTable, start:Int, production:Symbol) -> ECondParent|False
defmulti parents (t:RangeTable) -> Collection<EParent>
defmulti condparents (t:RangeTable) -> Collection<ECondParent>

defstruct EParent :
  rule: Int
  start: Int
  index: Int
  child: ParsedRange
  direct?: True|False
with:
  printer => true

defstruct ECondParent :
  rule: Int
  start: Int
  child-start: Int
  production: Symbol
with:
  printer => true

defstruct ParsedRange <: Equalable&Hashable :
  rule: Int
  start: Int
  end: Int
with:
  printer => true

defn RangeTable () :
  val children-table = HashTable<[Int, Int, Int, Int],List<EParent>>(List())
  val indirect-children-table = HashTable<[Int, Int, Int, Int],List<EParent>>(List())
  val parent-table = HashTable<[Int,Symbol],ECondParent>()
  new RangeTable :
    defmethod add (this, p:EParent) :
      val key = [rule(p), start(p), index(p), end(child(p))]
      val table = children-table when direct?(p) else indirect-children-table
      add(table, key, p)
      false
    defmethod add (this, p:ECondParent) :
      val key = [child-start(p), production(p)]
      fatal("Entry already exists.") when key?(parent-table, key)
      parent-table[key] = p
    defmethod children (this, rule:Int, start:Int, index:Int, end:Int) :
      children-table[[rule, start, index, end]]
    defmethod indirect-children (this, rule:Int, start:Int, index:Int, end:Int) :
      indirect-children-table[[rule, start, index, end]]
    defmethod parent? (this, start:Int, production:Symbol) :
      get?(parent-table, [start, production])
    defmethod parents (this) :
      within to-collection() :
        cat-all(values(children-table))
    defmethod condparents (this) :
      within to-collection() :
        to-seq(values(parent-table))

defmethod equal? (a:ParsedRange, b:ParsedRange) :
  rule(a) == rule(b) and
  start(a) == start(b) and
  end(a) == end(b)

defmethod hash (a:ParsedRange) :
  hash(rule(a)) + 7 * hash(start(a)) + 11 * hash(end(a))

defn length (r:ParsedRange) :
  end(r) - start(r)

;============================================================
;===================== ChildrenTable ========================
;============================================================
deftype ChildrenTable
defmulti add (t:ChildrenTable, parent:ParsedRange, index:Int, child:ParsedRange) -> False
defmulti get (t:ChildrenTable, parent:ParsedRange, index:Int, start:Int) -> List<ParsedRange>
defmulti start (t:ChildrenTable) -> ParsedRange
defmulti format (grammar:Grammar, t:ChildrenTable) -> Printable

defn ChildrenTable (start-range:ParsedRange) :
  val table = HashTable<RangeKey, List<ParsedRange>>(List())
  new ChildrenTable :
    defmethod start (this) :
      start-range
    defmethod add (this, parent:ParsedRange, index:Int, child:ParsedRange) :
      val k = RangeKey(parent, index, start(child))
      add(table, k, child)
      false
    defmethod get (this, parent:ParsedRange, index:Int, start:Int) :
      table[RangeKey(parent,index,start)]
    defmethod format (grammar:Grammar, this) :
      within o = printable-stream() :
        val o2 = IndentedStream(o)
        for (entry in table, i in 0 to false) do :
          val k = key(entry)
          print(o, '\n') when i > 0
          print(o, "%_ (index %_, start %_) =>" % [format(grammar, range(k)), index(k), child-start(k)])
          for c in value(entry) do :
            lnprint(o2, format(grammar,c))

defstruct RangeKey <: Hashable & Equalable :
  range: ParsedRange
  index: Int
  child-start: Int

defmethod hash (r:RangeKey) :
  hash(range(r)) + 7 * index(r) + 11 * child-start(r)
  
defmethod equal? (a:RangeKey, b:RangeKey) :
  range(a) == range(b) and
  index(a) == index(b) and
  child-start(a) == child-start(b)

;============================================================
;======================= ESet ===============================
;============================================================

deftype ESet <: Collection<EItem>
defmulti start-completed? (s:ESet) -> True|False
defmulti scanned-any? (s:ESet) -> True|False
defmulti scanned-atomic-any? (s:ESet) -> True|False
defmulti scanned-non-reluctant? (s:ESet) -> True|False
defmulti scanned-non-reluctant-list-start? (s:ESet) -> True|False
defmulti scanned-rest? (s:ESet) -> True|False
defmulti wildcard-expected? (s:ESet) -> True|False
defmulti list-expected? (s:ESet) -> True|False
defmulti list-end-expected? (s:ESet) -> True|False
defmulti add (s:ESet, item:EItem) -> False
defmulti clear (s:ESet, length:Int) -> False
defmulti length (s:ESet) -> Int
defmulti get (s:ESet, i:Int) -> EItem
defmulti map! (f:EItem -> EItem, s:ESet) -> False
defmulti remove! (f:EItem -> True|False, s:ESet) -> False

defn ESet (grammar:Grammar) :
  ;Accumulate items
  val items = Vector<EItem>()

  ;Track flags
  var start-completed?:True|False
  var scanned-any?:True|False
  var scanned-atomic-any?:True|False
  var scanned-non-reluctant?:True|False
  var scanned-non-reluctant-list-start?:True|False
  var scanned-rest?:True|False
  var wildcard-expected?: True|False
  var list-expected?: True|False
  var list-end-expected?: True|False
  
  defn recompute-flags () :
    start-completed? = false
    scanned-any? = false
    scanned-atomic-any? = false
    scanned-non-reluctant? = false
    scanned-non-reluctant-list-start? = false
    scanned-rest? = false
    wildcard-expected? = false
    list-expected? = false
    list-end-expected? = false
    do(process-flags, items)

  defn process-flags (item:EItem) :
    ;Set flags for what was scanned.
    val prev-item = previous(grammar,item)
    match(prev-item) :
      (t:GAny) :
        scanned-any? = true
        if type(t) is Atomic : scanned-atomic-any? = true
      (t:GListStart) :
        if not reluctant?(t) :
          scanned-non-reluctant-list-start? = true
      (t:GListRest) :
        scanned-rest? = true      
      (t) :
        false

    ;Process scanned non-reluctant flag
    if non-reluctant-terminal?(prev-item) :
      scanned-non-reluctant? = true
        
    ;Set flags for what is upcoming
    match(upcoming(grammar,item)) :
      (t:GListStart) :
        list-expected? = true
      (t:GListEnd) :
        list-end-expected? = true
      (t:GTerminal) :
        wildcard-expected? = true
      (t:False) :        
        if rule(item) == 0 : start-completed? = true
      (t) :
        false

  recompute-flags()
  new ESet :
    defmethod clear (this, l:Int) :
      shorten(items, l)
      recompute-flags()
    defmethod add (this, item:EItem) :
      add(items, item)
      process-flags(item)
    defmethod get (this, i:Int) : items[i]
    defmethod length (this) : length(items)
    defmethod to-seq (this) : to-seq(items)
    defmethod map! (f:EItem -> EItem, this) : map!(f, items)
    defmethod remove! (f:EItem -> True|False, this) :
      remove-when(f, items)
      recompute-flags()
    ;Flags
    defmethod start-completed? (this) : start-completed?
    defmethod scanned-any? (this) : scanned-any?
    defmethod scanned-atomic-any? (this) : scanned-atomic-any?
    defmethod scanned-non-reluctant? (this) : scanned-non-reluctant?
    defmethod scanned-non-reluctant-list-start? (this) : scanned-non-reluctant-list-start?
    defmethod scanned-rest? (this) : scanned-rest?
    defmethod wildcard-expected? (this) : wildcard-expected?
    defmethod list-expected? (this) : list-expected?
    defmethod list-end-expected? (this) : list-end-expected?

defmethod do (f:EItem -> ?, eset:ESet) :
  val item-index = to-seq(0 to false)
  while peek(item-index) < length(eset) :
    f(eset[next(item-index)])

defn empty? (s:ESet) :
  length(s) == 0

;============================================================
;================= Matching Predicates ======================
;============================================================

;Returns true if the given token is a non-reluctant terminal.
defn non-reluctant-terminal? (t:GToken|False) :
  match(t) :
    (t:GProduction) : false
    (t:False) : false
    (t:GListRest) : false
    (t:GAny) : type(t) is-not Reluctant
    (t:GListStart) : not reluctant?(t)
    (t) : true

;Returns true if the given terminal matches against the given input.
defn matches-input? (t:GTerminal, input:SExpToken) :
  match(t, input) :
    ;Wildcard matching
    (t:GListStart|GListEnd, input:SExpWildcard) : false
    (t, input:SExpWildcard) : true
    ;Form matching
    (t:GKeyword, input:SExpForm) : unwrap-token(form(input)) == item(t)
    (t:GCharToken, input:SExpForm) : unwrap-token(form(input)) is Char
    (t:GByteToken, input:SExpForm) : unwrap-token(form(input)) is Byte
    (t:GIntToken, input:SExpForm) : unwrap-token(form(input)) is Int
    (t:GLongToken, input:SExpForm) : unwrap-token(form(input)) is Long
    (t:GFloatToken, input:SExpForm) : unwrap-token(form(input)) is Float
    (t:GDoubleToken, input:SExpForm) : unwrap-token(form(input)) is Double
    (t:GStringToken, input:SExpForm) : unwrap-token(form(input)) is String
    (t:GSymbolToken, input:SExpForm) : unwrap-token(form(input)) is Symbol
    (t:GTrueToken, input:SExpForm) : unwrap-token(form(input)) is True
    (t:GFalseToken, input:SExpForm) : unwrap-token(form(input)) is False
    (t:GListStart, input:SExpForm) : unwrap-token(form(input)) is List
    (t:GAny, input:SExpForm) : true
    (t:GListRest, input:SExpForm) : true
    (t, input:SExpForm) : false
    ;List end matching
    (t:GListEnd, input:SExpListEnd) : true
    (t, input:SExpListEnd) : false

;Returns true if the upcoming input satisfies the matcher of the given rule.
defn matches-input? (rule:GMatcherRule, input:SExpToken) :
  match(input) :
    (input:SExpWildcard) : true
    (input:SExpForm) : matcher(rule)(form(input))
    (input) : false

;============================================================
;====================== Algorithm ===========================
;============================================================

defstruct ParseResult :
  node: ParseNode
  grammar: Grammar
  inputlist: Vector<SExpToken>
  infolist: Vector<FileInfo|False>

defn parse-result (grammar:Grammar, input:List) -> ParseResult|ParsingErrors :
  val setlist = ESetList(grammar)
  val prediction-set = ProductionSet()
  val completion-set = CompletionSet()
  val production-count = ProductionTable<Int>(0)
  val ranges = RangeTable()
  val inputlist = Vector<SExpToken>()
  val infolist = Vector<FileInfo|False>()
  val missing = Vector<MissingInput>()

  ;Returns true if the starting rule has been completed
  defn process-set (set-index:Int,
                    current-set:ESet,
                    next-set:ESet,
                    next-input:SExpToken,
                    include-all-rules?:True|False) -> True|False :                    
    ;Clear state
    clear-markers(setlist)
    clear(prediction-set)
    clear(completion-set)

    ;Iterate through each item
    for item in current-set do :
      dispatch(item) where :
        defn* dispatch (item:EItem) :
          if passed-guard?(item) :
            ;Dispatch
            match(upcoming(grammar,item)) :
              (t:GTerminal) : upcoming-terminal(item, t)
              (p:GProduction) : upcoming-production(item, p)
              (f:False) : end-of-rule(item)
          else :
            test-guard(item)
        defn test-guard (item:EItem) :
          val rule = grammar[rule(item)] as GMatcherRule
          if matches-input?(rule, next-input) :
            add(current-set, sub-passed-guard?(item, true))
        defn add-completion (item:EItem) :
          add(current-set, item) when add(completion-set, item)
        defn upcoming-terminal (item:EItem, t:GTerminal) :
          if matches-input?(t, next-input) :
            add(next-set, inc-num-parsed(item))
        defn upcoming-production (item:EItem, t:GProduction) :
          if nullable?(grammar, name(t)) :
            add-completion(inc-num-parsed(item))          
          if add(prediction-set, name(t)) :
            val rules = rules(grammar, name(t)) when include-all-rules?
                   else rules(grammar, name(t), next-input)
            for rule in rules do :
              val passed-guard? = grammar[rule] is-not GMatcherRule
              add(current-set, EItem(rule, 0, set-index, passed-guard?))
        defn end-of-rule (completed-item:EItem) :
          val prod = production(grammar,completed-item)
          if parent(completed-item) < set-index :
            within item = items(setlist, parent(completed-item), prod, true) :
              val item* = inc-num-parsed(item)
              val completion* = match(completion-root(item)) :
                (root:EItem) :
                  if core(root) == core(item) : item*
                  else : sub-completion-root(inc-num-parsed(root), item*)
                (f:False) : item*
              add-completion(completion*)

  defn prune-conditional-matches (eset:ESet, input:SExpToken) -> True|False :
    ;Remove all items whose previous token satisfies f.
    defn remove-previous (f:GToken|False -> True|False) :
      remove!(f{previous(grammar, _)}, eset)

    ;Is the input a list?
    val input-is-list? = match(input:SExpForm) :
      unwrap-token(form(input)) is List

    ;Determine whether we have made any progress?
    if scanned-non-reluctant?(eset) :
      ;Determine whether we have conditional matches to take care of. This
      ;occurs if the input is a list and an ANY has been scanned.
      if input-is-list? and scanned-any?(eset) :
        ;If an atomic any has been scanned, then we do not want the
        ;list to be expanded, and all matches with LIST-START should
        ;be removed.
        if scanned-atomic-any?(eset) :
          remove-previous({_ is GListStart|GListRest})
          false
        ;If a non-reluctant list start has been scanned, then we do want
        ;the list to be expanded, and all matches with ANY should
        ;be removed.
        else if scanned-non-reluctant-list-start?(eset) :
          remove-previous({_ is GAny|GListRest})
          true
        ;Otherwise, we do not need the list to be expanded, and all
        ;matches with LIST-START should be removed.
        else :
          remove-previous({_ is GListStart|GListRest})
          false
      ;If we scanned a rest production, then we need to remove it, since
      ;we know that we have successfully scanned a non-reluctant terminal.
      else if scanned-rest?(eset) :
        remove-previous({_ is GListRest})
        true
      ;By default, we expand the list.
      else :
        true
    ;Otherwise, we have scanned only reluctant items, and
    ;they should all should be removed, except for rest.
    else :
      remove-previous({_ is-not GListRest})
      false

  defn compute-completion-root (set-index:Int, current-set:ESet) :
    ;Compute count table
    clear(production-count)
    for item in current-set do :
      val t = upcoming(grammar,item)
      match(t:GProduction) :
        production-count[name(t)] = production-count[name(t)] + 1
    ;Determine whether deterministic reduction
    defn deterministic-reduction? (item:EItem) :
      val num-tokens = length(tokens!(grammar[rule(item)]))
      if num-parsed(item) == num-tokens - 1 :
        val t = upcoming(grammar,item)
        match(t:GProduction) : production-count[name(t)] == 1
    ;Compute completion
    defn complete (item:EItem) :
      if parent(item) < set-index :
        val pitem = first-item(setlist, parent(item), production(grammar,item))
        match(pitem:EItem) : completion-root(pitem)
    ;Compute completions of all deterministic reductions.
    for item in current-set map! :
      if deterministic-reduction?(item) :
        match(complete(item)) :
          (c:EItem) : sub-completion-root(item, c)
          (f:False) : sub-completion-root(item, item)
      else : item

  defn add-to-setlist (current-set:ESet) :
    defn prod? (e:EItem) : passed-guard?(e); and upcoming(grammar,e) is GProduction|False
    add(setlist, filter(prod?, current-set))

  defn record-completions (set-index:Int, current-set:ESet) :
    defn complete? (item:EItem) : upcoming(grammar,item) is False
    for item in current-set do :
      if complete?(item) :
        val range = ParsedRange(rule(item), parent(item), set-index)
        within pitem = items(setlist, parent(item), production(grammar, item), false) :
          match(completion-root(pitem)) :
            (ritem:EItem) :
              add(ranges, EParent(rule(ritem), parent(ritem), num-parsed(ritem), range, false))
            (f:False) :
              add(ranges, EParent(rule(pitem), parent(pitem), num-parsed(pitem), range, true))
      else if completion-root(item) is-not False :
        val production = name(upcoming(grammar,item) as GProduction)
        add(ranges, ECondParent(rule(item), parent(item), set-index, production))

  defn record-missing-input (next-input, index:Int, info:FileInfo|False, eset:ESet) :
    add(missing, MissingInput(next-input, index, info, to-tuple(eset)))
      
  defn process-all-sets () :
    ;Initialize current-set and next-set.
    val current-set = ESet(grammar)
    val next-set = ESet(grammar)
    add(current-set, EItem(0, 0, 0))
    
    ;Initialize input stream
    val input-stream = SExpStream(input)
    
    ;Process sets until finished.
    let loop (set-index:Int = 0,
              current-set:ESet = current-set,
              next-set:ESet = next-set) :
      val next-input = peek(input-stream)
      val num-scanned = length(current-set)      
      process-set(set-index, current-set, next-set, next-input, false)
      val expand-list? = prune-conditional-matches(next-set, next-input)

      ;Utilities
      defn* record-current-set () :
        ;Add matched input
        add(inputlist, next-input)
        add(infolist, info(input-stream))
        ;Compute the completion root and add to the setlist
        compute-completion-root(set-index, current-set)
        ;Debug
        print-current-set(grammar, set-index, current-set)
        add-to-setlist(current-set)
        ;Record all completed productions
        ;record-completions(set-index, current-set)
      defn* scan-next-set () :
        clear(current-set, 0)
        loop(set-index + 1, next-set, current-set)
      defn* scan-current-set-again () :
        clear(current-set, num-scanned)
        loop(set-index, current-set, next-set)
      defn* compute-complete-current-set () :
        clear(current-set, num-scanned)
        process-set(set-index, current-set, next-set, next-input, true)

      ;Dispatch to different cases
      defn* dispatch () :
        if empty?(next-set) :
          if start-completed?(current-set) : finished-parse()
          else : unexpected-input()
        else if scanned-rest?(next-set) : advance-to-list-end()
        else : advance-one()
      defn* finished-parse () :
        record-current-set()
      defn* advance-to-list-end () :
        record-current-set()
        advance-rest(input-stream)
        scan-next-set()
      defn* advance-one () :
        record-current-set()
        advance(input-stream, expand-list?)
        scan-next-set()
      defn* unexpected-input () :
        compute-complete-current-set()
        record-missing-input(next-input, set-index, info(input-stream), current-set)
        if list-end-expected?(current-set) : advance(input-stream, false)          
        else if wildcard-expected?(current-set) : insert-wildcard(input-stream)
        else if list-expected?(current-set) : insert-list(input-stream)
        else : fatal("Unrecoverable")
        scan-current-set-again()

      ;Launch
      dispatch()

  ;Launch!
  defn main () :
    within with-timer("process all sets") :
      process-all-sets()
    if empty?(missing) :
      val parse-forest = ParseForest(grammar, setlist)
      val node = within with-timer("select tree") :
        select-tree(grammar, parse-forest)
      ParseResult(node, grammar, inputlist, infolist)
    else :
      to-exception(grammar, missing)    

  main()  

;============================================================
;================ Construct Parse Forest ====================
;============================================================

deftype ParseForest
defmulti get (f:ParseForest, r:ParsedRange, index:Int, position:Int) -> Seqable<ParsedRange>
defmulti start (f:ParseForest) -> ParsedRange

defstruct RulePos <: Hashable&Equalable :
  rule: Int
  num-parsed: Int
  rule-start: Int
  position: Int
with:
  printer => true

defstruct ProdPos <: Hashable&Equalable :
  production: Symbol
  position: Int

defstruct EItemCore <: Hashable&Equalable :
  rule: Int
  num-parsed: Int
  parent: Int

defn core (item:EItem) :
  EItemCore(rule(item), num-parsed(item), parent(item))

defn parts (k:EItemCore) : [rule(k), num-parsed(k), parent(k)]
defmethod equal? (a:EItemCore, b:EItemCore) : parts(a) == parts(b)
defmethod hash (k:EItemCore) : hash(parts(k))

val hash-timer = MillisecondTimer("Hash RulePos")
defn parts (k:RulePos) : [rule(k), num-parsed(k), rule-start(k), position(k)]
defmethod equal? (a:RulePos, b:RulePos) : parts(a) == parts(b)
defmethod hash (k:RulePos) :
  start(hash-timer)
  val result = hash(parts(k))
  stop(hash-timer)
  result

defn parts (k:ProdPos) : [production(k), position(k)]
defmethod equal? (a:ProdPos, b:ProdPos) : parts(a) == parts(b)
defmethod hash (k:ProdPos) : hash(parts(k))

defn ParseForest (grammar:Grammar, setlist:ESetList) :
  ;Construct tables
  val rule-positions = HashSet<RulePos>()
  defn fill-rule-positions () :
    for eset in sets(setlist) do :
      for item in items(setlist,eset) do :
        add(rule-positions, RulePos(rule(item), num-parsed(item), parent(item), index(eset)))
  println(hash-timer)      

  ;Compute right recursion chains
  val completion-chains = HashTable<EItemCore, List<EItem>>()
  val completion-chain-productions-table = HashTable<EItemCore,List<Symbol>>()
  defn completion-parent? (item:EItem) -> Maybe<EItem> :
    fatal("Illegal argument.") when upcoming(grammar,item) is-not False
    val parent = first-item(setlist, parent(item), production(grammar,item)) as EItem
    val root = completion-root(parent) as EItem
    if core(parent) == core(root) : None()
    else : One(inc-num-parsed(parent))
    
  defn completion-chain (item:EItem) :
    set?(completion-chains, core(item), fn () :
      val p = completion-parent?(item)
      val rest = List() when empty?(p) else completion-chain(value!(p))
      cons(item, rest))

  defn completion-chain-productions (item:EItem) :
    set?(completion-chain-productions-table, core(item), fn () :
      val p = completion-parent?(item)
      val rest = List() when empty?(p) else completion-chain-productions(value!(p))
      val prod = production(grammar,item)
      rest when contains?(rest,prod) else cons(prod,rest))    

  ;Collect completion chains
  val pending-completion-chains = Vector<List<EItem>>()
  val pending-completions = HashTable<ProdPos,Int>()
  defn add-pending-completion-chain (set-index:Int, root:EItem) :
    val chain = completion-chain(root)
    val chain-index = length(pending-completion-chains)
    add(pending-completion-chains, chain)    
    for prod in completion-chain-productions(root) do :
      val prodpos = ProdPos(prod, set-index)
      pending-completions[prodpos] = chain-index
  defn pending-chains (return:EItem -> ?, prodpos:ProdPos) -> False :
    val index = get?(pending-completions, prodpos)
    match(index:Int) :
      if not empty?(pending-completion-chains[index]) :
        within with-timer("Compute pending completion chain") :
          do(return, pending-completion-chains[index])
      pending-completion-chains[index] = List()
      remove(pending-completions, prodpos)
      false
  defn collect-pending-completion-chains () :
    for eset in sets(setlist) do :
      for item in items(setlist, eset) do :
        if upcoming(grammar,item) is False :
          val root = completion-root(item)
          match(root:EItem) :
            add-pending-completion-chain(index(eset), root)

  ;Construct production tables
  val production-ranges = HashTable<ProdPos, List<ParsedRange>>(List())
  defn add-production-range (set-index:Int, item:EItem) :
    val prodpos = ProdPos(production(grammar,item), set-index)
    val range = ParsedRange(rule(item), parent(item), set-index)
    add(production-ranges, prodpos, range)
  defn fill-production-table () :
    for eset in sets(setlist) do :
      for item in items(setlist, eset) do :
        if upcoming(grammar,item) is False :
          add-production-range(index(eset), item)
  defn get-production-ranges (prodpos:ProdPos) :
    within item = pending-chains(prodpos) :
      add-production-range(position(prodpos), item)
    production-ranges[prodpos]

  ;Retrieve child ranges
  val child-range-timer = MillisecondTimer("Child Range Timer")
  defn child-ranges (range:ParsedRange, index:Int, end-position:Int) :
    start(child-range-timer)
    val token = tokens!(grammar[rule(range)])[index]
    val production = name(token as GProduction)
    val result = to-tuple $ for child in get-production-ranges(ProdPos(production, end-position)) filter :
      rule-positions[RulePos(rule(range), index, start(range), start(child))]
    stop(child-range-timer)
    println(child-range-timer)
    result

  ;Fill tables
  within with-timer("fill rule positions") :
    fill-rule-positions()
  within with-timer("collect pending completion chains") :
    collect-pending-completion-chains()
  within with-timer("fill production table") :
    fill-production-table()

  ;defn test-children (range:ParsedRange, index:Int, end-position:Int) :
  ;  println("Children of %_ (index %_) (ending at %_):" % [format(grammar,range), index, end-position])
  ;  within indented() :
  ;    for child in child-ranges(range, index, end-position) do :
  ;      println(format(grammar,child))
  ;
  ;;TEST
  ;let :
  ;  val end = length(setlist) - 1
  ;  test-children(ParsedRange(0, 0, end), 3, end)
  ;  test-children(ParsedRange(1, 3, 20), 2, 20)
  ;  test-children(ParsedRange(1, 3, 20), 1, 5)
  ;  test-children(ParsedRange(1, 3, 20), 0, 4)
  ;  test-children(ParsedRange(2, 5, 20), 2, 20)
  ;  test-children(ParsedRange(2, 5, 20), 1, 7)
  ;  test-children(ParsedRange(2, 5, 20), 0, 6)
          
  new ParseForest :
    defmethod get (this, range:ParsedRange, index:Int, end-position:Int) :
      child-ranges(range, index, end-position)
    defmethod start (this) :
      ParsedRange(0, 0, length(setlist) - 1)      

defn with-timer<?T> (f:() -> ?T, name:String) :
  val timer = MillisecondTimer(name)
  start(timer)
  val result = f()
  stop(timer)
  println(timer)
  result
    

;============================================================
;================= Pruning the Parse Tree ===================
;============================================================

defn prune-tree (grammar:Grammar, ranges:RangeTable, ending-set:Int) :
  println("OLD PARENTS:")
  for p in parents(ranges) do :
    println(format(grammar,p))

  ;Complete right recursive chains 
  val completed-right-recursive-chains = HashSet<ParsedRange>()
  defn* complete-right-recursive-chain (r:ParsedRange) :
    if add(completed-right-recursive-chains, r) :
      val production = name(grammar[rule(r)])
      val parent = parent?(ranges, start(r), production)
      match(parent:ECondParent) :
        val last-index = length(tokens!(grammar[rule(parent)])) - 1
        add(ranges, EParent(rule(parent), start(parent), last-index, r, true))        
        complete-right-recursive-chain(ParsedRange(rule(parent), start(parent), end(r)))

  ;Reachable Ranges
  val reachable-ranges = HashSet<ParsedRange>()
  val children-table = ChildrenTable(ParsedRange(0, 0, ending-set))
  defn reach-range (range:ParsedRange) :
    if add(reachable-ranges, range) :
      val grule = grammar[rule(range)] as GMatcherRule|GTokenRule
      val last-index = length(tokens(grule)) - 1
      let loop (index:Int = last-index, end-positions:List<Int> = List(end(range))) :        
        if index >= 0 :
          match(tokens(grule)[index]) :
            (t:GTerminal) :
              val end-positions* = map({_ - 1}, end-positions)
              loop(index - 1, end-positions*)
            (t:GProduction) :
              ;Right recursive chains
              if index == last-index :
                for end-position in end-positions do :
                  for c in indirect-children(ranges, rule(range), start(range), index, end-position) do :
                    complete-right-recursive-chain(child(c))
              ;Children
              val children = to-list $ for end-position in end-positions seq-cat :
                children(ranges, rule(range), start(range), index, end-position)
              for c in children do :
                add(children-table, range, index, child(c))
                reach-range(child(c))
              ;Earlier productions
              val end-positions = unique $ seq(start{child(_)}, children)
              loop(index - 1, end-positions)

  ;Launcher
  reach-range(start(children-table))
  children-table
  
;============================================================
;================ Selecting the Parse Tree ==================
;============================================================

defn select-tree (grammar:Grammar, forest:ParseForest) -> ParseNode :
  val node-table = HashTable<ParsedRange,ParseNode>()

  defn select (range:ParsedRange) -> ParseNode :
    set?(node-table, range, fn () :
      val grule = grammar[rule(range)] as GMatcherRule|GTokenRule
      val children = Vector<ParseNode|False>()
      val num-tokens = length(tokens(grule))
      let loop (index:Int = num-tokens - 1, position:Int = end(range)) :
        if index >= 0 :
          match(tokens(grule)[index]) :
            (t:GTerminal) :
              add(children, false)
              loop(index - 1, position - 1)
            (t:GProduction) :
              val child-ranges = forest[range, index, position]
              val child-range = minimum(child-ranges, {compare-specificity(grammar, rule(range), _, _) < 0})
              val child = select(child-range)
              add(children, child)
              loop(index - 1, start(/range(child)))
      reverse!(children)        
      ParseNode(range, to-tuple(children)))

  ;Launch!
  select(start(forest))

;defn select-tree (grammar:Grammar, children-table:ChildrenTable) -> ParseNode :
;  val node-table = HashTable<ParsedRange,ParseNode>()
;
;  defn select (range:ParsedRange) -> ParseNode :
;    set?(node-table, range, fn () :
;      val grule = grammar[rule(range)] as GMatcherRule|GTokenRule
;      var max-failure:Int = length(range) when failure(grule) else 0
;      val children = Vector<ParseNode|False>()
;      val num-tokens = length(tokens(grule))
;      let loop (index:Int = 0, position:Int = start(range)) :
;        if index < num-tokens :
;          match(tokens(grule)[index]) :
;            (t:GTerminal) :
;              add(children, false)
;              loop(index + 1, position + 1)
;            (t:GProduction) :
;              val child-ranges = children-table[range, index, position]
;              val candidate-children = map(select, child-ranges)
;              val child = minimum(candidate-children, {compare-specificity(grammar, rule(range), _, _) < 0})
;              max-failure = max(max-failure, /max-failure(child))
;              add(children, child)
;              loop(index + 1, end(/range(child)))
;      ParseNode(range, max-failure, to-tuple(children)))
;
;  ;Launch!
;  select(start(children-table))

;;Return -1 if a should take priority over b during a left-to-right disambiguation sweep of the parse forest.
;defn compare-specificity (grammar:Grammar, parent-rule-index:Int, a:ParseNode, b:ParseNode) :
;  val parent-rule = grammar[parent-rule-index] as GMatcherRule|GTokenRule
;  val rule-a = grammar[rule(range(a))] as GMatcherRule|GTokenRule
;  val rule-b = grammar[rule(range(b))] as GMatcherRule|GTokenRule
;  defn compare-failure () :
;    compare(max-failure(a), max-failure(b))
;  defn compare-associativity () :
;    switch(associativity(parent-rule)) :
;      LeftAssociative : compare(length(range(a)), length(range(b)))
;      RightAssociative : compare(length(range(b)), length(range(a)))
;  defn compare-priority () :
;    compare(priority(rule-b), priority(rule-a))
;  defn compare-order () :
;    compare(rule(range(a)), rule(range(b)))
;  val c0 = compare-failure()
;  if c0 == 0 :
;    val c1 = compare-associativity()
;    if c1 == 0 :
;      val c2 = compare-priority()
;      if c2 == 0 : compare-order()
;      else : c2
;    else : c1  
;  else : c0

;Return -1 if a should take priority over b during a right-to-left disambiguation sweep of the parse forest.
defn compare-specificity (grammar:Grammar, parent-rule-index:Int, a:ParsedRange, b:ParsedRange) :
  val parent-rule = grammar[parent-rule-index] as GMatcherRule|GTokenRule
  val rule-a = grammar[rule(a)] as GMatcherRule|GTokenRule
  val rule-b = grammar[rule(b)] as GMatcherRule|GTokenRule
  defn compare-associativity () :
    switch(associativity(parent-rule)) :
      LeftAssociative : compare(length(a), length(b))
      RightAssociative : compare(length(b), length(a))
  defn compare-priority () :
    compare(priority(rule-b), priority(rule-a))
  defn compare-order () :
    compare(rule(a), rule(b))
  val c1 = compare-associativity()
  if c1 == 0 :
    val c2 = compare-priority()
    if c2 == 0 : compare-order()
    else : c2
  else : c1  

;============================================================
;================= Evaluate the Parse Tree ==================
;============================================================

defn evaluate-parse-tree (parse-result:ParseResult) :
  ;Pull out fields
  val grammar = grammar(parse-result)
  val inputlist = inputlist(parse-result)
  val infolist = infolist(parse-result)
  
  ;Accumulated errors                        
  val errors = Vector<Exception>()

  ;Attempt evaluation of a given ParseNode
  defn evaluate (tree:ParseNode) -> Maybe :
    ;Retrieve rule
    val rule = grammar[rule(range(tree))] as GMatcherRule|GTokenRule
    defn evaluate-child (i:Int) -> Maybe :
      match(children(tree)[i]) :
        (child:ParseNode) :
          evaluate(child)
        (f:False) :
          val token = tokens(rule)[i]
          val input = inputlist[start(range(tree)) + i]
          match(token, input) :
            (token:GListRest, input:SExpForm|SExpListEnd) : One(list(input))
            (token:GListEnd, input:SExpListEnd) : One(false)
            (token, input:SExpForm) : One(form(input))
            
    ;Lazy evaluation
    defn lazy-evaluation () :
      val result = new ParsedResult :
        defmethod get (this, i:Int) :
          val v = evaluate-child(i)
          throw(ChildNotEvaluated()) when empty?(v)
          value!(v)
        defmethod info (this) : infolist[start(range(tree))]
        defmethod form (this) : list(inputlist[start(range(tree))] as SExpForm|SExpListEnd)
      try :
        One(action(rule)(result))
      catch (e:ChildNotEvaluated) :
        None()
      catch (e:Exception) :
        add(errors, e)
        None()
        
    ;Eager evaluation
    defn eager-evaluation () :
      val results = to-tuple $
        seq(evaluate-child, 0 to length(tokens(rule)))
      if none?(empty?, results) :
        val result = new ParsedResult :
          defmethod get (this, i:Int) : value!(results[i])
          defmethod info (this) : infolist[start(range(tree))]
          defmethod form (this) : list(inputlist[start(range(tree))] as SExpForm|SExpListEnd)
        try :
          One(action(rule)(result))
        catch (e:Exception) :
          add(errors, e)
          None()
      else :
        None()

    ;Launch!
    if lazy-action?(rule) : lazy-evaluation()
    else : eager-evaluation()

  ;Launch!
  val v = evaluate(node(parse-result))
  if empty?(v) : throw(ParsingErrors(to-tuple(errors)))
  else : value!(v)

defstruct ChildNotEvaluated <: Exception

;============================================================
;==================== Overall Launcher ======================
;============================================================

defn parse (grammar:Grammar, input:List) :
  match(parse-result(grammar, input)) :
    (r:ParseResult) : evaluate-parse-tree(r)
    (e:ParsingErrors) : throw(e)  

;============================================================
;======================= Test Case ==========================
;============================================================

defn test-parse (rules:Tuple<GRule>, input:List) :
  val g = Grammar(rules)
  match(parse-result(g, input)) :
    (n:ParseResult) : println(format(g,node(n)))
    (e:ParsingErrors) : println(e)

defn test-parse-action (rules:Tuple<GRule>, input:List) :
  println(parse(Grammar(rules), input))

defn example-grammar () :
  val E = GProduction(`E)
  val N = GKeyword(`N)
  val PLUS = GKeyword(`+)
  val TIMES = GKeyword(`x)
  val LPAREN = GKeyword(`L)
  val RPAREN = GKeyword(`R)
  [GTokenRule(`S, [E])
   GTokenRule(`E, [E PLUS E], false, 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], false, 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])]

deftest print-grammar :
  val g = example-grammar()
  do(println, g)

deftest parse :
  test-parse(example-grammar(), `(N x N x L N + N R x N x N + N x N x N))

defn example-grammar-2 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val B = GKeyword(`B)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [E E X])
   GTokenRule(`S, [F F Y])
   GTokenRule(`E, [A A B])
   GTokenRule(`F, [A A B])]

deftest parse-2 :
  val g = example-grammar-2()
  test-parse(g, `(A A B A A B Y))

defn example-grammar-3 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val F = GProduction(`F)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  val Y = GKeyword(`Y)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [E F X])
   GTokenRule(`S, [F E X])
   GTokenRule(`S, [F F F Y])
   GTokenRule(`E, [A A])
   GTokenRule(`F, [A])]

deftest parse-3 :
  val g = example-grammar-3()
  test-parse(g, `(A A A X))

defn example-grammar-4 () :
  val S = GProduction(`S)
  val E = GProduction(`E)
  val A = GKeyword(`A)
  val X = GKeyword(`X)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [E E X])
   GTokenRule(`E, [A])
   GTokenRule(`E, [A A])]

deftest parse-4 :
  val g = example-grammar-4()
  test-parse(g, `(A A A A X))

defn example-grammar-5 () :
  #for E in [ES, E, IF-E, SCLAUSES, SCLAUSE, ECLAUSE] :
    val E = GProduction(`E)
  #for (X in [PLUS, TIMES, LPAREN, RPAREN, N, EQ, LET, IN, IF, COLON, ELSE, SWITCH],
        x in [+, x, L, R, N, =, let, in, if, :, else, switch]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [E PLUS E], false, 90, LeftAssociative)
   GTokenRule(`E, [E TIMES E], false, 80, LeftAssociative)
   GTokenRule(`E, [LPAREN E RPAREN])
   GTokenRule(`E, [N])
   GTokenRule(`E, [E EQ E])
   GTokenRule(`E, [LET E EQ E IN E])
   GTokenRule(`E, [IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE IF-E])
   GTokenRule(`IF-E, [IF E COLON E ELSE COLON E])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES ECLAUSE RPAREN])
   GTokenRule(`E, [SWITCH LPAREN SCLAUSES RPAREN])
   GTokenRule(`SCLAUSES, [SCLAUSE SCLAUSES])
   GTokenRule(`SCLAUSES, [])
   GTokenRule(`SCLAUSE, [E COLON E])
   GTokenRule(`ECLAUSE, [ELSE COLON E])]

deftest grammar-calc :
  Grammar(example-grammar-5())

deftest parse-5 :
  val g = example-grammar-5()
  test-parse(g, `(
    switch L
      N : N x N
      N x N : N
      N + N : N + N 
      else : N x N
    R))

deftest parse-5-2 :
  val g = example-grammar-5()
  test-parse(g, `(N + N x N + N))

deftest parse-6 :
  test-parse(example-grammar-5(), reader/read-file("test.txt"))

defn example-grammar-6 () :
  #for E in [ES, E] :
    val E = GProduction(`E)
  #for (X in [A B C],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [ES])
   GTokenRule(`ES, [E, ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [A])
   GTokenRule(`E, [B C])]

deftest parse-7 :
  val g = example-grammar-6()
  test-parse(g, `(a a b c a a b c b c a a a a a a a a a a a a a a a a))

let :;deftest parse-mutually-right-recursive :
  #for E in [AS BS CS A B C X] :
    val E = GProduction(`E)
  #for (X in [x a b c],
        x in [x a b c]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [X X X AS])
    GTokenRule(`AS, [A, X, BS])
    GTokenRule(`BS, [B, X, CS])
    GTokenRule(`CS, [X])
    GTokenRule(`CS, [C, X, AS])
    GTokenRule(`X, [x])
    GTokenRule(`A, [a])
    GTokenRule(`B, [b])
    GTokenRule(`C, [c])]
  test-parse(rules, `(x x x a x b x c x a x b x c x a x b x x))

deftest right-recursive-priority :
  #for E in [E A BS] :
    val E = GProduction(`E)
  #for (X in [a],
        x in [a]) :
    val X = GKeyword(`x)
  val rules = [
    GTokenRule(`Start, [E])
    GTokenRule(`E, [A BS])
    GTokenRule(`E, [A A A A], false, 200)
    GTokenRule(`BS, [A BS])
    GTokenRule(`BS, [])
    GTokenRule(`A, [a])]
  test-parse(rules, `(a a a a))

defn example-null-grammar () :
  #for X in [S Ap E] :
    val X = GProduction(`X)
  #for (X in [A],
        x in [a]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [Ap Ap Ap Ap])
   GTokenRule(`Ap, [A])
   GTokenRule(`Ap, [E])
   GTokenRule(`E, [])]

deftest parse-null :
  val g = example-null-grammar()
  test-parse(g, `(a a a))

defn example-tricky-null-grammar () :
  #for E in [S, A, B] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S])
   GTokenRule(`S, [w A d])
   GTokenRule(`S, [A d])
   GTokenRule(`S, [w B A A A d])
   GTokenRule(`A, [x])
   GTokenRule(`A, [])
   GTokenRule(`B, [x])]

deftest parse-tricky-null :
  val g = example-tricky-null-grammar()
  test-parse(g, `(w x x d))

defn example-tricky-null-grammar-2 () :
  #for E in [B S A] :
    val E = GProduction(`E)
  #for (X in [w, x, d],
        x in [w, x, d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [B])
   GTokenRule(`B, [S])
   GTokenRule(`B, [A])
   GTokenRule(`S, [w x A A A A d], false, 100, LeftAssociative)
   GTokenRule(`A, [w x])
   GTokenRule(`A, [])]

deftest parse-tricky-null-2 :
  val g = example-tricky-null-grammar-2()
  test-parse(g, `(w x w x d))

defn list-grammar () :
  #for E in [S, A, B, C, D, L, R, CD, CDs] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [A B CDs L CDs R CDs])
   GTokenRule(`S, [A B C])
   GTokenRule(`CDs, [CD, CDs])
   GTokenRule(`CDs, [])
   GTokenRule(`CD, [L C D R])
   GTokenRule(`A, [a])
   GTokenRule(`B, [b])
   GTokenRule(`C, [c])
   GTokenRule(`D, [d])
   GTokenRule(`L, [GListStart()])
   GTokenRule(`R, [GListEnd()])]

deftest parse-list :
  val g = list-grammar()
  test-parse(g, `(a b (c d) (c d) ((c d) (c d) (c d)) (c d)))

defn any-vs-list-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [done],
        x in [done]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [GAny() done])
   GTokenRule(`S, [GListStart() done GListEnd() done])]

deftest parse-any-vs-list :
  val g = any-vs-list-grammar()
  test-parse(g, `((done) done))

defn any-as-list-grammar () :
  #for E in [S A As Xs] :
    val E = GProduction(`E)
;  #for (X in [],
;        x in [a b c d]) :
;    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [Xs Xs])
   GTokenRule(`S, [A A])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [GListStart(true) As GListEnd()])
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`Xs, [GListStart() GKeyword(`x) GListEnd()])]

deftest parse-any-as-list :
  val g = any-as-list-grammar()
  test-parse(g, `((x) (x y z)))

defn list-recovery-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [a GListStart() b GListEnd() c])]

deftest parse-list-recovery :
  val g = list-recovery-grammar()
  test-parse(g, `(a b c))

defn rest-grammar () :
  #for E in [S] :
    val E = GProduction(`E)
  #for (X in [a b c],
        x in [a b c]) :
    val X = GKeyword(`x)
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [GListStart() a b c GListEnd()])
   GTokenRule(`S, [GListStart() a b GListRest() GListEnd()])]

deftest parse-rest :
  val g = rest-grammar()
  test-parse(g, `((a b d e f)))

defn full-any-grammar () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [LP a b LP c d As d RP RP])   
   GTokenRule(`S, [LP a b LP c d R RP RP])   
   GTokenRule(`S, [A])
   GTokenRule(`As, [A As])
   GTokenRule(`As, [])
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]  

deftest parse-full-any-grammar :
  val g = full-any-grammar()
  test-parse(g, `((a b (c d x y z d g d))))

defn full-any-grammar-2 () :
  #for E in [S A As R] :
    val E = GProduction(`E)
  #for (X in [a b c d],
        x in [a b c d]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [A a b c]) 
   GTokenRule(`S, [R])   
   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]  

deftest parse-full-any-grammar-2 :
  val g = full-any-grammar-2()
  test-parse(g, `((x y z) a b c))

defn amb-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], false, 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])]    

deftest parse-amb-grammar :
  val g = amb-grammar()
  test-parse(g, `(red red dog dog red dog dog dog))

defn amb-grammar-2 () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [red dog],
        x in [red dog]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E])
   GTokenRule(`ES, [E ES], false, 100, LeftAssociative)
   GTokenRule(`E, [dog])
   GTokenRule(`E, [red])
   GTokenRule(`E, [dog dog])]    

deftest parse-amb-grammar-2 :
  val g = amb-grammar-2()
  test-parse(g, `(red dog dog red dog dog red dog dog red dog dog red dog dog))

defn if-grammar () :
  #for E in [S ES E] :
    val E = GProduction(`E)
  #for (X in [IF THEN ELSE N],
        x in [if then else N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()
  [GTokenRule(`Start, [S GListEnd()])
   GTokenRule(`S, [ES])
   GTokenRule(`ES, [E ES], false, 100, LeftAssociative)
   GTokenRule(`ES, [])
   GTokenRule(`E, [LP E RP])   
   GTokenRule(`E, [IF E THEN E], false, 100, LeftAssociative)      
   GTokenRule(`E, [IF E THEN E ELSE E], false, 100, LeftAssociative)
   GTokenRule(`E, [N])]    

deftest parse-if-grammar :
  val g = if-grammar()
  test-parse(g, `(if N then if N then N else N))

defn matcher-grammar () :
  #for E in [ES E Id BId RId] :
    val E = GProduction(`E)
  #for (X in [VAR EQ N DOT],
        x in [var = N .]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn prefix-symbol? (form, prefix:String) :
    match(unwrap-token(form)) :
      (f:Symbol) : prefix?(name(f), prefix)
      (f) : false
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [VAR Id EQ E])
   GTokenRule(`E, [N])
   GTokenRule(`Id, [BId DOT RId])
   GMatcherRule(`BId, [GAny()], prefix-symbol?{_, "B"})
   GMatcherRule(`RId, [GAny()], prefix-symbol?{_, "R"})]

deftest parse-matcher-grammar :
  val g = matcher-grammar()
  test-parse(g, `(var B10.R18 = N N))

deftest parse-matcher-grammar-error :
  val g = matcher-grammar()
  test-parse(g, `("hello world"))

defn core-form-grammar () :
  #for E in [ES E A R] :
    val E = GProduction(`E)
  #for (X in [CORE],
        x in [$core]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val RP = GListEnd()

  defn core-form? (form) :
    match(unwrap-token(form)) :
      (f:List) : not empty?(f) and unwrap-token(head(f)) == `$core
      (f) : false
      
  [GTokenRule(`Start, [ES GListEnd()])
   GTokenRule(`ES, [E ES])
   GTokenRule(`ES, [])
   GTokenRule(`E, [CORE])
   GTokenRule(`E, [LP ES RP])   
   GMatcherRule(`E, [GAny(Atomic)], core-form?)

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP R RP])
   GTokenRule(`R, [GAny() R])
   GTokenRule(`R, [LP R RP R])
   GTokenRule(`R, [GListRest()])]

deftest parse-core-form-grammar :
  val g = core-form-grammar()
  test-parse(g, `($core ($core a b c d) $core))

defn exp-grammar () :
  #for E in [ES E ID A R] :
    val E = GProduction(`E)
  #for (X in [VAR VAL FOR LET IN EQ COLON PLUS TIMES N DO],
        x in [var val for let in = : + * N @do]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
      
  [GTokenRule(`Start, [ES GListEnd()], fn (result) :
     result[0])
  
   GTokenRule(`keywords, [VAR])     
   GTokenRule(`keywords, [VAL])     
   GTokenRule(`keywords, [FOR])     
   GTokenRule(`keywords, [LET])     
   GTokenRule(`keywords, [IN])
   GTokenRule(`keywords, [EQ])
   GTokenRule(`keywords, [COLON])
   GTokenRule(`keywords, [DO])

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])

   GTokenRule(`ID, [A], fn (result) :
     result[0])
   GNegationRule(`ID, GProduction(`keywords))
   
   GTokenRule(`ES, [E ES], fn (result) :
     cons(result[0], result[1]))
   GTokenRule(`ES, [], fn (result) :
     List())
   
   GTokenRule(`E, [VAR ID EQ E], fn (result) :
     qquote($var ~(result[1]) ~(result[3])))
   GTokenRule(`E, [VAL ID EQ E], fn (result) :
     qquote($val ~(result[1]) ~(result[3])))
   GTokenRule(`E, [FOR ID IN E COLON E], fn (result) :
       qquote($for ~(result[1]) ~(result[3]) ~(result[5])))
   GTokenRule(`E, [LET ID EQ E COLON E], fn (result) :
     qquote($let ~(result[1]) ~(result[3]) ~(result[5])))
   GTokenRule(`E, [LET ID EQ E R], true, 100, RightAssociative, fn (result) :
     throw(Exception("%_: Expected a colon after let binding" % [info(result)])))
   GTokenRule(`E, [E LP DO ES RP], false, 70, LeftAssociative, fn (result) :
     qquote($call ~(result[0]) ~@(result[3])))
   GTokenRule(`E, [LP E RP], fn (result) :
     result[1])
   GTokenRule(`E, [LP ES RP], fn (result) :
     qquote($begin ~@(result[1])))
   GTokenRule(`E, [N], fn (result) :
     result[0])
   GTokenRule(`E, [GIntToken()], fn (result) :
     result[0])
   GTokenRule(`E, [E PLUS E], false, 90, LeftAssociative, fn (result) :
     qquote($plus ~(result[0]), ~(result[2])))
   GTokenRule(`E, [E TIMES E], false, 80, LeftAssociative, fn (result) :
     qquote($times ~(result[0]), ~(result[2])))]

deftest parse-exp-grammar :
  test-parse(exp-grammar(), reader/read-file("exp-test.txt"))

deftest action-exp-grammar :
  test-parse-action(exp-grammar(), reader/read-file("exp-test.txt"))

defn rest-priority-grammar () :
  #for E in [ES E F A R] :
    val E = GProduction(`E)
  #for (X in [PLUS N],
        x in [+ N]) :
    val X = GKeyword(`x)
  val LP = GListStart()
  val LP* = GListStart(true)
  val RP = GListEnd()
      
  [GTokenRule(`Start, [F GListEnd()])

   GTokenRule(`F, [E E], false, 100, LeftAssociative)
   
   GTokenRule(`E, [E PLUS E], false, 90, LeftAssociative)
   GTokenRule(`E, [N R], true)
   GTokenRule(`E, [N])

   GTokenRule(`A, [GAny()])
   GTokenRule(`A, [LP* R RP])
   GTokenRule(`R, [GAny(Reluctant) R])
   GTokenRule(`R, [LP* R RP R])
   GTokenRule(`R, [GListRest()])
   GTokenRule(`R, [])]

deftest parse-rest-priority-grammar :
  val g = rest-priority-grammar()
  test-parse(g, `(N + N + N N + N))

deftest parse-blowup-grammar :
  #for E in [E] :
    val E = GProduction(`E)
  #for (X in [N],
        x in [N]) :
    val X = GKeyword(`x)
  val grammar = [
    GTokenRule(`Start, [E GListEnd()])
    GTokenRule(`E, [E E E])
    GTokenRule(`E, [N])]  

;  test-parse(grammar, `(N N N N N N N N N N N N N N N N N
;                        N N N N N N N N N N N N N N N N N N
;                        N N N N N N N N N N N N N N N N N
;                        N N N N N N N N N N N N N N N N N))

  test-parse(grammar, `(N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N
                        N N N N N N N N N N N N N N N N N N N))